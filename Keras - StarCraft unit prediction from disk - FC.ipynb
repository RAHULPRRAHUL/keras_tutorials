{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick start with keras for Star Craft classification  \n",
    "The objective of this guide is to show how to train a model from disk using keras. This is useful if your training or testing set is numerous and you just can not have a numpy array with all the values.  \n",
    "  \n",
    "This guide will show you how to use a multilayer perceptron for a feature you extract from images. The data set has the Star craft units for Protoss, Terran And Zerg that I found here **[1]**.  In another guide I will show how to use Convolutional Neural Networks for the same purposes.\n",
    "  \n",
    "* [1]http://starcraft.wikia.com/wiki/List_of_StarCraft_II_units  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import keras\n",
    "from PIL import Image\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show the files in the current location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "${f}  keras_class.ipynb  notes\tSC2Units  sc2_units_files  sc2_units.html\r\n"
     ]
    }
   ],
   "source": [
    "#First get the data\n",
    "!ls"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The folder **SC2Units** has the images. We use os to list the content of it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Banshee_SC2_Icon1.jpg', 'Icon_Zerg_Drone.jpg', 'Icon_Zerg_Hydralisk.jpg', 'Icon_Zerg_Baneling_Nest.jpg', 'Icon_Protoss_High_Templar.jpg', 'CommandCenter_SC2_Icon1.jpg', 'Viking_SC2_Icon1.jpg', 'Icon_Zerg_Overlord.jpg', 'Icon_Protoss_Cybernetics_Core.jpg', 'Icon_Protoss_Sentry.jpg', 'Icon_Zerg_Queen.jpg', 'Icon_Protoss_Templar_Archives.jpg', 'Icon_Zerg_Nydus_Network.jpg', 'Icon_Protoss_Phoenix.jpg', 'Icon_Zerg_Hatchery.jpg', 'Icon_Zerg_Creep_Tumor.jpg', 'Icon_Zerg_Roach_Warren.jpg', 'Icon_Zerg_Nydus_Worm.jpg', 'Hellbat_SC2-HotS_Icon1.jpg', 'MULE_SC2_Icon1.jpg', 'Hellion_SC2_Icon1.jpg', 'Liberator_SC2-LotV_Icon1.jpg', 'Armory_SC2_Icon1.jpg', 'Icon_Zerg_Spire.jpg', 'Icon_Zerg_Corruptor.jpg', 'Icon_Zerg_Lair.jpg', 'Raven_SC2_Icon1.jpg', 'Reaper_SC2_Icon1.jpg', 'Cyclone_SC2-LotV_Icon1.jpg', 'Icon_Protoss_Oracle.jpg', 'Icon_Zerg_Viper.jpg', 'Icon_Protoss_Photon_Cannon.jpg', 'Icon_Protoss_Dark_Shrine.jpg', 'SupplyDepot_SC2_Icon1.jpg', 'Icon_Protoss_Mothership.jpg', 'Icon_Protoss_Robotics_Facility.jpg', 'Thor_SC2_Icon1.jpg', 'SiegeTank_SC2_Icon1.jpg', 'Icon_Protoss_Gateway.jpg', 'Icon_Zerg_Infested_Terran.jpg', 'Icon_Zerg_Broodling.jpg', 'Icon_Zerg_Zergling.jpg', 'Icon_Zerg_Baneling.jpg', 'Icon_Protoss_Observer.jpg', 'Icon_Protoss_Warp_Prism.jpg', 'Icon_Zerg_Infestor.jpg', 'Icon_Protoss_Tempest.jpg', 'Icon_Zerg_Larva.jpg', 'Icon_Zerg_Spawning_Pool.jpg', 'Reactor_SC2_Icon1.jpg', 'Icon_Protoss_Immortal.jpg', 'Icon_Zerg_Ultralisk.jpg', 'SCV_SC2_Icon1.jpg', 'TechLab_SC2_Icon1.jpg', 'Bunker_SC2_Icon1.jpg', 'Icon_Protoss_Adept.jpg', 'Point_defense_drone_SC2_Icon1.jpg', 'PlanetaryFortress_SC2_Icon1.jpg', 'Icon_Zerg_Ravager.jpg', 'Icon_Zerg_Infestation_Pit.jpg', 'Barracks_SC2_Icon1.jpg', 'GhostAcademy_SC2_Icon1.jpg', 'Starport_SC2_Icon1.jpg', 'Medivac_SC2_Icon1.jpg', 'Icon_Protoss_Probe.jpg', 'Icon_Zerg_Swarm_Host.jpg', 'Icon_Protoss_Carrier.jpg', 'Icon_Zerg_Roach.jpg', 'Auto-turret_SC2_Icon1.jpg', 'FusionCore_SC2_Icon1.jpg', 'Icon_Zerg_Brood_Lord.jpg', 'Icon_Protoss_Stargate.jpg', 'Icon_Zerg_Changeling.jpg', 'Icon_Protoss_Zealot.jpg', 'Icon_Zerg_Lurker.jpg', 'Icon_Protoss_Stalker.jpg', 'Icon_Zerg_Spine_Crawler.jpg', 'Icon_Zerg_Greater_Spire.jpg', 'Icon_Protoss_Nexus.jpg', 'MissileTurret_SC2_Icon1.jpg', 'LurkerDen_SC2_Icon1.png', 'Icon_Protoss_Disruptor.jpg', 'Icon_Protoss_Mothership_Core.jpg', 'Icon_Zerg_Overseer.jpg', 'Icon_Protoss_Pylon.jpg', 'OrbitalCommand_SC2_Icon1.jpg', 'Icon_Protoss_Colossus.jpg', 'Icon_Protoss_Fleet_Beacon.jpg', 'Icon_Protoss_Archon.jpg', 'Icon_Zerg_Hive.jpg', 'Icon_Zerg_Spore_Crawler.jpg', 'Ghost_SC2_Icon1.jpg', 'Icon_Protoss_Dark_Templar.jpg', 'Marauder_SC2_Icon1.jpg', 'Icon_Protoss_Assimilator.jpg', 'Icon_Zerg_Hydralisk_Den.jpg', 'Battlecruiser_SC2_Icon1.jpg', 'WidowMine_SC2-HotS_Icon1.jpg', 'Marine_SC2_Icon1.jpg', 'Icon_Zerg_Ultralisk_Cavern.jpg', 'Icon_Zerg_Extractor.jpg', 'Refinery_SC2_Icon1.jpg', 'SensorTower_SC2_Icon1.jpg', 'EngineeringBay_SC2_Icon1.jpg', 'Icon_Protoss_Warp_Gate.jpg', 'Icon_Zerg_Evolution_Chamber.jpg', 'Icon_Protoss_Twilight_Council.jpg', 'Icon_Zerg_Mutalisk.jpg', 'Factory_SC2_Icon1.jpg', 'Icon_Protoss_Robotics_Bay.jpg', 'Icon_Protoss_Forge.jpg']\n"
     ]
    }
   ],
   "source": [
    "image_dir = 'SC2Units/'\n",
    "\n",
    "images = os.listdir(image_dir)\n",
    "print(images)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define a Dataframe that will have in one column the location to the images and in another a vector, **hot encoding**, for the three races.  \n",
    "Later, we shuffle the dataframe and split it into training and testing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first 10 lines of Dataframe \n",
      "                                      filename       target\n",
      "0              SC2Units/Banshee_SC2_Icon1.jpg  [[0, 0, 1]]\n",
      "1                SC2Units/Icon_Zerg_Drone.jpg  [[1, 0, 0]]\n",
      "2            SC2Units/Icon_Zerg_Hydralisk.jpg  [[1, 0, 0]]\n",
      "3        SC2Units/Icon_Zerg_Baneling_Nest.jpg  [[1, 0, 0]]\n",
      "4      SC2Units/Icon_Protoss_High_Templar.jpg  [[0, 1, 0]]\n",
      "5        SC2Units/CommandCenter_SC2_Icon1.jpg  [[0, 0, 1]]\n",
      "6               SC2Units/Viking_SC2_Icon1.jpg  [[0, 0, 1]]\n",
      "7             SC2Units/Icon_Zerg_Overlord.jpg  [[1, 0, 0]]\n",
      "8  SC2Units/Icon_Protoss_Cybernetics_Core.jpg  [[0, 1, 0]]\n",
      "9            SC2Units/Icon_Protoss_Sentry.jpg  [[0, 1, 0]]\n",
      "Shape of target array: (1, 3)\n",
      "(88, 3) (22, 3)\n",
      "Training head 2:\n",
      "    index                           filename       target\n",
      "0      9   SC2Units/Icon_Protoss_Sentry.jpg  [[0, 1, 0]]\n",
      "1     46  SC2Units/Icon_Protoss_Tempest.jpg  [[0, 1, 0]]\n",
      "Testing head 2:\n",
      "     index                              filename       target\n",
      "88     77  SC2Units/Icon_Zerg_Greater_Spire.jpg  [[1, 0, 0]]\n",
      "89      6         SC2Units/Viking_SC2_Icon1.jpg  [[0, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "classes = {'Zerg':np.array([[1,0,0]]),\n",
    "            'Protoss':np.array([[0,1,0]]),\n",
    "           'Terran':np.array([[0,0,1]]),\n",
    "            }\n",
    "to_df = []\n",
    "for image in images:\n",
    "    if \".jpg\" in image:\n",
    "        fullname = image_dir+image\n",
    "        unit_class = 'Terran'\n",
    "        if 'Zerg' in image:\n",
    "            unit_class='Zerg'\n",
    "        elif 'Protoss' in image:\n",
    "            unit_class='Protoss'\n",
    "        to_df.append({'filename':fullname,'target':classes[unit_class]})\n",
    "sc2_df = pd.DataFrame(to_df)\n",
    "\n",
    "print(\"first 10 lines of Dataframe \\n\",sc2_df.head(10))\n",
    "print(\"Shape of target array:\",sc2_df['target'][0].shape)\n",
    "\n",
    "#Shuffle the DataFrame, frac=1, means to take a sample of a fraction size of 1, so 100%\n",
    "# We reset the index to have a \"new\" dataframe without a record of the previous order.\n",
    "sc_df = sc2_df.sample(frac=1).reset_index()\n",
    "\n",
    "#Split into training and testing set\n",
    "training_fraction = 0.8\n",
    "rows = sc_df.shape[0]\n",
    "train_rows = int(rows*training_fraction)\n",
    "test_rows = rows - train_rows\n",
    "\n",
    "train_df = sc_df.head(train_rows)\n",
    "test_df = sc_df.tail(test_rows)\n",
    "\n",
    "\n",
    "print(train_df.shape,test_df.shape)\n",
    "print(\"Training head 2:\\n\",train_df.head(2))\n",
    "print(\"Testing head 2:\\n\",test_df.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a function to load an image from a file location and in addition we resize it to a shape **(64,64)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP4AAAD8CAYAAABXXhlaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe973f6f2e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def image_file_to_np(ifile,resize=(64,64)):\n",
    "    pil_img = Image.open(ifile)\n",
    "    pil_img = pil_img.resize(resize,Image.ANTIALIAS)\n",
    "    np_img = np.asarray(pil_img)\n",
    "    pil_img.close()\n",
    "    return np_img.copy()\n",
    "\n",
    "test_img = train_df['filename'][0]\n",
    "test_img = image_file_to_np(test_img)\n",
    "plt.imshow(test_img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we define a function that will use the numpy image and extract some features. In this case a histogram for the three channels, and will concatenate one after the other. The number of bars is represented by the variable **bins**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 30)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nS1LjDHpJapxBL0mNM+glqXEGvSQ17n8B2KkidroI21YAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fe9735c1a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def np_img_to_hist(inp,bins=10):\n",
    "    return np.hstack([ np.histogram(inp[:,:,x],bins=bins)[0] for x in range(3)]).reshape(1,bins*3)\n",
    "\n",
    "def plot_hist(i_np_hist):\n",
    "    x_bins = np.arange(0,i_np_hist.shape[1])\n",
    "    for x,h in zip(x_bins,i_np_hist.flatten()):\n",
    "        if x%10!=0:#Not counting the black\n",
    "            if x<10:\n",
    "                c='red'\n",
    "            elif x<20:\n",
    "                c='green'\n",
    "            else:\n",
    "                c='blue'\n",
    "            plt.bar(x,h,color=c)\n",
    "    plt.show()\n",
    "\n",
    "test_hist = np_img_to_hist(test_img,bins=10)\n",
    "print(test_hist.shape)\n",
    "\n",
    "#Plot the histogram of values\n",
    "plot_hist(test_hist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a function to create batches from disk  \n",
    "We need to load the content according to the mini-batch size, so the previous functions of loading a numpy array from disk and extracting a histogram must be called only for a batch. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 30) (4, 3)\n"
     ]
    }
   ],
   "source": [
    "def batch_hist_from_df(idf,x_col='filename',y_col='target',batch_size=4,offset=4,resize=(64,64),bins=10):\n",
    "    start_index = offset\n",
    "    rows = idf.shape[0]\n",
    "    if start_index >= rows:\n",
    "        start_index = start_index%rows\n",
    "    end_index = start_index + batch_size\n",
    "    \n",
    "    if end_index>rows:\n",
    "        end_index = rows\n",
    "    \n",
    "    tdf = idf.iloc[start_index:end_index]\n",
    "    _y = np.vstack(tdf[y_col])\n",
    "    \n",
    "    arrays = list(map(lambda x: image_file_to_np(x,resize=resize),tdf[x_col]))\n",
    "    _x = np.vstack(list(map(lambda x: np_img_to_hist(x,bins=bins),arrays)))\n",
    "    return _x.copy(),_y.copy()\n",
    "        \n",
    "\n",
    "xb,yb = batch_hist_from_df(idf=train_df,x_col='filename',y_col='target',\n",
    "                           batch_size=4,offset=4,resize=(64,64),bins=10)\n",
    "\n",
    "print(xb.shape,yb.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The keras model\n",
    "In the keras website we find this quickstart to build a model:  \n",
    "\n",
    "from keras.models import Sequential\n",
    "model = Sequential()\n",
    "from keras.layers import Dense\n",
    "model.add(Dense(units=64, activation='relu', input_dim=100))\n",
    "model.add(Dense(units=10, activation='softmax'))\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=0.01, momentum=0.9, nesterov=True))\n",
    "model.train_on_batch(x_batch, y_batch)\n",
    "#Evaluate\n",
    "loss_and_metrics = model.evaluate(x_test, y_test)\n",
    "#Prediction\n",
    "classes = model.predict(x_test)  \n",
    "\n",
    "### Changing our model  \n",
    "Here we have defined how many bins we want for the histogram, number of iterations (epochs), learning rate, batch-size, the resizing shape for each image.  \n",
    "We use batch normalization after each fully connected layer for a better performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter 0 Batch 0 / 22 Loss: 1.6536396\n",
      "Iter 0 Batch 1 / 22 Loss: 1.0313554\n",
      "Iter 0 Batch 2 / 22 Loss: 1.0657228\n",
      "Iter 0 Batch 3 / 22 Loss: 1.0714729\n",
      "Iter 0 Batch 4 / 22 Loss: 1.1490614\n",
      "Iter 0 Batch 5 / 22 Loss: 0.4619735\n",
      "Iter 0 Batch 6 / 22 Loss: 1.5612675\n",
      "Iter 0 Batch 7 / 22 Loss: 1.2878578\n",
      "Iter 0 Batch 8 / 22 Loss: 1.6079942\n",
      "Iter 0 Batch 9 / 22 Loss: 0.5196297\n",
      "Iter 0 Batch 10 / 22 Loss: 2.4733205\n",
      "Iter 0 Batch 11 / 22 Loss: 1.3874974\n",
      "Iter 0 Batch 12 / 22 Loss: 1.5880681\n",
      "Iter 0 Batch 13 / 22 Loss: 1.515432\n",
      "Iter 0 Batch 14 / 22 Loss: 1.9616457\n",
      "Iter 0 Batch 15 / 22 Loss: 1.6095573\n",
      "Iter 0 Batch 16 / 22 Loss: 1.1904781\n",
      "Iter 0 Batch 17 / 22 Loss: 1.7724915\n",
      "Iter 0 Batch 18 / 22 Loss: 2.0570128\n",
      "Iter 0 Batch 19 / 22 Loss: 0.9210616\n",
      "Iter 0 Batch 20 / 22 Loss: 1.9735522\n",
      "Iter 0 Batch 21 / 22 Loss: 1.9311455\n",
      "Iter 1 Batch 0 / 22 Loss: 1.5936828\n",
      "Iter 1 Batch 1 / 22 Loss: 1.1557336\n",
      "Iter 1 Batch 2 / 22 Loss: 1.4624382\n",
      "Iter 1 Batch 3 / 22 Loss: 0.75132537\n",
      "Iter 1 Batch 4 / 22 Loss: 1.6848018\n",
      "Iter 1 Batch 5 / 22 Loss: 0.98456085\n",
      "Iter 1 Batch 6 / 22 Loss: 1.4505405\n",
      "Iter 1 Batch 7 / 22 Loss: 1.6514509\n",
      "Iter 1 Batch 8 / 22 Loss: 1.3365606\n",
      "Iter 1 Batch 9 / 22 Loss: 1.9781514\n",
      "Iter 1 Batch 10 / 22 Loss: 1.6592519\n",
      "Iter 1 Batch 11 / 22 Loss: 1.4332114\n",
      "Iter 1 Batch 12 / 22 Loss: 1.860612\n",
      "Iter 1 Batch 13 / 22 Loss: 1.4801986\n",
      "Iter 1 Batch 14 / 22 Loss: 1.0494739\n",
      "Iter 1 Batch 15 / 22 Loss: 1.2998853\n",
      "Iter 1 Batch 16 / 22 Loss: 1.1465874\n",
      "Iter 1 Batch 17 / 22 Loss: 1.7084996\n",
      "Iter 1 Batch 18 / 22 Loss: 1.4397796\n",
      "Iter 1 Batch 19 / 22 Loss: 1.8745753\n",
      "Iter 1 Batch 20 / 22 Loss: 1.6781551\n",
      "Iter 1 Batch 21 / 22 Loss: 1.4891334\n",
      "Iter 2 Batch 0 / 22 Loss: 1.2181582\n",
      "Iter 2 Batch 1 / 22 Loss: 0.91198814\n",
      "Iter 2 Batch 2 / 22 Loss: 1.2784884\n",
      "Iter 2 Batch 3 / 22 Loss: 0.6497339\n",
      "Iter 2 Batch 4 / 22 Loss: 1.6889944\n",
      "Iter 2 Batch 5 / 22 Loss: 1.1560593\n",
      "Iter 2 Batch 6 / 22 Loss: 1.4975811\n",
      "Iter 2 Batch 7 / 22 Loss: 1.5903115\n",
      "Iter 2 Batch 8 / 22 Loss: 1.4827161\n",
      "Iter 2 Batch 9 / 22 Loss: 1.292074\n",
      "Iter 2 Batch 10 / 22 Loss: 1.3304055\n",
      "Iter 2 Batch 11 / 22 Loss: 1.3614738\n",
      "Iter 2 Batch 12 / 22 Loss: 1.376282\n",
      "Iter 2 Batch 13 / 22 Loss: 1.3733236\n",
      "Iter 2 Batch 14 / 22 Loss: 1.2262251\n",
      "Iter 2 Batch 15 / 22 Loss: 1.2736226\n",
      "Iter 2 Batch 16 / 22 Loss: 1.6740935\n",
      "Iter 2 Batch 17 / 22 Loss: 1.4274846\n",
      "Iter 2 Batch 18 / 22 Loss: 1.0991204\n",
      "Iter 2 Batch 19 / 22 Loss: 1.0539924\n",
      "Iter 2 Batch 20 / 22 Loss: 1.7588265\n",
      "Iter 2 Batch 21 / 22 Loss: 1.5115873\n",
      "Iter 3 Batch 0 / 22 Loss: 1.256917\n",
      "Iter 3 Batch 1 / 22 Loss: 1.2725301\n",
      "Iter 3 Batch 2 / 22 Loss: 0.9851546\n",
      "Iter 3 Batch 3 / 22 Loss: 1.2175525\n",
      "Iter 3 Batch 4 / 22 Loss: 1.1292081\n",
      "Iter 3 Batch 5 / 22 Loss: 0.9778831\n",
      "Iter 3 Batch 6 / 22 Loss: 1.4833337\n",
      "Iter 3 Batch 7 / 22 Loss: 0.885056\n",
      "Iter 3 Batch 8 / 22 Loss: 1.7256672\n",
      "Iter 3 Batch 9 / 22 Loss: 1.2656071\n",
      "Iter 3 Batch 10 / 22 Loss: 1.283612\n",
      "Iter 3 Batch 11 / 22 Loss: 1.3894386\n",
      "Iter 3 Batch 12 / 22 Loss: 1.2783272\n",
      "Iter 3 Batch 13 / 22 Loss: 1.1652471\n",
      "Iter 3 Batch 14 / 22 Loss: 1.0486044\n",
      "Iter 3 Batch 15 / 22 Loss: 1.2057266\n",
      "Iter 3 Batch 16 / 22 Loss: 1.294013\n",
      "Iter 3 Batch 17 / 22 Loss: 1.355612\n",
      "Iter 3 Batch 18 / 22 Loss: 1.0899911\n",
      "Iter 3 Batch 19 / 22 Loss: 1.0189563\n",
      "Iter 3 Batch 20 / 22 Loss: 1.5957234\n",
      "Iter 3 Batch 21 / 22 Loss: 1.5645497\n",
      "Iter 4 Batch 0 / 22 Loss: 1.2093892\n",
      "Iter 4 Batch 1 / 22 Loss: 1.210736\n",
      "Iter 4 Batch 2 / 22 Loss: 0.9394787\n",
      "Iter 4 Batch 3 / 22 Loss: 1.1032176\n",
      "Iter 4 Batch 4 / 22 Loss: 1.0596831\n",
      "Iter 4 Batch 5 / 22 Loss: 0.97586954\n",
      "Iter 4 Batch 6 / 22 Loss: 1.4374683\n",
      "Iter 4 Batch 7 / 22 Loss: 0.85775054\n",
      "Iter 4 Batch 8 / 22 Loss: 1.1554692\n",
      "Iter 4 Batch 9 / 22 Loss: 1.1285449\n",
      "Iter 4 Batch 10 / 22 Loss: 1.2030087\n",
      "Iter 4 Batch 11 / 22 Loss: 1.3532608\n",
      "Iter 4 Batch 12 / 22 Loss: 1.2558885\n",
      "Iter 4 Batch 13 / 22 Loss: 1.0908597\n",
      "Iter 4 Batch 14 / 22 Loss: 1.0221391\n",
      "Iter 4 Batch 15 / 22 Loss: 1.2051407\n",
      "Iter 4 Batch 16 / 22 Loss: 0.9693288\n",
      "Iter 4 Batch 17 / 22 Loss: 1.3436502\n",
      "Iter 4 Batch 18 / 22 Loss: 0.9531274\n",
      "Iter 4 Batch 19 / 22 Loss: 0.9819472\n",
      "Iter 4 Batch 20 / 22 Loss: 1.5502301\n",
      "Iter 4 Batch 21 / 22 Loss: 1.528936\n",
      "Iter 5 Batch 0 / 22 Loss: 1.2442851\n",
      "Iter 5 Batch 1 / 22 Loss: 1.1992428\n",
      "Iter 5 Batch 2 / 22 Loss: 1.1932052\n",
      "Iter 5 Batch 3 / 22 Loss: 0.8777504\n",
      "Iter 5 Batch 4 / 22 Loss: 1.0033313\n",
      "Iter 5 Batch 5 / 22 Loss: 0.8641205\n",
      "Iter 5 Batch 6 / 22 Loss: 1.4642539\n",
      "Iter 5 Batch 7 / 22 Loss: 0.86118823\n",
      "Iter 5 Batch 8 / 22 Loss: 1.1129905\n",
      "Iter 5 Batch 9 / 22 Loss: 1.1403608\n",
      "Iter 5 Batch 10 / 22 Loss: 1.1938615\n",
      "Iter 5 Batch 11 / 22 Loss: 1.3126137\n",
      "Iter 5 Batch 12 / 22 Loss: 1.202826\n",
      "Iter 5 Batch 13 / 22 Loss: 1.0560038\n",
      "Iter 5 Batch 14 / 22 Loss: 1.0621778\n",
      "Iter 5 Batch 15 / 22 Loss: 1.1137916\n",
      "Iter 5 Batch 16 / 22 Loss: 1.0079398\n",
      "Iter 5 Batch 17 / 22 Loss: 1.2896653\n",
      "Iter 5 Batch 18 / 22 Loss: 0.9297985\n",
      "Iter 5 Batch 19 / 22 Loss: 0.97647035\n",
      "Iter 5 Batch 20 / 22 Loss: 1.4694731\n",
      "Iter 5 Batch 21 / 22 Loss: 1.4933497\n",
      "Iter 6 Batch 0 / 22 Loss: 1.2492166\n",
      "Iter 6 Batch 1 / 22 Loss: 1.2266475\n",
      "Iter 6 Batch 2 / 22 Loss: 0.92685527\n",
      "Iter 6 Batch 3 / 22 Loss: 0.73681515\n",
      "Iter 6 Batch 4 / 22 Loss: 0.9676913\n",
      "Iter 6 Batch 5 / 22 Loss: 0.9160457\n",
      "Iter 6 Batch 6 / 22 Loss: 1.4894058\n",
      "Iter 6 Batch 7 / 22 Loss: 0.8497156\n",
      "Iter 6 Batch 8 / 22 Loss: 1.0086931\n",
      "Iter 6 Batch 9 / 22 Loss: 1.0755887\n",
      "Iter 6 Batch 10 / 22 Loss: 1.1796938\n",
      "Iter 6 Batch 11 / 22 Loss: 1.2654917\n",
      "Iter 6 Batch 12 / 22 Loss: 1.159376\n",
      "Iter 6 Batch 13 / 22 Loss: 1.0759081\n",
      "Iter 6 Batch 14 / 22 Loss: 1.0463269\n",
      "Iter 6 Batch 15 / 22 Loss: 1.0707161\n",
      "Iter 6 Batch 16 / 22 Loss: 0.9169626\n",
      "Iter 6 Batch 17 / 22 Loss: 1.3041006\n",
      "Iter 6 Batch 18 / 22 Loss: 0.88577545\n",
      "Iter 6 Batch 19 / 22 Loss: 0.94595367\n",
      "Iter 6 Batch 20 / 22 Loss: 1.3774675\n",
      "Iter 6 Batch 21 / 22 Loss: 1.342685\n",
      "Iter 7 Batch 0 / 22 Loss: 1.1444134\n",
      "Iter 7 Batch 1 / 22 Loss: 1.1879467\n",
      "Iter 7 Batch 2 / 22 Loss: 0.9986733\n",
      "Iter 7 Batch 3 / 22 Loss: 0.668991\n",
      "Iter 7 Batch 4 / 22 Loss: 0.87212557\n",
      "Iter 7 Batch 5 / 22 Loss: 0.8787454\n",
      "Iter 7 Batch 6 / 22 Loss: 1.4179237\n",
      "Iter 7 Batch 7 / 22 Loss: 0.84139836\n",
      "Iter 7 Batch 8 / 22 Loss: 1.0308926\n",
      "Iter 7 Batch 9 / 22 Loss: 0.99799967\n",
      "Iter 7 Batch 10 / 22 Loss: 1.1440212\n",
      "Iter 7 Batch 11 / 22 Loss: 1.2644913\n",
      "Iter 7 Batch 12 / 22 Loss: 1.1084306\n",
      "Iter 7 Batch 13 / 22 Loss: 1.0790368\n",
      "Iter 7 Batch 14 / 22 Loss: 1.0250386\n",
      "Iter 7 Batch 15 / 22 Loss: 1.0375427\n",
      "Iter 7 Batch 16 / 22 Loss: 0.8827344\n",
      "Iter 7 Batch 17 / 22 Loss: 1.2592387\n",
      "Iter 7 Batch 18 / 22 Loss: 0.86704654\n",
      "Iter 7 Batch 19 / 22 Loss: 0.930556\n",
      "Iter 7 Batch 20 / 22 Loss: 1.0993696\n",
      "Iter 7 Batch 21 / 22 Loss: 1.1952335\n",
      "Iter 8 Batch 0 / 22 Loss: 1.125772\n",
      "Iter 8 Batch 1 / 22 Loss: 1.2160823\n",
      "Iter 8 Batch 2 / 22 Loss: 0.94273865\n",
      "Iter 8 Batch 3 / 22 Loss: 0.6052951\n",
      "Iter 8 Batch 4 / 22 Loss: 0.8312367\n",
      "Iter 8 Batch 5 / 22 Loss: 0.758966\n",
      "Iter 8 Batch 6 / 22 Loss: 1.3724498\n",
      "Iter 8 Batch 7 / 22 Loss: 0.82641023\n",
      "Iter 8 Batch 8 / 22 Loss: 1.0449022\n",
      "Iter 8 Batch 9 / 22 Loss: 0.9168671\n",
      "Iter 8 Batch 10 / 22 Loss: 1.1210499\n",
      "Iter 8 Batch 11 / 22 Loss: 1.2588725\n",
      "Iter 8 Batch 12 / 22 Loss: 1.0956914\n",
      "Iter 8 Batch 13 / 22 Loss: 1.0215122\n",
      "Iter 8 Batch 14 / 22 Loss: 0.984221\n",
      "Iter 8 Batch 15 / 22 Loss: 0.9944966\n",
      "Iter 8 Batch 16 / 22 Loss: 0.8532584\n",
      "Iter 8 Batch 17 / 22 Loss: 1.2122104\n",
      "Iter 8 Batch 18 / 22 Loss: 0.8379503\n",
      "Iter 8 Batch 19 / 22 Loss: 0.9084845\n",
      "Iter 8 Batch 20 / 22 Loss: 1.110574\n",
      "Iter 8 Batch 21 / 22 Loss: 1.1660068\n",
      "Iter 9 Batch 0 / 22 Loss: 1.1034378\n",
      "Iter 9 Batch 1 / 22 Loss: 1.1861494\n",
      "Iter 9 Batch 2 / 22 Loss: 0.9456322\n",
      "Iter 9 Batch 3 / 22 Loss: 0.5677543\n",
      "Iter 9 Batch 4 / 22 Loss: 0.7898605\n",
      "Iter 9 Batch 5 / 22 Loss: 0.6275411\n",
      "Iter 9 Batch 6 / 22 Loss: 1.3429585\n",
      "Iter 9 Batch 7 / 22 Loss: 0.8172826\n",
      "Iter 9 Batch 8 / 22 Loss: 1.0130095\n",
      "Iter 9 Batch 9 / 22 Loss: 0.8764167\n",
      "Iter 9 Batch 10 / 22 Loss: 1.1191809\n",
      "Iter 9 Batch 11 / 22 Loss: 1.2560037\n",
      "Iter 9 Batch 12 / 22 Loss: 1.0886021\n",
      "Iter 9 Batch 13 / 22 Loss: 0.99239165\n",
      "Iter 9 Batch 14 / 22 Loss: 0.9627416\n",
      "Iter 9 Batch 15 / 22 Loss: 0.939315\n",
      "Iter 9 Batch 16 / 22 Loss: 0.82398236\n",
      "Iter 9 Batch 17 / 22 Loss: 1.1787211\n",
      "Iter 9 Batch 18 / 22 Loss: 0.82779866\n",
      "Iter 9 Batch 19 / 22 Loss: 0.89698577\n",
      "Iter 9 Batch 20 / 22 Loss: 1.1285967\n",
      "Iter 9 Batch 21 / 22 Loss: 1.1135823\n",
      "Iter 10 Batch 0 / 22 Loss: 1.0893158\n",
      "Iter 10 Batch 1 / 22 Loss: 1.1786721\n",
      "Iter 10 Batch 2 / 22 Loss: 0.94121593\n",
      "Iter 10 Batch 3 / 22 Loss: 0.49930874\n",
      "Iter 10 Batch 4 / 22 Loss: 0.7705295\n",
      "Iter 10 Batch 5 / 22 Loss: 0.5786226\n",
      "Iter 10 Batch 6 / 22 Loss: 1.3183379\n",
      "Iter 10 Batch 7 / 22 Loss: 0.80050766\n",
      "Iter 10 Batch 8 / 22 Loss: 0.99615306\n",
      "Iter 10 Batch 9 / 22 Loss: 0.85201573\n",
      "Iter 10 Batch 10 / 22 Loss: 1.112043\n",
      "Iter 10 Batch 11 / 22 Loss: 1.2491397\n",
      "Iter 10 Batch 12 / 22 Loss: 1.0721749\n",
      "Iter 10 Batch 13 / 22 Loss: 0.9606313\n",
      "Iter 10 Batch 14 / 22 Loss: 0.96033156\n",
      "Iter 10 Batch 15 / 22 Loss: 0.7576537\n",
      "Iter 10 Batch 16 / 22 Loss: 0.8019853\n",
      "Iter 10 Batch 17 / 22 Loss: 1.1796056\n",
      "Iter 10 Batch 18 / 22 Loss: 0.8235271\n",
      "Iter 10 Batch 19 / 22 Loss: 0.88623494\n",
      "Iter 10 Batch 20 / 22 Loss: 1.1383917\n",
      "Iter 10 Batch 21 / 22 Loss: 1.069726\n",
      "Iter 11 Batch 0 / 22 Loss: 1.0781344\n",
      "Iter 11 Batch 1 / 22 Loss: 1.2130228\n",
      "Iter 11 Batch 2 / 22 Loss: 0.95279276\n",
      "Iter 11 Batch 3 / 22 Loss: 0.48960543\n",
      "Iter 11 Batch 4 / 22 Loss: 0.7457203\n",
      "Iter 11 Batch 5 / 22 Loss: 0.55766827\n",
      "Iter 11 Batch 6 / 22 Loss: 1.2895948\n",
      "Iter 11 Batch 7 / 22 Loss: 0.79959846\n",
      "Iter 11 Batch 8 / 22 Loss: 1.0055294\n",
      "Iter 11 Batch 9 / 22 Loss: 0.866913\n",
      "Iter 11 Batch 10 / 22 Loss: 1.1013626\n",
      "Iter 11 Batch 11 / 22 Loss: 1.252769\n",
      "Iter 11 Batch 12 / 22 Loss: 1.0443518\n",
      "Iter 11 Batch 13 / 22 Loss: 0.95645845\n",
      "Iter 11 Batch 14 / 22 Loss: 0.9549764\n",
      "Iter 11 Batch 15 / 22 Loss: 0.8727123\n",
      "Iter 11 Batch 16 / 22 Loss: 0.7893324\n",
      "Iter 11 Batch 17 / 22 Loss: 1.158878\n",
      "Iter 11 Batch 18 / 22 Loss: 0.79442096\n",
      "Iter 11 Batch 19 / 22 Loss: 0.897928\n",
      "Iter 11 Batch 20 / 22 Loss: 1.1306884\n",
      "Iter 11 Batch 21 / 22 Loss: 1.1035109\n",
      "Iter 12 Batch 0 / 22 Loss: 1.0612315\n",
      "Iter 12 Batch 1 / 22 Loss: 1.1752971\n",
      "Iter 12 Batch 2 / 22 Loss: 0.91220117\n",
      "Iter 12 Batch 3 / 22 Loss: 0.4328587\n",
      "Iter 12 Batch 4 / 22 Loss: 0.70066595\n",
      "Iter 12 Batch 5 / 22 Loss: 0.5828246\n",
      "Iter 12 Batch 6 / 22 Loss: 1.2909899\n",
      "Iter 12 Batch 7 / 22 Loss: 0.7616564\n",
      "Iter 12 Batch 8 / 22 Loss: 0.99109066\n",
      "Iter 12 Batch 9 / 22 Loss: 0.82689095\n",
      "Iter 12 Batch 10 / 22 Loss: 1.0670677\n",
      "Iter 12 Batch 11 / 22 Loss: 1.2593702\n",
      "Iter 12 Batch 12 / 22 Loss: 1.0593474\n",
      "Iter 12 Batch 13 / 22 Loss: 0.9310994\n",
      "Iter 12 Batch 14 / 22 Loss: 0.94602793\n",
      "Iter 12 Batch 15 / 22 Loss: 0.74885774\n",
      "Iter 12 Batch 16 / 22 Loss: 0.7768775\n",
      "Iter 12 Batch 17 / 22 Loss: 1.0323128\n",
      "Iter 12 Batch 18 / 22 Loss: 0.83532226\n",
      "Iter 12 Batch 19 / 22 Loss: 0.8779318\n",
      "Iter 12 Batch 20 / 22 Loss: 1.127565\n",
      "Iter 12 Batch 21 / 22 Loss: 1.0490792\n",
      "Iter 13 Batch 0 / 22 Loss: 1.0431422\n",
      "Iter 13 Batch 1 / 22 Loss: 1.1738265\n",
      "Iter 13 Batch 2 / 22 Loss: 0.91273487\n",
      "Iter 13 Batch 3 / 22 Loss: 0.4163438\n",
      "Iter 13 Batch 4 / 22 Loss: 0.6889346\n",
      "Iter 13 Batch 5 / 22 Loss: 0.56923085\n",
      "Iter 13 Batch 6 / 22 Loss: 1.291655\n",
      "Iter 13 Batch 7 / 22 Loss: 0.7525201\n",
      "Iter 13 Batch 8 / 22 Loss: 0.96775186\n",
      "Iter 13 Batch 9 / 22 Loss: 0.8298833\n",
      "Iter 13 Batch 10 / 22 Loss: 1.0609426\n",
      "Iter 13 Batch 11 / 22 Loss: 1.2394867\n",
      "Iter 13 Batch 12 / 22 Loss: 1.031204\n",
      "Iter 13 Batch 13 / 22 Loss: 0.9102237\n",
      "Iter 13 Batch 14 / 22 Loss: 0.9540918\n",
      "Iter 13 Batch 15 / 22 Loss: 0.66421753\n",
      "Iter 13 Batch 16 / 22 Loss: 0.75318694\n",
      "Iter 13 Batch 17 / 22 Loss: 0.9968145\n",
      "Iter 13 Batch 18 / 22 Loss: 0.77348197\n",
      "Iter 13 Batch 19 / 22 Loss: 0.8812747\n",
      "Iter 13 Batch 20 / 22 Loss: 1.1260965\n",
      "Iter 13 Batch 21 / 22 Loss: 1.0258676\n",
      "Iter 14 Batch 0 / 22 Loss: 1.023453\n",
      "Iter 14 Batch 1 / 22 Loss: 1.1417562\n",
      "Iter 14 Batch 2 / 22 Loss: 0.89549196\n",
      "Iter 14 Batch 3 / 22 Loss: 0.40156165\n",
      "Iter 14 Batch 4 / 22 Loss: 0.6555447\n",
      "Iter 14 Batch 5 / 22 Loss: 0.5726454\n",
      "Iter 14 Batch 6 / 22 Loss: 1.2637821\n",
      "Iter 14 Batch 7 / 22 Loss: 0.7358011\n",
      "Iter 14 Batch 8 / 22 Loss: 0.9623369\n",
      "Iter 14 Batch 9 / 22 Loss: 0.79699427\n",
      "Iter 14 Batch 10 / 22 Loss: 1.0439004\n",
      "Iter 14 Batch 11 / 22 Loss: 1.2335731\n",
      "Iter 14 Batch 12 / 22 Loss: 1.0461594\n",
      "Iter 14 Batch 13 / 22 Loss: 0.89881563\n",
      "Iter 14 Batch 14 / 22 Loss: 0.9539577\n",
      "Iter 14 Batch 15 / 22 Loss: 0.66752005\n",
      "Iter 14 Batch 16 / 22 Loss: 0.7496851\n",
      "Iter 14 Batch 17 / 22 Loss: 1.1399558\n",
      "Iter 14 Batch 18 / 22 Loss: 0.7764873\n",
      "Iter 14 Batch 19 / 22 Loss: 0.87582314\n",
      "Iter 14 Batch 20 / 22 Loss: 1.1236575\n",
      "Iter 14 Batch 21 / 22 Loss: 1.0130016\n",
      "Iter 15 Batch 0 / 22 Loss: 1.0195498\n",
      "Iter 15 Batch 1 / 22 Loss: 1.1570055\n",
      "Iter 15 Batch 2 / 22 Loss: 0.86746436\n",
      "Iter 15 Batch 3 / 22 Loss: 0.39019758\n",
      "Iter 15 Batch 4 / 22 Loss: 0.6361903\n",
      "Iter 15 Batch 5 / 22 Loss: 0.56826156\n",
      "Iter 15 Batch 6 / 22 Loss: 1.2809117\n",
      "Iter 15 Batch 7 / 22 Loss: 0.72037816\n",
      "Iter 15 Batch 8 / 22 Loss: 0.9419811\n",
      "Iter 15 Batch 9 / 22 Loss: 0.78130144\n",
      "Iter 15 Batch 10 / 22 Loss: 1.0301754\n",
      "Iter 15 Batch 11 / 22 Loss: 1.2556001\n",
      "Iter 15 Batch 12 / 22 Loss: 0.99871457\n",
      "Iter 15 Batch 13 / 22 Loss: 0.91560227\n",
      "Iter 15 Batch 14 / 22 Loss: 0.97697806\n",
      "Iter 15 Batch 15 / 22 Loss: 0.66887414\n",
      "Iter 15 Batch 16 / 22 Loss: 0.7541384\n",
      "Iter 15 Batch 17 / 22 Loss: 0.91529\n",
      "Iter 15 Batch 18 / 22 Loss: 0.7704054\n",
      "Iter 15 Batch 19 / 22 Loss: 0.89146376\n",
      "Iter 15 Batch 20 / 22 Loss: 1.1085463\n",
      "Iter 15 Batch 21 / 22 Loss: 0.9891374\n",
      "Iter 16 Batch 0 / 22 Loss: 1.0148472\n",
      "Iter 16 Batch 1 / 22 Loss: 1.1320457\n",
      "Iter 16 Batch 2 / 22 Loss: 0.8656964\n",
      "Iter 16 Batch 3 / 22 Loss: 0.38278568\n",
      "Iter 16 Batch 4 / 22 Loss: 0.622577\n",
      "Iter 16 Batch 5 / 22 Loss: 0.5783733\n",
      "Iter 16 Batch 6 / 22 Loss: 1.2671983\n",
      "Iter 16 Batch 7 / 22 Loss: 0.7071614\n",
      "Iter 16 Batch 8 / 22 Loss: 0.9280942\n",
      "Iter 16 Batch 9 / 22 Loss: 0.7723996\n",
      "Iter 16 Batch 10 / 22 Loss: 1.0190628\n",
      "Iter 16 Batch 11 / 22 Loss: 1.2284712\n",
      "Iter 16 Batch 12 / 22 Loss: 1.0178916\n",
      "Iter 16 Batch 13 / 22 Loss: 0.8808526\n",
      "Iter 16 Batch 14 / 22 Loss: 0.94377244\n",
      "Iter 16 Batch 15 / 22 Loss: 0.64877594\n",
      "Iter 16 Batch 16 / 22 Loss: 0.70256233\n",
      "Iter 16 Batch 17 / 22 Loss: 0.8035375\n",
      "Iter 16 Batch 18 / 22 Loss: 0.7469488\n",
      "Iter 16 Batch 19 / 22 Loss: 0.8574866\n",
      "Iter 16 Batch 20 / 22 Loss: 1.1158013\n",
      "Iter 16 Batch 21 / 22 Loss: 0.9805014\n",
      "Iter 17 Batch 0 / 22 Loss: 0.99570817\n",
      "Iter 17 Batch 1 / 22 Loss: 1.1221291\n",
      "Iter 17 Batch 2 / 22 Loss: 0.85149825\n",
      "Iter 17 Batch 3 / 22 Loss: 0.37541664\n",
      "Iter 17 Batch 4 / 22 Loss: 0.5970003\n",
      "Iter 17 Batch 5 / 22 Loss: 0.5645159\n",
      "Iter 17 Batch 6 / 22 Loss: 1.2557166\n",
      "Iter 17 Batch 7 / 22 Loss: 0.6977137\n",
      "Iter 17 Batch 8 / 22 Loss: 0.925493\n",
      "Iter 17 Batch 9 / 22 Loss: 0.76073045\n",
      "Iter 17 Batch 10 / 22 Loss: 1.010553\n",
      "Iter 17 Batch 11 / 22 Loss: 1.2452737\n",
      "Iter 17 Batch 12 / 22 Loss: 0.9882585\n",
      "Iter 17 Batch 13 / 22 Loss: 0.8761711\n",
      "Iter 17 Batch 14 / 22 Loss: 0.93423796\n",
      "Iter 17 Batch 15 / 22 Loss: 0.6221936\n",
      "Iter 17 Batch 16 / 22 Loss: 0.68193674\n",
      "Iter 17 Batch 17 / 22 Loss: 0.68631756\n",
      "Iter 17 Batch 18 / 22 Loss: 0.73959744\n",
      "Iter 17 Batch 19 / 22 Loss: 0.8687388\n",
      "Iter 17 Batch 20 / 22 Loss: 1.0881854\n",
      "Iter 17 Batch 21 / 22 Loss: 0.95897454\n",
      "Iter 18 Batch 0 / 22 Loss: 0.9909762\n",
      "Iter 18 Batch 1 / 22 Loss: 1.115008\n",
      "Iter 18 Batch 2 / 22 Loss: 0.84830976\n",
      "Iter 18 Batch 3 / 22 Loss: 0.37406182\n",
      "Iter 18 Batch 4 / 22 Loss: 0.5880927\n",
      "Iter 18 Batch 5 / 22 Loss: 0.56707996\n",
      "Iter 18 Batch 6 / 22 Loss: 1.2564676\n",
      "Iter 18 Batch 7 / 22 Loss: 0.6871309\n",
      "Iter 18 Batch 8 / 22 Loss: 0.92945504\n",
      "Iter 18 Batch 9 / 22 Loss: 0.7594947\n",
      "Iter 18 Batch 10 / 22 Loss: 0.9899435\n",
      "Iter 18 Batch 11 / 22 Loss: 1.2503994\n",
      "Iter 18 Batch 12 / 22 Loss: 0.97342354\n",
      "Iter 18 Batch 13 / 22 Loss: 0.86658645\n",
      "Iter 18 Batch 14 / 22 Loss: 0.93129426\n",
      "Iter 18 Batch 15 / 22 Loss: 0.61952335\n",
      "Iter 18 Batch 16 / 22 Loss: 0.6418783\n",
      "Iter 18 Batch 17 / 22 Loss: 0.8699796\n",
      "Iter 18 Batch 18 / 22 Loss: 0.7247869\n",
      "Iter 18 Batch 19 / 22 Loss: 0.8723136\n",
      "Iter 18 Batch 20 / 22 Loss: 1.0910506\n",
      "Iter 18 Batch 21 / 22 Loss: 0.94044715\n",
      "Iter 19 Batch 0 / 22 Loss: 0.99436677\n",
      "Iter 19 Batch 1 / 22 Loss: 1.1130023\n",
      "Iter 19 Batch 2 / 22 Loss: 0.84084517\n",
      "Iter 19 Batch 3 / 22 Loss: 0.36777106\n",
      "Iter 19 Batch 4 / 22 Loss: 0.5764471\n",
      "Iter 19 Batch 5 / 22 Loss: 0.57068044\n",
      "Iter 19 Batch 6 / 22 Loss: 1.2560648\n",
      "Iter 19 Batch 7 / 22 Loss: 0.6723057\n",
      "Iter 19 Batch 8 / 22 Loss: 0.9087796\n",
      "Iter 19 Batch 9 / 22 Loss: 0.7425827\n",
      "Iter 19 Batch 10 / 22 Loss: 0.96674967\n",
      "Iter 19 Batch 11 / 22 Loss: 1.2458131\n",
      "Iter 19 Batch 12 / 22 Loss: 0.9555237\n",
      "Iter 19 Batch 13 / 22 Loss: 0.8580041\n",
      "Iter 19 Batch 14 / 22 Loss: 0.93348455\n",
      "Iter 19 Batch 15 / 22 Loss: 0.61179674\n",
      "Iter 19 Batch 16 / 22 Loss: 0.63538146\n",
      "Iter 19 Batch 17 / 22 Loss: 0.81092846\n",
      "Iter 19 Batch 18 / 22 Loss: 0.7207113\n",
      "Iter 19 Batch 19 / 22 Loss: 0.8604088\n",
      "Iter 19 Batch 20 / 22 Loss: 1.0710142\n",
      "Iter 19 Batch 21 / 22 Loss: 0.92571706\n",
      "Iter 20 Batch 0 / 22 Loss: 0.98780495\n",
      "Iter 20 Batch 1 / 22 Loss: 1.1051724\n",
      "Iter 20 Batch 2 / 22 Loss: 0.8363215\n",
      "Iter 20 Batch 3 / 22 Loss: 0.360691\n",
      "Iter 20 Batch 4 / 22 Loss: 0.5658745\n",
      "Iter 20 Batch 5 / 22 Loss: 0.57151157\n",
      "Iter 20 Batch 6 / 22 Loss: 1.2425506\n",
      "Iter 20 Batch 7 / 22 Loss: 0.6560016\n",
      "Iter 20 Batch 8 / 22 Loss: 0.894809\n",
      "Iter 20 Batch 9 / 22 Loss: 0.7353685\n",
      "Iter 20 Batch 10 / 22 Loss: 0.95609266\n",
      "Iter 20 Batch 11 / 22 Loss: 1.2320235\n",
      "Iter 20 Batch 12 / 22 Loss: 0.9527611\n",
      "Iter 20 Batch 13 / 22 Loss: 0.8478031\n",
      "Iter 20 Batch 14 / 22 Loss: 0.93011475\n",
      "Iter 20 Batch 15 / 22 Loss: 0.49798912\n",
      "Iter 20 Batch 16 / 22 Loss: 0.6224109\n",
      "Iter 20 Batch 17 / 22 Loss: 0.778095\n",
      "Iter 20 Batch 18 / 22 Loss: 0.706088\n",
      "Iter 20 Batch 19 / 22 Loss: 0.8641122\n",
      "Iter 20 Batch 20 / 22 Loss: 1.0628597\n",
      "Iter 20 Batch 21 / 22 Loss: 0.9091861\n",
      "Iter 21 Batch 0 / 22 Loss: 0.9779902\n",
      "Iter 21 Batch 1 / 22 Loss: 1.0977452\n",
      "Iter 21 Batch 2 / 22 Loss: 0.82399285\n",
      "Iter 21 Batch 3 / 22 Loss: 0.3586043\n",
      "Iter 21 Batch 4 / 22 Loss: 0.5559999\n",
      "Iter 21 Batch 5 / 22 Loss: 0.57049155\n",
      "Iter 21 Batch 6 / 22 Loss: 1.2459505\n",
      "Iter 21 Batch 7 / 22 Loss: 0.64604485\n",
      "Iter 21 Batch 8 / 22 Loss: 0.8892058\n",
      "Iter 21 Batch 9 / 22 Loss: 0.73089373\n",
      "Iter 21 Batch 10 / 22 Loss: 0.9400603\n",
      "Iter 21 Batch 11 / 22 Loss: 1.23666\n",
      "Iter 21 Batch 12 / 22 Loss: 0.9443061\n",
      "Iter 21 Batch 13 / 22 Loss: 0.8356141\n",
      "Iter 21 Batch 14 / 22 Loss: 0.91782\n",
      "Iter 21 Batch 15 / 22 Loss: 0.4737131\n",
      "Iter 21 Batch 16 / 22 Loss: 0.6056706\n",
      "Iter 21 Batch 17 / 22 Loss: 0.763195\n",
      "Iter 21 Batch 18 / 22 Loss: 0.7025377\n",
      "Iter 21 Batch 19 / 22 Loss: 0.8574168\n",
      "Iter 21 Batch 20 / 22 Loss: 1.0515943\n",
      "Iter 21 Batch 21 / 22 Loss: 0.9007385\n",
      "Iter 22 Batch 0 / 22 Loss: 0.97090816\n",
      "Iter 22 Batch 1 / 22 Loss: 1.0829422\n",
      "Iter 22 Batch 2 / 22 Loss: 0.81247044\n",
      "Iter 22 Batch 3 / 22 Loss: 0.3588516\n",
      "Iter 22 Batch 4 / 22 Loss: 0.5401986\n",
      "Iter 22 Batch 5 / 22 Loss: 0.5762034\n",
      "Iter 22 Batch 6 / 22 Loss: 1.2464753\n",
      "Iter 22 Batch 7 / 22 Loss: 0.6244794\n",
      "Iter 22 Batch 8 / 22 Loss: 0.88806546\n",
      "Iter 22 Batch 9 / 22 Loss: 0.71665484\n",
      "Iter 22 Batch 10 / 22 Loss: 0.92784935\n",
      "Iter 22 Batch 11 / 22 Loss: 1.2265884\n",
      "Iter 22 Batch 12 / 22 Loss: 0.9402381\n",
      "Iter 22 Batch 13 / 22 Loss: 0.8291529\n",
      "Iter 22 Batch 14 / 22 Loss: 0.9204242\n",
      "Iter 22 Batch 15 / 22 Loss: 0.5550938\n",
      "Iter 22 Batch 16 / 22 Loss: 0.59582734\n",
      "Iter 22 Batch 17 / 22 Loss: 0.73489845\n",
      "Iter 22 Batch 18 / 22 Loss: 0.71613693\n",
      "Iter 22 Batch 19 / 22 Loss: 0.8391462\n",
      "Iter 22 Batch 20 / 22 Loss: 1.0567138\n",
      "Iter 22 Batch 21 / 22 Loss: 0.8694729\n",
      "Iter 23 Batch 0 / 22 Loss: 0.98010516\n",
      "Iter 23 Batch 1 / 22 Loss: 1.0668192\n",
      "Iter 23 Batch 2 / 22 Loss: 0.88888395\n",
      "Iter 23 Batch 3 / 22 Loss: 0.34901893\n",
      "Iter 23 Batch 4 / 22 Loss: 0.5534539\n",
      "Iter 23 Batch 5 / 22 Loss: 0.5751838\n",
      "Iter 23 Batch 6 / 22 Loss: 1.2258143\n",
      "Iter 23 Batch 7 / 22 Loss: 0.6410557\n",
      "Iter 23 Batch 8 / 22 Loss: 0.9614725\n",
      "Iter 23 Batch 9 / 22 Loss: 0.76676214\n",
      "Iter 23 Batch 10 / 22 Loss: 0.95524323\n",
      "Iter 23 Batch 11 / 22 Loss: 1.2600892\n",
      "Iter 23 Batch 12 / 22 Loss: 0.9177528\n",
      "Iter 23 Batch 13 / 22 Loss: 0.82161546\n",
      "Iter 23 Batch 14 / 22 Loss: 0.91109324\n",
      "Iter 23 Batch 15 / 22 Loss: 0.71398664\n",
      "Iter 23 Batch 16 / 22 Loss: 0.5855977\n",
      "Iter 23 Batch 17 / 22 Loss: 0.76568115\n",
      "Iter 23 Batch 18 / 22 Loss: 0.70435786\n",
      "Iter 23 Batch 19 / 22 Loss: 0.8660939\n",
      "Iter 23 Batch 20 / 22 Loss: 1.0732815\n",
      "Iter 23 Batch 21 / 22 Loss: 0.8549651\n",
      "Iter 24 Batch 0 / 22 Loss: 0.9728011\n",
      "Iter 24 Batch 1 / 22 Loss: 1.0675099\n",
      "Iter 24 Batch 2 / 22 Loss: 0.8170359\n",
      "Iter 24 Batch 3 / 22 Loss: 0.33668685\n",
      "Iter 24 Batch 4 / 22 Loss: 0.54746354\n",
      "Iter 24 Batch 5 / 22 Loss: 0.5553069\n",
      "Iter 24 Batch 6 / 22 Loss: 1.2490063\n",
      "Iter 24 Batch 7 / 22 Loss: 0.62923384\n",
      "Iter 24 Batch 8 / 22 Loss: 0.90583986\n",
      "Iter 24 Batch 9 / 22 Loss: 0.72224486\n",
      "Iter 24 Batch 10 / 22 Loss: 0.9295348\n",
      "Iter 24 Batch 11 / 22 Loss: 1.2509451\n",
      "Iter 24 Batch 12 / 22 Loss: 0.9498089\n",
      "Iter 24 Batch 13 / 22 Loss: 0.81278914\n",
      "Iter 24 Batch 14 / 22 Loss: 0.9121859\n",
      "Iter 24 Batch 15 / 22 Loss: 0.61281717\n",
      "Iter 24 Batch 16 / 22 Loss: 0.59562564\n",
      "Iter 24 Batch 17 / 22 Loss: 0.72977513\n",
      "Iter 24 Batch 18 / 22 Loss: 0.6982294\n",
      "Iter 24 Batch 19 / 22 Loss: 0.85566497\n",
      "Iter 24 Batch 20 / 22 Loss: 1.0480955\n",
      "Iter 24 Batch 21 / 22 Loss: 0.8488124\n",
      "Iter 25 Batch 0 / 22 Loss: 0.9613738\n",
      "Iter 25 Batch 1 / 22 Loss: 1.0576692\n",
      "Iter 25 Batch 2 / 22 Loss: 0.7905155\n",
      "Iter 25 Batch 3 / 22 Loss: 0.34366423\n",
      "Iter 25 Batch 4 / 22 Loss: 0.52928793\n",
      "Iter 25 Batch 5 / 22 Loss: 0.56205714\n",
      "Iter 25 Batch 6 / 22 Loss: 1.2298212\n",
      "Iter 25 Batch 7 / 22 Loss: 0.59594434\n",
      "Iter 25 Batch 8 / 22 Loss: 0.8923236\n",
      "Iter 25 Batch 9 / 22 Loss: 0.69766223\n",
      "Iter 25 Batch 10 / 22 Loss: 0.90880007\n",
      "Iter 25 Batch 11 / 22 Loss: 1.2293909\n",
      "Iter 25 Batch 12 / 22 Loss: 0.9301857\n",
      "Iter 25 Batch 13 / 22 Loss: 0.81283146\n",
      "Iter 25 Batch 14 / 22 Loss: 0.9082421\n",
      "Iter 25 Batch 15 / 22 Loss: 0.5989911\n",
      "Iter 25 Batch 16 / 22 Loss: 0.60040987\n",
      "Iter 25 Batch 17 / 22 Loss: 0.62508255\n",
      "Iter 25 Batch 18 / 22 Loss: 0.7100527\n",
      "Iter 25 Batch 19 / 22 Loss: 0.83620596\n",
      "Iter 25 Batch 20 / 22 Loss: 1.0439925\n",
      "Iter 25 Batch 21 / 22 Loss: 0.8374798\n",
      "Iter 26 Batch 0 / 22 Loss: 0.9566676\n",
      "Iter 26 Batch 1 / 22 Loss: 1.0460341\n",
      "Iter 26 Batch 2 / 22 Loss: 0.79923236\n",
      "Iter 26 Batch 3 / 22 Loss: 0.33223313\n",
      "Iter 26 Batch 4 / 22 Loss: 0.5203723\n",
      "Iter 26 Batch 5 / 22 Loss: 0.55850583\n",
      "Iter 26 Batch 6 / 22 Loss: 1.2221082\n",
      "Iter 26 Batch 7 / 22 Loss: 0.59418476\n",
      "Iter 26 Batch 8 / 22 Loss: 0.8848443\n",
      "Iter 26 Batch 9 / 22 Loss: 0.7014103\n",
      "Iter 26 Batch 10 / 22 Loss: 0.89227915\n",
      "Iter 26 Batch 11 / 22 Loss: 1.2224731\n",
      "Iter 26 Batch 12 / 22 Loss: 0.9203002\n",
      "Iter 26 Batch 13 / 22 Loss: 0.80197847\n",
      "Iter 26 Batch 14 / 22 Loss: 0.9024135\n",
      "Iter 26 Batch 15 / 22 Loss: 0.54719424\n",
      "Iter 26 Batch 16 / 22 Loss: 0.57187897\n",
      "Iter 26 Batch 17 / 22 Loss: 0.70415545\n",
      "Iter 26 Batch 18 / 22 Loss: 0.70373595\n",
      "Iter 26 Batch 19 / 22 Loss: 0.84015447\n",
      "Iter 26 Batch 20 / 22 Loss: 1.0272683\n",
      "Iter 26 Batch 21 / 22 Loss: 0.8308523\n",
      "Iter 27 Batch 0 / 22 Loss: 0.9509474\n",
      "Iter 27 Batch 1 / 22 Loss: 1.0429168\n",
      "Iter 27 Batch 2 / 22 Loss: 0.7797017\n",
      "Iter 27 Batch 3 / 22 Loss: 0.3215706\n",
      "Iter 27 Batch 4 / 22 Loss: 0.50474936\n",
      "Iter 27 Batch 5 / 22 Loss: 0.56120855\n",
      "Iter 27 Batch 6 / 22 Loss: 1.2342867\n",
      "Iter 27 Batch 7 / 22 Loss: 0.5825796\n",
      "Iter 27 Batch 8 / 22 Loss: 0.86408144\n",
      "Iter 27 Batch 9 / 22 Loss: 0.6832551\n",
      "Iter 27 Batch 10 / 22 Loss: 0.87495136\n",
      "Iter 27 Batch 11 / 22 Loss: 1.2207611\n",
      "Iter 27 Batch 12 / 22 Loss: 0.92217004\n",
      "Iter 27 Batch 13 / 22 Loss: 0.7974695\n",
      "Iter 27 Batch 14 / 22 Loss: 0.9185836\n",
      "Iter 27 Batch 15 / 22 Loss: 0.44018754\n",
      "Iter 27 Batch 16 / 22 Loss: 0.5661536\n",
      "Iter 27 Batch 17 / 22 Loss: 0.69552505\n",
      "Iter 27 Batch 18 / 22 Loss: 0.69291425\n",
      "Iter 27 Batch 19 / 22 Loss: 0.8356871\n",
      "Iter 27 Batch 20 / 22 Loss: 1.0142065\n",
      "Iter 27 Batch 21 / 22 Loss: 0.8211316\n",
      "Iter 28 Batch 0 / 22 Loss: 0.94241637\n",
      "Iter 28 Batch 1 / 22 Loss: 1.0260314\n",
      "Iter 28 Batch 2 / 22 Loss: 0.76154625\n",
      "Iter 28 Batch 3 / 22 Loss: 0.312954\n",
      "Iter 28 Batch 4 / 22 Loss: 0.50452274\n",
      "Iter 28 Batch 5 / 22 Loss: 0.5667164\n",
      "Iter 28 Batch 6 / 22 Loss: 1.2171264\n",
      "Iter 28 Batch 7 / 22 Loss: 0.57401454\n",
      "Iter 28 Batch 8 / 22 Loss: 0.8829447\n",
      "Iter 28 Batch 9 / 22 Loss: 0.6812404\n",
      "Iter 28 Batch 10 / 22 Loss: 0.8756358\n",
      "Iter 28 Batch 11 / 22 Loss: 1.2064255\n",
      "Iter 28 Batch 12 / 22 Loss: 0.91353595\n",
      "Iter 28 Batch 13 / 22 Loss: 0.78324187\n",
      "Iter 28 Batch 14 / 22 Loss: 0.89115536\n",
      "Iter 28 Batch 15 / 22 Loss: 0.42823976\n",
      "Iter 28 Batch 16 / 22 Loss: 0.57221615\n",
      "Iter 28 Batch 17 / 22 Loss: 0.81895787\n",
      "Iter 28 Batch 18 / 22 Loss: 0.7070605\n",
      "Iter 28 Batch 19 / 22 Loss: 0.8288034\n",
      "Iter 28 Batch 20 / 22 Loss: 1.0204856\n",
      "Iter 28 Batch 21 / 22 Loss: 0.8075333\n",
      "Iter 29 Batch 0 / 22 Loss: 0.93300354\n",
      "Iter 29 Batch 1 / 22 Loss: 1.0235114\n",
      "Iter 29 Batch 2 / 22 Loss: 0.7356773\n",
      "Iter 29 Batch 3 / 22 Loss: 0.31142595\n",
      "Iter 29 Batch 4 / 22 Loss: 0.49312323\n",
      "Iter 29 Batch 5 / 22 Loss: 0.5739661\n",
      "Iter 29 Batch 6 / 22 Loss: 1.2254951\n",
      "Iter 29 Batch 7 / 22 Loss: 0.5634184\n",
      "Iter 29 Batch 8 / 22 Loss: 0.8578634\n",
      "Iter 29 Batch 9 / 22 Loss: 0.6533303\n",
      "Iter 29 Batch 10 / 22 Loss: 0.8541441\n",
      "Iter 29 Batch 11 / 22 Loss: 1.1834328\n",
      "Iter 29 Batch 12 / 22 Loss: 0.9065434\n",
      "Iter 29 Batch 13 / 22 Loss: 0.7785688\n",
      "Iter 29 Batch 14 / 22 Loss: 0.9035164\n",
      "Iter 29 Batch 15 / 22 Loss: 0.40300438\n",
      "Iter 29 Batch 16 / 22 Loss: 0.56050146\n",
      "Iter 29 Batch 17 / 22 Loss: 0.7178514\n",
      "Iter 29 Batch 18 / 22 Loss: 0.7054473\n",
      "Iter 29 Batch 19 / 22 Loss: 0.8380739\n",
      "Iter 29 Batch 20 / 22 Loss: 0.9915187\n",
      "Iter 29 Batch 21 / 22 Loss: 0.7899806\n",
      "Iter 30 Batch 0 / 22 Loss: 0.9340063\n",
      "Iter 30 Batch 1 / 22 Loss: 1.0224541\n",
      "Iter 30 Batch 2 / 22 Loss: 0.73076725\n",
      "Iter 30 Batch 3 / 22 Loss: 0.30958253\n",
      "Iter 30 Batch 4 / 22 Loss: 0.4869233\n",
      "Iter 30 Batch 5 / 22 Loss: 0.58005273\n",
      "Iter 30 Batch 6 / 22 Loss: 1.2209365\n",
      "Iter 30 Batch 7 / 22 Loss: 0.5477956\n",
      "Iter 30 Batch 8 / 22 Loss: 0.8524365\n",
      "Iter 30 Batch 9 / 22 Loss: 0.64665186\n",
      "Iter 30 Batch 10 / 22 Loss: 0.8473173\n",
      "Iter 30 Batch 11 / 22 Loss: 1.185049\n",
      "Iter 30 Batch 12 / 22 Loss: 0.89479256\n",
      "Iter 30 Batch 13 / 22 Loss: 0.77261555\n",
      "Iter 30 Batch 14 / 22 Loss: 0.903539\n",
      "Iter 30 Batch 15 / 22 Loss: 0.3931616\n",
      "Iter 30 Batch 16 / 22 Loss: 0.5536163\n",
      "Iter 30 Batch 17 / 22 Loss: 0.6376905\n",
      "Iter 30 Batch 18 / 22 Loss: 0.69354296\n",
      "Iter 30 Batch 19 / 22 Loss: 0.8403938\n",
      "Iter 30 Batch 20 / 22 Loss: 0.97741336\n",
      "Iter 30 Batch 21 / 22 Loss: 0.7874893\n",
      "Iter 31 Batch 0 / 22 Loss: 0.92727387\n",
      "Iter 31 Batch 1 / 22 Loss: 1.0056407\n",
      "Iter 31 Batch 2 / 22 Loss: 0.7235521\n",
      "Iter 31 Batch 3 / 22 Loss: 0.30655208\n",
      "Iter 31 Batch 4 / 22 Loss: 0.48404136\n",
      "Iter 31 Batch 5 / 22 Loss: 0.577905\n",
      "Iter 31 Batch 6 / 22 Loss: 1.2173009\n",
      "Iter 31 Batch 7 / 22 Loss: 0.5373533\n",
      "Iter 31 Batch 8 / 22 Loss: 0.85733795\n",
      "Iter 31 Batch 9 / 22 Loss: 0.64193124\n",
      "Iter 31 Batch 10 / 22 Loss: 0.8388674\n",
      "Iter 31 Batch 11 / 22 Loss: 1.1780893\n",
      "Iter 31 Batch 12 / 22 Loss: 0.89291763\n",
      "Iter 31 Batch 13 / 22 Loss: 0.76515377\n",
      "Iter 31 Batch 14 / 22 Loss: 0.89134735\n",
      "Iter 31 Batch 15 / 22 Loss: 0.39346105\n",
      "Iter 31 Batch 16 / 22 Loss: 0.5526696\n",
      "Iter 31 Batch 17 / 22 Loss: 0.58560264\n",
      "Iter 31 Batch 18 / 22 Loss: 0.6847967\n",
      "Iter 31 Batch 19 / 22 Loss: 0.81357306\n",
      "Iter 31 Batch 20 / 22 Loss: 0.9723136\n",
      "Iter 31 Batch 21 / 22 Loss: 0.76153195\n",
      "Iter 32 Batch 0 / 22 Loss: 0.9191116\n",
      "Iter 32 Batch 1 / 22 Loss: 0.9964793\n",
      "Iter 32 Batch 2 / 22 Loss: 0.7201159\n",
      "Iter 32 Batch 3 / 22 Loss: 0.30378428\n",
      "Iter 32 Batch 4 / 22 Loss: 0.4767977\n",
      "Iter 32 Batch 5 / 22 Loss: 0.5811366\n",
      "Iter 32 Batch 6 / 22 Loss: 1.2147812\n",
      "Iter 32 Batch 7 / 22 Loss: 0.5350958\n",
      "Iter 32 Batch 8 / 22 Loss: 0.82792\n",
      "Iter 32 Batch 9 / 22 Loss: 0.63644683\n",
      "Iter 32 Batch 10 / 22 Loss: 0.8303388\n",
      "Iter 32 Batch 11 / 22 Loss: 1.177326\n",
      "Iter 32 Batch 12 / 22 Loss: 0.8851739\n",
      "Iter 32 Batch 13 / 22 Loss: 0.7590494\n",
      "Iter 32 Batch 14 / 22 Loss: 0.8895523\n",
      "Iter 32 Batch 15 / 22 Loss: 0.39370722\n",
      "Iter 32 Batch 16 / 22 Loss: 0.5438857\n",
      "Iter 32 Batch 17 / 22 Loss: 0.5695881\n",
      "Iter 32 Batch 18 / 22 Loss: 0.6638326\n",
      "Iter 32 Batch 19 / 22 Loss: 0.81160444\n",
      "Iter 32 Batch 20 / 22 Loss: 0.9571061\n",
      "Iter 32 Batch 21 / 22 Loss: 0.7459636\n",
      "Iter 33 Batch 0 / 22 Loss: 0.9128989\n",
      "Iter 33 Batch 1 / 22 Loss: 0.9880703\n",
      "Iter 33 Batch 2 / 22 Loss: 0.7188828\n",
      "Iter 33 Batch 3 / 22 Loss: 0.30211604\n",
      "Iter 33 Batch 4 / 22 Loss: 0.47558933\n",
      "Iter 33 Batch 5 / 22 Loss: 0.5805135\n",
      "Iter 33 Batch 6 / 22 Loss: 1.2044843\n",
      "Iter 33 Batch 7 / 22 Loss: 0.53298104\n",
      "Iter 33 Batch 8 / 22 Loss: 0.82635754\n",
      "Iter 33 Batch 9 / 22 Loss: 0.6222457\n",
      "Iter 33 Batch 10 / 22 Loss: 0.8264514\n",
      "Iter 33 Batch 11 / 22 Loss: 1.1775706\n",
      "Iter 33 Batch 12 / 22 Loss: 0.8818437\n",
      "Iter 33 Batch 13 / 22 Loss: 0.7524413\n",
      "Iter 33 Batch 14 / 22 Loss: 0.87906677\n",
      "Iter 33 Batch 15 / 22 Loss: 0.3935351\n",
      "Iter 33 Batch 16 / 22 Loss: 0.54048157\n",
      "Iter 33 Batch 17 / 22 Loss: 0.57436883\n",
      "Iter 33 Batch 18 / 22 Loss: 0.66921043\n",
      "Iter 33 Batch 19 / 22 Loss: 0.8246387\n",
      "Iter 33 Batch 20 / 22 Loss: 0.93905354\n",
      "Iter 33 Batch 21 / 22 Loss: 0.7361798\n",
      "Iter 34 Batch 0 / 22 Loss: 0.90502495\n",
      "Iter 34 Batch 1 / 22 Loss: 0.98711914\n",
      "Iter 34 Batch 2 / 22 Loss: 0.6988896\n",
      "Iter 34 Batch 3 / 22 Loss: 0.29832378\n",
      "Iter 34 Batch 4 / 22 Loss: 0.47042847\n",
      "Iter 34 Batch 5 / 22 Loss: 0.58448744\n",
      "Iter 34 Batch 6 / 22 Loss: 1.2387944\n",
      "Iter 34 Batch 7 / 22 Loss: 0.5149944\n",
      "Iter 34 Batch 8 / 22 Loss: 0.82245386\n",
      "Iter 34 Batch 9 / 22 Loss: 0.6222513\n",
      "Iter 34 Batch 10 / 22 Loss: 0.8201989\n",
      "Iter 34 Batch 11 / 22 Loss: 1.1723936\n",
      "Iter 34 Batch 12 / 22 Loss: 0.8834889\n",
      "Iter 34 Batch 13 / 22 Loss: 0.75003403\n",
      "Iter 34 Batch 14 / 22 Loss: 0.88584584\n",
      "Iter 34 Batch 15 / 22 Loss: 0.39259613\n",
      "Iter 34 Batch 16 / 22 Loss: 0.5357082\n",
      "Iter 34 Batch 17 / 22 Loss: 0.54929024\n",
      "Iter 34 Batch 18 / 22 Loss: 0.68924433\n",
      "Iter 34 Batch 19 / 22 Loss: 0.7979339\n",
      "Iter 34 Batch 20 / 22 Loss: 0.9443351\n",
      "Iter 34 Batch 21 / 22 Loss: 0.7276381\n",
      "Iter 35 Batch 0 / 22 Loss: 0.9029268\n",
      "Iter 35 Batch 1 / 22 Loss: 0.9729959\n",
      "Iter 35 Batch 2 / 22 Loss: 0.7191136\n",
      "Iter 35 Batch 3 / 22 Loss: 0.29996052\n",
      "Iter 35 Batch 4 / 22 Loss: 0.46726173\n",
      "Iter 35 Batch 5 / 22 Loss: 0.56991935\n",
      "Iter 35 Batch 6 / 22 Loss: 1.2074836\n",
      "Iter 35 Batch 7 / 22 Loss: 0.5359135\n",
      "Iter 35 Batch 8 / 22 Loss: 0.82100147\n",
      "Iter 35 Batch 9 / 22 Loss: 0.6080525\n",
      "Iter 35 Batch 10 / 22 Loss: 0.81478167\n",
      "Iter 35 Batch 11 / 22 Loss: 1.1795732\n",
      "Iter 35 Batch 12 / 22 Loss: 0.86343193\n",
      "Iter 35 Batch 13 / 22 Loss: 0.7452522\n",
      "Iter 35 Batch 14 / 22 Loss: 0.88740647\n",
      "Iter 35 Batch 15 / 22 Loss: 0.39029676\n",
      "Iter 35 Batch 16 / 22 Loss: 0.5260805\n",
      "Iter 35 Batch 17 / 22 Loss: 0.5538711\n",
      "Iter 35 Batch 18 / 22 Loss: 0.6205054\n",
      "Iter 35 Batch 19 / 22 Loss: 0.81495976\n",
      "Iter 35 Batch 20 / 22 Loss: 0.92845356\n",
      "Iter 35 Batch 21 / 22 Loss: 0.7196015\n",
      "Iter 36 Batch 0 / 22 Loss: 0.8925765\n",
      "Iter 36 Batch 1 / 22 Loss: 0.96837837\n",
      "Iter 36 Batch 2 / 22 Loss: 0.6873331\n",
      "Iter 36 Batch 3 / 22 Loss: 0.29549617\n",
      "Iter 36 Batch 4 / 22 Loss: 0.46920627\n",
      "Iter 36 Batch 5 / 22 Loss: 0.57224953\n",
      "Iter 36 Batch 6 / 22 Loss: 1.2129304\n",
      "Iter 36 Batch 7 / 22 Loss: 0.52576876\n",
      "Iter 36 Batch 8 / 22 Loss: 0.829597\n",
      "Iter 36 Batch 9 / 22 Loss: 0.59430194\n",
      "Iter 36 Batch 10 / 22 Loss: 0.79973674\n",
      "Iter 36 Batch 11 / 22 Loss: 1.1633083\n",
      "Iter 36 Batch 12 / 22 Loss: 0.87178385\n",
      "Iter 36 Batch 13 / 22 Loss: 0.74898326\n",
      "Iter 36 Batch 14 / 22 Loss: 0.8728749\n",
      "Iter 36 Batch 15 / 22 Loss: 0.39138338\n",
      "Iter 36 Batch 16 / 22 Loss: 0.5243803\n",
      "Iter 36 Batch 17 / 22 Loss: 0.54276526\n",
      "Iter 36 Batch 18 / 22 Loss: 0.65732235\n",
      "Iter 36 Batch 19 / 22 Loss: 0.8093008\n",
      "Iter 36 Batch 20 / 22 Loss: 0.91984797\n",
      "Iter 36 Batch 21 / 22 Loss: 0.70851225\n",
      "Iter 37 Batch 0 / 22 Loss: 0.89576286\n",
      "Iter 37 Batch 1 / 22 Loss: 0.9692476\n",
      "Iter 37 Batch 2 / 22 Loss: 0.6889928\n",
      "Iter 37 Batch 3 / 22 Loss: 0.2945796\n",
      "Iter 37 Batch 4 / 22 Loss: 0.4544735\n",
      "Iter 37 Batch 5 / 22 Loss: 0.5742098\n",
      "Iter 37 Batch 6 / 22 Loss: 1.2366369\n",
      "Iter 37 Batch 7 / 22 Loss: 0.50323653\n",
      "Iter 37 Batch 8 / 22 Loss: 0.7914328\n",
      "Iter 37 Batch 9 / 22 Loss: 0.5974485\n",
      "Iter 37 Batch 10 / 22 Loss: 0.8028435\n",
      "Iter 37 Batch 11 / 22 Loss: 1.1727731\n",
      "Iter 37 Batch 12 / 22 Loss: 0.8607366\n",
      "Iter 37 Batch 13 / 22 Loss: 0.7369034\n",
      "Iter 37 Batch 14 / 22 Loss: 0.87230515\n",
      "Iter 37 Batch 15 / 22 Loss: 0.38815394\n",
      "Iter 37 Batch 16 / 22 Loss: 0.5125488\n",
      "Iter 37 Batch 17 / 22 Loss: 0.5378894\n",
      "Iter 37 Batch 18 / 22 Loss: 0.59009045\n",
      "Iter 37 Batch 19 / 22 Loss: 0.7977536\n",
      "Iter 37 Batch 20 / 22 Loss: 0.92423165\n",
      "Iter 37 Batch 21 / 22 Loss: 0.71300626\n",
      "Iter 38 Batch 0 / 22 Loss: 0.8847767\n",
      "Iter 38 Batch 1 / 22 Loss: 0.95635486\n",
      "Iter 38 Batch 2 / 22 Loss: 0.6959835\n",
      "Iter 38 Batch 3 / 22 Loss: 0.29416502\n",
      "Iter 38 Batch 4 / 22 Loss: 0.45656163\n",
      "Iter 38 Batch 5 / 22 Loss: 0.5642492\n",
      "Iter 38 Batch 6 / 22 Loss: 1.2204553\n",
      "Iter 38 Batch 7 / 22 Loss: 0.5011114\n",
      "Iter 38 Batch 8 / 22 Loss: 0.79023135\n",
      "Iter 38 Batch 9 / 22 Loss: 0.58380294\n",
      "Iter 38 Batch 10 / 22 Loss: 0.7818322\n",
      "Iter 38 Batch 11 / 22 Loss: 1.1630058\n",
      "Iter 38 Batch 12 / 22 Loss: 0.832747\n",
      "Iter 38 Batch 13 / 22 Loss: 0.732708\n",
      "Iter 38 Batch 14 / 22 Loss: 0.87143165\n",
      "Iter 38 Batch 15 / 22 Loss: 0.3949259\n",
      "Iter 38 Batch 16 / 22 Loss: 0.50926834\n",
      "Iter 38 Batch 17 / 22 Loss: 0.5341423\n",
      "Iter 38 Batch 18 / 22 Loss: 0.57228625\n",
      "Iter 38 Batch 19 / 22 Loss: 0.8037689\n",
      "Iter 38 Batch 20 / 22 Loss: 0.9154855\n",
      "Iter 38 Batch 21 / 22 Loss: 0.69535804\n",
      "Iter 39 Batch 0 / 22 Loss: 0.882202\n",
      "Iter 39 Batch 1 / 22 Loss: 0.95804036\n",
      "Iter 39 Batch 2 / 22 Loss: 0.6785543\n",
      "Iter 39 Batch 3 / 22 Loss: 0.29391342\n",
      "Iter 39 Batch 4 / 22 Loss: 0.45628947\n",
      "Iter 39 Batch 5 / 22 Loss: 0.5626377\n",
      "Iter 39 Batch 6 / 22 Loss: 1.209996\n",
      "Iter 39 Batch 7 / 22 Loss: 0.5008268\n",
      "Iter 39 Batch 8 / 22 Loss: 0.78348905\n",
      "Iter 39 Batch 9 / 22 Loss: 0.5803159\n",
      "Iter 39 Batch 10 / 22 Loss: 0.77887195\n",
      "Iter 39 Batch 11 / 22 Loss: 1.1660949\n",
      "Iter 39 Batch 12 / 22 Loss: 0.82534623\n",
      "Iter 39 Batch 13 / 22 Loss: 0.728482\n",
      "Iter 39 Batch 14 / 22 Loss: 0.8610916\n",
      "Iter 39 Batch 15 / 22 Loss: 0.393665\n",
      "Iter 39 Batch 16 / 22 Loss: 0.5186459\n",
      "Iter 39 Batch 17 / 22 Loss: 0.5278628\n",
      "Iter 39 Batch 18 / 22 Loss: 0.54927105\n",
      "Iter 39 Batch 19 / 22 Loss: 0.8164231\n",
      "Iter 39 Batch 20 / 22 Loss: 0.8990599\n",
      "Iter 39 Batch 21 / 22 Loss: 0.6892431\n",
      "Iter 40 Batch 0 / 22 Loss: 0.87882274\n",
      "Iter 40 Batch 1 / 22 Loss: 0.9469898\n",
      "Iter 40 Batch 2 / 22 Loss: 0.66222674\n",
      "Iter 40 Batch 3 / 22 Loss: 0.2915452\n",
      "Iter 40 Batch 4 / 22 Loss: 0.45041376\n",
      "Iter 40 Batch 5 / 22 Loss: 0.5675402\n",
      "Iter 40 Batch 6 / 22 Loss: 1.2175717\n",
      "Iter 40 Batch 7 / 22 Loss: 0.4934147\n",
      "Iter 40 Batch 8 / 22 Loss: 0.7928177\n",
      "Iter 40 Batch 9 / 22 Loss: 0.5648229\n",
      "Iter 40 Batch 10 / 22 Loss: 0.7701058\n",
      "Iter 40 Batch 11 / 22 Loss: 1.1524643\n",
      "Iter 40 Batch 12 / 22 Loss: 0.79141545\n",
      "Iter 40 Batch 13 / 22 Loss: 0.7216366\n",
      "Iter 40 Batch 14 / 22 Loss: 0.851894\n",
      "Iter 40 Batch 15 / 22 Loss: 0.39175195\n",
      "Iter 40 Batch 16 / 22 Loss: 0.52570254\n",
      "Iter 40 Batch 17 / 22 Loss: 0.52409756\n",
      "Iter 40 Batch 18 / 22 Loss: 0.5842241\n",
      "Iter 40 Batch 19 / 22 Loss: 0.8200903\n",
      "Iter 40 Batch 20 / 22 Loss: 0.89876986\n",
      "Iter 40 Batch 21 / 22 Loss: 0.6836937\n",
      "Iter 41 Batch 0 / 22 Loss: 0.88105965\n",
      "Iter 41 Batch 1 / 22 Loss: 0.9672875\n",
      "Iter 41 Batch 2 / 22 Loss: 0.65447116\n",
      "Iter 41 Batch 3 / 22 Loss: 0.29156834\n",
      "Iter 41 Batch 4 / 22 Loss: 0.46445808\n",
      "Iter 41 Batch 5 / 22 Loss: 0.6261023\n",
      "Iter 41 Batch 6 / 22 Loss: 1.2517337\n",
      "Iter 41 Batch 7 / 22 Loss: 0.50401366\n",
      "Iter 41 Batch 8 / 22 Loss: 0.78287715\n",
      "Iter 41 Batch 9 / 22 Loss: 0.56785655\n",
      "Iter 41 Batch 10 / 22 Loss: 0.78513736\n",
      "Iter 41 Batch 11 / 22 Loss: 1.1534258\n",
      "Iter 41 Batch 12 / 22 Loss: 0.8038985\n",
      "Iter 41 Batch 13 / 22 Loss: 0.7313107\n",
      "Iter 41 Batch 14 / 22 Loss: 0.8590871\n",
      "Iter 41 Batch 15 / 22 Loss: 0.39382917\n",
      "Iter 41 Batch 16 / 22 Loss: 0.49746397\n",
      "Iter 41 Batch 17 / 22 Loss: 0.5233396\n",
      "Iter 41 Batch 18 / 22 Loss: 0.6299467\n",
      "Iter 41 Batch 19 / 22 Loss: 0.78649205\n",
      "Iter 41 Batch 20 / 22 Loss: 0.9089724\n",
      "Iter 41 Batch 21 / 22 Loss: 0.72049475\n",
      "Iter 42 Batch 0 / 22 Loss: 0.8764848\n",
      "Iter 42 Batch 1 / 22 Loss: 0.92568684\n",
      "Iter 42 Batch 2 / 22 Loss: 0.695728\n",
      "Iter 42 Batch 3 / 22 Loss: 0.2927425\n",
      "Iter 42 Batch 4 / 22 Loss: 0.4413448\n",
      "Iter 42 Batch 5 / 22 Loss: 0.5586705\n",
      "Iter 42 Batch 6 / 22 Loss: 1.2177101\n",
      "Iter 42 Batch 7 / 22 Loss: 0.48919284\n",
      "Iter 42 Batch 8 / 22 Loss: 0.7762016\n",
      "Iter 42 Batch 9 / 22 Loss: 0.5457583\n",
      "Iter 42 Batch 10 / 22 Loss: 0.7598494\n",
      "Iter 42 Batch 11 / 22 Loss: 1.1648414\n",
      "Iter 42 Batch 12 / 22 Loss: 0.8064915\n",
      "Iter 42 Batch 13 / 22 Loss: 0.7222184\n",
      "Iter 42 Batch 14 / 22 Loss: 0.8775671\n",
      "Iter 42 Batch 15 / 22 Loss: 0.40016657\n",
      "Iter 42 Batch 16 / 22 Loss: 0.4762719\n",
      "Iter 42 Batch 17 / 22 Loss: 0.50928795\n",
      "Iter 42 Batch 18 / 22 Loss: 0.5867259\n",
      "Iter 42 Batch 19 / 22 Loss: 0.7859953\n",
      "Iter 42 Batch 20 / 22 Loss: 0.9037128\n",
      "Iter 42 Batch 21 / 22 Loss: 0.6828666\n",
      "Iter 43 Batch 0 / 22 Loss: 0.88061553\n",
      "Iter 43 Batch 1 / 22 Loss: 0.9236659\n",
      "Iter 43 Batch 2 / 22 Loss: 0.74908984\n",
      "Iter 43 Batch 3 / 22 Loss: 0.3006979\n",
      "Iter 43 Batch 4 / 22 Loss: 0.4434111\n",
      "Iter 43 Batch 5 / 22 Loss: 0.55588734\n",
      "Iter 43 Batch 6 / 22 Loss: 1.1909144\n",
      "Iter 43 Batch 7 / 22 Loss: 0.5347881\n",
      "Iter 43 Batch 8 / 22 Loss: 0.7954224\n",
      "Iter 43 Batch 9 / 22 Loss: 0.5586839\n",
      "Iter 43 Batch 10 / 22 Loss: 0.74571097\n",
      "Iter 43 Batch 11 / 22 Loss: 1.2063541\n",
      "Iter 43 Batch 12 / 22 Loss: 0.73227024\n",
      "Iter 43 Batch 13 / 22 Loss: 0.7228479\n",
      "Iter 43 Batch 14 / 22 Loss: 0.8692483\n",
      "Iter 43 Batch 15 / 22 Loss: 0.41573977\n",
      "Iter 43 Batch 16 / 22 Loss: 0.5074484\n",
      "Iter 43 Batch 17 / 22 Loss: 0.5055372\n",
      "Iter 43 Batch 18 / 22 Loss: 0.5789089\n",
      "Iter 43 Batch 19 / 22 Loss: 0.8255029\n",
      "Iter 43 Batch 20 / 22 Loss: 0.88844424\n",
      "Iter 43 Batch 21 / 22 Loss: 0.68859375\n",
      "Iter 44 Batch 0 / 22 Loss: 0.8683501\n",
      "Iter 44 Batch 1 / 22 Loss: 0.93676186\n",
      "Iter 44 Batch 2 / 22 Loss: 0.66576093\n",
      "Iter 44 Batch 3 / 22 Loss: 0.28739417\n",
      "Iter 44 Batch 4 / 22 Loss: 0.44424862\n",
      "Iter 44 Batch 5 / 22 Loss: 0.5494958\n",
      "Iter 44 Batch 6 / 22 Loss: 1.2277197\n",
      "Iter 44 Batch 7 / 22 Loss: 0.49040568\n",
      "Iter 44 Batch 8 / 22 Loss: 0.786769\n",
      "Iter 44 Batch 9 / 22 Loss: 0.56009513\n",
      "Iter 44 Batch 10 / 22 Loss: 0.72537875\n",
      "Iter 44 Batch 11 / 22 Loss: 1.1856282\n",
      "Iter 44 Batch 12 / 22 Loss: 0.71955305\n",
      "Iter 44 Batch 13 / 22 Loss: 0.7055298\n",
      "Iter 44 Batch 14 / 22 Loss: 0.8374058\n",
      "Iter 44 Batch 15 / 22 Loss: 0.39575475\n",
      "Iter 44 Batch 16 / 22 Loss: 0.5042106\n",
      "Iter 44 Batch 17 / 22 Loss: 0.515908\n",
      "Iter 44 Batch 18 / 22 Loss: 0.52746207\n",
      "Iter 44 Batch 19 / 22 Loss: 0.79399043\n",
      "Iter 44 Batch 20 / 22 Loss: 0.9025861\n",
      "Iter 44 Batch 21 / 22 Loss: 0.72583145\n",
      "Iter 45 Batch 0 / 22 Loss: 0.86899436\n",
      "Iter 45 Batch 1 / 22 Loss: 0.93602383\n",
      "Iter 45 Batch 2 / 22 Loss: 0.67250353\n",
      "Iter 45 Batch 3 / 22 Loss: 0.28770146\n",
      "Iter 45 Batch 4 / 22 Loss: 0.42972445\n",
      "Iter 45 Batch 5 / 22 Loss: 0.5450761\n",
      "Iter 45 Batch 6 / 22 Loss: 1.2247789\n",
      "Iter 45 Batch 7 / 22 Loss: 0.48043248\n",
      "Iter 45 Batch 8 / 22 Loss: 0.766269\n",
      "Iter 45 Batch 9 / 22 Loss: 0.54735094\n",
      "Iter 45 Batch 10 / 22 Loss: 0.7152808\n",
      "Iter 45 Batch 11 / 22 Loss: 1.1566457\n",
      "Iter 45 Batch 12 / 22 Loss: 0.7089051\n",
      "Iter 45 Batch 13 / 22 Loss: 0.7013994\n",
      "Iter 45 Batch 14 / 22 Loss: 0.8418654\n",
      "Iter 45 Batch 15 / 22 Loss: 0.38228333\n",
      "Iter 45 Batch 16 / 22 Loss: 0.4755666\n",
      "Iter 45 Batch 17 / 22 Loss: 0.54166335\n",
      "Iter 45 Batch 18 / 22 Loss: 0.4980654\n",
      "Iter 45 Batch 19 / 22 Loss: 0.7867187\n",
      "Iter 45 Batch 20 / 22 Loss: 0.89258033\n",
      "Iter 45 Batch 21 / 22 Loss: 0.6857872\n",
      "Iter 46 Batch 0 / 22 Loss: 0.8594947\n",
      "Iter 46 Batch 1 / 22 Loss: 0.9190799\n",
      "Iter 46 Batch 2 / 22 Loss: 0.6491021\n",
      "Iter 46 Batch 3 / 22 Loss: 0.2871706\n",
      "Iter 46 Batch 4 / 22 Loss: 0.42990807\n",
      "Iter 46 Batch 5 / 22 Loss: 0.540467\n",
      "Iter 46 Batch 6 / 22 Loss: 1.207789\n",
      "Iter 46 Batch 7 / 22 Loss: 0.48035234\n",
      "Iter 46 Batch 8 / 22 Loss: 0.7680539\n",
      "Iter 46 Batch 9 / 22 Loss: 0.5312053\n",
      "Iter 46 Batch 10 / 22 Loss: 0.71628994\n",
      "Iter 46 Batch 11 / 22 Loss: 1.1528924\n",
      "Iter 46 Batch 12 / 22 Loss: 0.73419327\n",
      "Iter 46 Batch 13 / 22 Loss: 0.6999743\n",
      "Iter 46 Batch 14 / 22 Loss: 0.83661914\n",
      "Iter 46 Batch 15 / 22 Loss: 0.41583112\n",
      "Iter 46 Batch 16 / 22 Loss: 0.48938656\n",
      "Iter 46 Batch 17 / 22 Loss: 0.60568523\n",
      "Iter 46 Batch 18 / 22 Loss: 0.51359123\n",
      "Iter 46 Batch 19 / 22 Loss: 0.78035414\n",
      "Iter 46 Batch 20 / 22 Loss: 0.8751223\n",
      "Iter 46 Batch 21 / 22 Loss: 0.62596977\n",
      "Iter 47 Batch 0 / 22 Loss: 0.8595748\n",
      "Iter 47 Batch 1 / 22 Loss: 0.91206014\n",
      "Iter 47 Batch 2 / 22 Loss: 0.64181244\n",
      "Iter 47 Batch 3 / 22 Loss: 0.28131723\n",
      "Iter 47 Batch 4 / 22 Loss: 0.44063464\n",
      "Iter 47 Batch 5 / 22 Loss: 0.5660129\n",
      "Iter 47 Batch 6 / 22 Loss: 1.2134149\n",
      "Iter 47 Batch 7 / 22 Loss: 0.4777211\n",
      "Iter 47 Batch 8 / 22 Loss: 0.76701874\n",
      "Iter 47 Batch 9 / 22 Loss: 0.5192988\n",
      "Iter 47 Batch 10 / 22 Loss: 0.71746624\n",
      "Iter 47 Batch 11 / 22 Loss: 1.1425743\n",
      "Iter 47 Batch 12 / 22 Loss: 0.7176002\n",
      "Iter 47 Batch 13 / 22 Loss: 0.69294643\n",
      "Iter 47 Batch 14 / 22 Loss: 0.8297727\n",
      "Iter 47 Batch 15 / 22 Loss: 0.3886072\n",
      "Iter 47 Batch 16 / 22 Loss: 0.5280756\n",
      "Iter 47 Batch 17 / 22 Loss: 0.60059345\n",
      "Iter 47 Batch 18 / 22 Loss: 0.49416128\n",
      "Iter 47 Batch 19 / 22 Loss: 0.7755542\n",
      "Iter 47 Batch 20 / 22 Loss: 0.86796373\n",
      "Iter 47 Batch 21 / 22 Loss: 0.70575446\n",
      "Iter 48 Batch 0 / 22 Loss: 0.85461736\n",
      "Iter 48 Batch 1 / 22 Loss: 0.89912575\n",
      "Iter 48 Batch 2 / 22 Loss: 0.6527914\n",
      "Iter 48 Batch 3 / 22 Loss: 0.28608447\n",
      "Iter 48 Batch 4 / 22 Loss: 0.42367625\n",
      "Iter 48 Batch 5 / 22 Loss: 0.5458174\n",
      "Iter 48 Batch 6 / 22 Loss: 1.2075167\n",
      "Iter 48 Batch 7 / 22 Loss: 0.4690069\n",
      "Iter 48 Batch 8 / 22 Loss: 0.7606802\n",
      "Iter 48 Batch 9 / 22 Loss: 0.5438478\n",
      "Iter 48 Batch 10 / 22 Loss: 0.68219197\n",
      "Iter 48 Batch 11 / 22 Loss: 1.1559004\n",
      "Iter 48 Batch 12 / 22 Loss: 0.687556\n",
      "Iter 48 Batch 13 / 22 Loss: 0.68386316\n",
      "Iter 48 Batch 14 / 22 Loss: 0.83099174\n",
      "Iter 48 Batch 15 / 22 Loss: 0.39438426\n",
      "Iter 48 Batch 16 / 22 Loss: 0.48883566\n",
      "Iter 48 Batch 17 / 22 Loss: 0.62803394\n",
      "Iter 48 Batch 18 / 22 Loss: 0.4753843\n",
      "Iter 48 Batch 19 / 22 Loss: 0.76201147\n",
      "Iter 48 Batch 20 / 22 Loss: 0.9340645\n",
      "Iter 48 Batch 21 / 22 Loss: 0.70853686\n",
      "Iter 49 Batch 0 / 22 Loss: 0.8559551\n",
      "Iter 49 Batch 1 / 22 Loss: 0.89694375\n",
      "Iter 49 Batch 2 / 22 Loss: 0.6484792\n",
      "Iter 49 Batch 3 / 22 Loss: 0.28416264\n",
      "Iter 49 Batch 4 / 22 Loss: 0.41957057\n",
      "Iter 49 Batch 5 / 22 Loss: 0.52567935\n",
      "Iter 49 Batch 6 / 22 Loss: 1.2107087\n",
      "Iter 49 Batch 7 / 22 Loss: 0.46528018\n",
      "Iter 49 Batch 8 / 22 Loss: 0.7681812\n",
      "Iter 49 Batch 9 / 22 Loss: 0.5209471\n",
      "Iter 49 Batch 10 / 22 Loss: 0.6965348\n",
      "Iter 49 Batch 11 / 22 Loss: 1.1422079\n",
      "Iter 49 Batch 12 / 22 Loss: 0.71388304\n",
      "Iter 49 Batch 13 / 22 Loss: 0.67683244\n",
      "Iter 49 Batch 14 / 22 Loss: 0.8383896\n",
      "Iter 49 Batch 15 / 22 Loss: 0.38738838\n",
      "Iter 49 Batch 16 / 22 Loss: 0.54898363\n",
      "Iter 49 Batch 17 / 22 Loss: 0.58357453\n",
      "Iter 49 Batch 18 / 22 Loss: 0.474573\n",
      "Iter 49 Batch 19 / 22 Loss: 0.7747244\n",
      "Iter 49 Batch 20 / 22 Loss: 0.8675431\n",
      "Iter 49 Batch 21 / 22 Loss: 0.67988384\n",
      "Iter 50 Batch 0 / 22 Loss: 0.8512654\n",
      "Iter 50 Batch 1 / 22 Loss: 0.8950387\n",
      "Iter 50 Batch 2 / 22 Loss: 0.62994194\n",
      "Iter 50 Batch 3 / 22 Loss: 0.27903616\n",
      "Iter 50 Batch 4 / 22 Loss: 0.41633278\n",
      "Iter 50 Batch 5 / 22 Loss: 0.54225034\n",
      "Iter 50 Batch 6 / 22 Loss: 1.2161975\n",
      "Iter 50 Batch 7 / 22 Loss: 0.45964578\n",
      "Iter 50 Batch 8 / 22 Loss: 0.7529909\n",
      "Iter 50 Batch 9 / 22 Loss: 0.53282624\n",
      "Iter 50 Batch 10 / 22 Loss: 0.66879475\n",
      "Iter 50 Batch 11 / 22 Loss: 1.1760948\n",
      "Iter 50 Batch 12 / 22 Loss: 0.6995652\n",
      "Iter 50 Batch 13 / 22 Loss: 0.6797396\n",
      "Iter 50 Batch 14 / 22 Loss: 0.82258004\n",
      "Iter 50 Batch 15 / 22 Loss: 0.40911278\n",
      "Iter 50 Batch 16 / 22 Loss: 0.49543837\n",
      "Iter 50 Batch 17 / 22 Loss: 0.56683546\n",
      "Iter 50 Batch 18 / 22 Loss: 0.467887\n",
      "Iter 50 Batch 19 / 22 Loss: 0.76271987\n",
      "Iter 50 Batch 20 / 22 Loss: 0.8683923\n",
      "Iter 50 Batch 21 / 22 Loss: 0.6662623\n",
      "Iter 51 Batch 0 / 22 Loss: 0.8477702\n",
      "Iter 51 Batch 1 / 22 Loss: 0.8759794\n",
      "Iter 51 Batch 2 / 22 Loss: 0.6487566\n",
      "Iter 51 Batch 3 / 22 Loss: 0.27975976\n",
      "Iter 51 Batch 4 / 22 Loss: 0.41610178\n",
      "Iter 51 Batch 5 / 22 Loss: 0.53769135\n",
      "Iter 51 Batch 6 / 22 Loss: 1.1945845\n",
      "Iter 51 Batch 7 / 22 Loss: 0.46086633\n",
      "Iter 51 Batch 8 / 22 Loss: 0.7788141\n",
      "Iter 51 Batch 9 / 22 Loss: 0.4921149\n",
      "Iter 51 Batch 10 / 22 Loss: 0.693508\n",
      "Iter 51 Batch 11 / 22 Loss: 1.1425784\n",
      "Iter 51 Batch 12 / 22 Loss: 0.7042492\n",
      "Iter 51 Batch 13 / 22 Loss: 0.66697305\n",
      "Iter 51 Batch 14 / 22 Loss: 0.824851\n",
      "Iter 51 Batch 15 / 22 Loss: 0.5463042\n",
      "Iter 51 Batch 16 / 22 Loss: 0.51359266\n",
      "Iter 51 Batch 17 / 22 Loss: 0.54629105\n",
      "Iter 51 Batch 18 / 22 Loss: 0.48613197\n",
      "Iter 51 Batch 19 / 22 Loss: 0.7422515\n",
      "Iter 51 Batch 20 / 22 Loss: 0.8528936\n",
      "Iter 51 Batch 21 / 22 Loss: 0.6555222\n",
      "Iter 52 Batch 0 / 22 Loss: 0.8513281\n",
      "Iter 52 Batch 1 / 22 Loss: 0.8715427\n",
      "Iter 52 Batch 2 / 22 Loss: 0.6405958\n",
      "Iter 52 Batch 3 / 22 Loss: 0.28874898\n",
      "Iter 52 Batch 4 / 22 Loss: 0.41295555\n",
      "Iter 52 Batch 5 / 22 Loss: 0.50984323\n",
      "Iter 52 Batch 6 / 22 Loss: 1.2106645\n",
      "Iter 52 Batch 7 / 22 Loss: 0.49707985\n",
      "Iter 52 Batch 8 / 22 Loss: 0.7880266\n",
      "Iter 52 Batch 9 / 22 Loss: 0.5295421\n",
      "Iter 52 Batch 10 / 22 Loss: 0.6811312\n",
      "Iter 52 Batch 11 / 22 Loss: 1.17736\n",
      "Iter 52 Batch 12 / 22 Loss: 0.68585527\n",
      "Iter 52 Batch 13 / 22 Loss: 0.66777813\n",
      "Iter 52 Batch 14 / 22 Loss: 0.8507656\n",
      "Iter 52 Batch 15 / 22 Loss: 0.51074356\n",
      "Iter 52 Batch 16 / 22 Loss: 0.4630192\n",
      "Iter 52 Batch 17 / 22 Loss: 0.5116363\n",
      "Iter 52 Batch 18 / 22 Loss: 0.48142996\n",
      "Iter 52 Batch 19 / 22 Loss: 0.74422103\n",
      "Iter 52 Batch 20 / 22 Loss: 0.87904453\n",
      "Iter 52 Batch 21 / 22 Loss: 0.6461009\n",
      "Iter 53 Batch 0 / 22 Loss: 0.8546104\n",
      "Iter 53 Batch 1 / 22 Loss: 0.86604965\n",
      "Iter 53 Batch 2 / 22 Loss: 0.6202673\n",
      "Iter 53 Batch 3 / 22 Loss: 0.27666456\n",
      "Iter 53 Batch 4 / 22 Loss: 0.40706602\n",
      "Iter 53 Batch 5 / 22 Loss: 0.5291484\n",
      "Iter 53 Batch 6 / 22 Loss: 1.1965461\n",
      "Iter 53 Batch 7 / 22 Loss: 0.45484865\n",
      "Iter 53 Batch 8 / 22 Loss: 0.7551241\n",
      "Iter 53 Batch 9 / 22 Loss: 0.4984392\n",
      "Iter 53 Batch 10 / 22 Loss: 0.6707716\n",
      "Iter 53 Batch 11 / 22 Loss: 1.1478378\n",
      "Iter 53 Batch 12 / 22 Loss: 0.6760545\n",
      "Iter 53 Batch 13 / 22 Loss: 0.6667204\n",
      "Iter 53 Batch 14 / 22 Loss: 0.8504845\n",
      "Iter 53 Batch 15 / 22 Loss: 0.42347464\n",
      "Iter 53 Batch 16 / 22 Loss: 0.45546123\n",
      "Iter 53 Batch 17 / 22 Loss: 0.487569\n",
      "Iter 53 Batch 18 / 22 Loss: 0.45980364\n",
      "Iter 53 Batch 19 / 22 Loss: 0.7588815\n",
      "Iter 53 Batch 20 / 22 Loss: 0.9919462\n",
      "Iter 53 Batch 21 / 22 Loss: 0.6668165\n",
      "Iter 54 Batch 0 / 22 Loss: 0.8596465\n",
      "Iter 54 Batch 1 / 22 Loss: 0.9275084\n",
      "Iter 54 Batch 2 / 22 Loss: 0.6174495\n",
      "Iter 54 Batch 3 / 22 Loss: 0.27799422\n",
      "Iter 54 Batch 4 / 22 Loss: 0.5632897\n",
      "Iter 54 Batch 5 / 22 Loss: 0.5348621\n",
      "Iter 54 Batch 6 / 22 Loss: 1.2523882\n",
      "Iter 54 Batch 7 / 22 Loss: 0.81381726\n",
      "Iter 54 Batch 8 / 22 Loss: 0.78330636\n",
      "Iter 54 Batch 9 / 22 Loss: 0.5725402\n",
      "Iter 54 Batch 10 / 22 Loss: 0.66666746\n",
      "Iter 54 Batch 11 / 22 Loss: 1.1840703\n",
      "Iter 54 Batch 12 / 22 Loss: 0.9136174\n",
      "Iter 54 Batch 13 / 22 Loss: 0.9834577\n",
      "Iter 54 Batch 14 / 22 Loss: 0.87373483\n",
      "Iter 54 Batch 15 / 22 Loss: 0.43774018\n",
      "Iter 54 Batch 16 / 22 Loss: 0.6536241\n",
      "Iter 54 Batch 17 / 22 Loss: 0.5969434\n",
      "Iter 54 Batch 18 / 22 Loss: 0.6319364\n",
      "Iter 54 Batch 19 / 22 Loss: 0.7406104\n",
      "Iter 54 Batch 20 / 22 Loss: 0.94096625\n",
      "Iter 54 Batch 21 / 22 Loss: 0.66292024\n",
      "Iter 55 Batch 0 / 22 Loss: 0.85763377\n",
      "Iter 55 Batch 1 / 22 Loss: 0.8780503\n",
      "Iter 55 Batch 2 / 22 Loss: 0.72907597\n",
      "Iter 55 Batch 3 / 22 Loss: 0.28724754\n",
      "Iter 55 Batch 4 / 22 Loss: 0.4044591\n",
      "Iter 55 Batch 5 / 22 Loss: 0.52068216\n",
      "Iter 55 Batch 6 / 22 Loss: 1.201284\n",
      "Iter 55 Batch 7 / 22 Loss: 0.4857232\n",
      "Iter 55 Batch 8 / 22 Loss: 0.8369341\n",
      "Iter 55 Batch 9 / 22 Loss: 0.52397674\n",
      "Iter 55 Batch 10 / 22 Loss: 0.68742555\n",
      "Iter 55 Batch 11 / 22 Loss: 1.257396\n",
      "Iter 55 Batch 12 / 22 Loss: 0.6518644\n",
      "Iter 55 Batch 13 / 22 Loss: 0.6421983\n",
      "Iter 55 Batch 14 / 22 Loss: 0.9912613\n",
      "Iter 55 Batch 15 / 22 Loss: 0.43396294\n",
      "Iter 55 Batch 16 / 22 Loss: 0.77107227\n",
      "Iter 55 Batch 17 / 22 Loss: 0.99499786\n",
      "Iter 55 Batch 18 / 22 Loss: 0.5968989\n",
      "Iter 55 Batch 19 / 22 Loss: 0.7208062\n",
      "Iter 55 Batch 20 / 22 Loss: 1.0820941\n",
      "Iter 55 Batch 21 / 22 Loss: 0.7695979\n",
      "Iter 56 Batch 0 / 22 Loss: 0.94587666\n",
      "Iter 56 Batch 1 / 22 Loss: 0.8848779\n",
      "Iter 56 Batch 2 / 22 Loss: 0.6977559\n",
      "Iter 56 Batch 3 / 22 Loss: 0.28173518\n",
      "Iter 56 Batch 4 / 22 Loss: 0.40672433\n",
      "Iter 56 Batch 5 / 22 Loss: 0.55310374\n",
      "Iter 56 Batch 6 / 22 Loss: 1.2167736\n",
      "Iter 56 Batch 7 / 22 Loss: 0.4676834\n",
      "Iter 56 Batch 8 / 22 Loss: 0.80860263\n",
      "Iter 56 Batch 9 / 22 Loss: 0.55403066\n",
      "Iter 56 Batch 10 / 22 Loss: 0.63580894\n",
      "Iter 56 Batch 11 / 22 Loss: 1.179018\n",
      "Iter 56 Batch 12 / 22 Loss: 0.76658374\n",
      "Iter 56 Batch 13 / 22 Loss: 0.646907\n",
      "Iter 56 Batch 14 / 22 Loss: 0.88360095\n",
      "Iter 56 Batch 15 / 22 Loss: 0.44630575\n",
      "Iter 56 Batch 16 / 22 Loss: 0.5249259\n",
      "Iter 56 Batch 17 / 22 Loss: 0.85242414\n",
      "Iter 56 Batch 18 / 22 Loss: 0.47751966\n",
      "Iter 56 Batch 19 / 22 Loss: 0.72174567\n",
      "Iter 56 Batch 20 / 22 Loss: 0.9697797\n",
      "Iter 56 Batch 21 / 22 Loss: 0.74118555\n",
      "Iter 57 Batch 0 / 22 Loss: 0.8747189\n",
      "Iter 57 Batch 1 / 22 Loss: 0.8587058\n",
      "Iter 57 Batch 2 / 22 Loss: 0.74561834\n",
      "Iter 57 Batch 3 / 22 Loss: 0.27593222\n",
      "Iter 57 Batch 4 / 22 Loss: 0.38550508\n",
      "Iter 57 Batch 5 / 22 Loss: 0.5334239\n",
      "Iter 57 Batch 6 / 22 Loss: 1.2028981\n",
      "Iter 57 Batch 7 / 22 Loss: 0.46122417\n",
      "Iter 57 Batch 8 / 22 Loss: 0.79962337\n",
      "Iter 57 Batch 9 / 22 Loss: 0.49908605\n",
      "Iter 57 Batch 10 / 22 Loss: 0.6277129\n",
      "Iter 57 Batch 11 / 22 Loss: 1.1699365\n",
      "Iter 57 Batch 12 / 22 Loss: 0.5821235\n",
      "Iter 57 Batch 13 / 22 Loss: 0.6314559\n",
      "Iter 57 Batch 14 / 22 Loss: 0.8434155\n",
      "Iter 57 Batch 15 / 22 Loss: 0.41143835\n",
      "Iter 57 Batch 16 / 22 Loss: 0.67735034\n",
      "Iter 57 Batch 17 / 22 Loss: 0.6329166\n",
      "Iter 57 Batch 18 / 22 Loss: 0.7905016\n",
      "Iter 57 Batch 19 / 22 Loss: 0.7282293\n",
      "Iter 57 Batch 20 / 22 Loss: 0.915861\n",
      "Iter 57 Batch 21 / 22 Loss: 0.7452986\n",
      "Iter 58 Batch 0 / 22 Loss: 0.9280878\n",
      "Iter 58 Batch 1 / 22 Loss: 0.8835709\n",
      "Iter 58 Batch 2 / 22 Loss: 0.638147\n",
      "Iter 58 Batch 3 / 22 Loss: 0.2754258\n",
      "Iter 58 Batch 4 / 22 Loss: 0.4195299\n",
      "Iter 58 Batch 5 / 22 Loss: 0.6436687\n",
      "Iter 58 Batch 6 / 22 Loss: 1.2991967\n",
      "Iter 58 Batch 7 / 22 Loss: 0.51777256\n",
      "Iter 58 Batch 8 / 22 Loss: 0.86674017\n",
      "Iter 58 Batch 9 / 22 Loss: 0.61169803\n",
      "Iter 58 Batch 10 / 22 Loss: 0.703853\n",
      "Iter 58 Batch 11 / 22 Loss: 1.1760696\n",
      "Iter 58 Batch 12 / 22 Loss: 0.8062871\n",
      "Iter 58 Batch 13 / 22 Loss: 0.6800246\n",
      "Iter 58 Batch 14 / 22 Loss: 0.90947944\n",
      "Iter 58 Batch 15 / 22 Loss: 0.4061677\n",
      "Iter 58 Batch 16 / 22 Loss: 0.5252891\n",
      "Iter 58 Batch 17 / 22 Loss: 0.6953957\n",
      "Iter 58 Batch 18 / 22 Loss: 0.6965883\n",
      "Iter 58 Batch 19 / 22 Loss: 0.7515087\n",
      "Iter 58 Batch 20 / 22 Loss: 0.90879965\n",
      "Iter 58 Batch 21 / 22 Loss: 0.82900083\n",
      "Iter 59 Batch 0 / 22 Loss: 0.8997259\n",
      "Iter 59 Batch 1 / 22 Loss: 0.82161385\n",
      "Iter 59 Batch 2 / 22 Loss: 0.656135\n",
      "Iter 59 Batch 3 / 22 Loss: 0.29235846\n",
      "Iter 59 Batch 4 / 22 Loss: 0.4203984\n",
      "Iter 59 Batch 5 / 22 Loss: 0.59561956\n",
      "Iter 59 Batch 6 / 22 Loss: 1.2391703\n",
      "Iter 59 Batch 7 / 22 Loss: 0.44178462\n",
      "Iter 59 Batch 8 / 22 Loss: 0.8199806\n",
      "Iter 59 Batch 9 / 22 Loss: 0.565729\n",
      "Iter 59 Batch 10 / 22 Loss: 0.64663166\n",
      "Iter 59 Batch 11 / 22 Loss: 1.148448\n",
      "Iter 59 Batch 12 / 22 Loss: 0.59841716\n",
      "Iter 59 Batch 13 / 22 Loss: 0.6478188\n",
      "Iter 59 Batch 14 / 22 Loss: 0.9356935\n",
      "Iter 59 Batch 15 / 22 Loss: 0.44603997\n",
      "Iter 59 Batch 16 / 22 Loss: 0.608238\n",
      "Iter 59 Batch 17 / 22 Loss: 0.49264663\n",
      "Iter 59 Batch 18 / 22 Loss: 0.64916193\n",
      "Iter 59 Batch 19 / 22 Loss: 0.7457076\n",
      "Iter 59 Batch 20 / 22 Loss: 0.936656\n",
      "Iter 59 Batch 21 / 22 Loss: 0.7484423\n",
      "Iter 60 Batch 0 / 22 Loss: 0.87392056\n",
      "Iter 60 Batch 1 / 22 Loss: 0.8055379\n",
      "Iter 60 Batch 2 / 22 Loss: 0.79923546\n",
      "Iter 60 Batch 3 / 22 Loss: 0.31524128\n",
      "Iter 60 Batch 4 / 22 Loss: 0.401204\n",
      "Iter 60 Batch 5 / 22 Loss: 0.5190247\n",
      "Iter 60 Batch 6 / 22 Loss: 1.2162836\n",
      "Iter 60 Batch 7 / 22 Loss: 0.46752265\n",
      "Iter 60 Batch 8 / 22 Loss: 0.7637552\n",
      "Iter 60 Batch 9 / 22 Loss: 0.6025527\n",
      "Iter 60 Batch 10 / 22 Loss: 0.6418499\n",
      "Iter 60 Batch 11 / 22 Loss: 1.2680786\n",
      "Iter 60 Batch 12 / 22 Loss: 0.5811537\n",
      "Iter 60 Batch 13 / 22 Loss: 0.62947345\n",
      "Iter 60 Batch 14 / 22 Loss: 0.9133684\n",
      "Iter 60 Batch 15 / 22 Loss: 0.6654979\n",
      "Iter 60 Batch 16 / 22 Loss: 0.5203265\n",
      "Iter 60 Batch 17 / 22 Loss: 0.62445533\n",
      "Iter 60 Batch 18 / 22 Loss: 0.61463124\n",
      "Iter 60 Batch 19 / 22 Loss: 0.7012879\n",
      "Iter 60 Batch 20 / 22 Loss: 0.9061781\n",
      "Iter 60 Batch 21 / 22 Loss: 0.71135837\n",
      "Iter 61 Batch 0 / 22 Loss: 0.8570577\n",
      "Iter 61 Batch 1 / 22 Loss: 0.8344383\n",
      "Iter 61 Batch 2 / 22 Loss: 0.62034446\n",
      "Iter 61 Batch 3 / 22 Loss: 0.28508025\n",
      "Iter 61 Batch 4 / 22 Loss: 0.38041666\n",
      "Iter 61 Batch 5 / 22 Loss: 0.55275434\n",
      "Iter 61 Batch 6 / 22 Loss: 1.214116\n",
      "Iter 61 Batch 7 / 22 Loss: 0.44176987\n",
      "Iter 61 Batch 8 / 22 Loss: 0.75435066\n",
      "Iter 61 Batch 9 / 22 Loss: 0.553328\n",
      "Iter 61 Batch 10 / 22 Loss: 0.6371306\n",
      "Iter 61 Batch 11 / 22 Loss: 1.1855704\n",
      "Iter 61 Batch 12 / 22 Loss: 0.58778465\n",
      "Iter 61 Batch 13 / 22 Loss: 0.6409165\n",
      "Iter 61 Batch 14 / 22 Loss: 0.8386775\n",
      "Iter 61 Batch 15 / 22 Loss: 0.48131087\n",
      "Iter 61 Batch 16 / 22 Loss: 0.4943722\n",
      "Iter 61 Batch 17 / 22 Loss: 0.4832481\n",
      "Iter 61 Batch 18 / 22 Loss: 0.5117207\n",
      "Iter 61 Batch 19 / 22 Loss: 0.7166683\n",
      "Iter 61 Batch 20 / 22 Loss: 0.8987486\n",
      "Iter 61 Batch 21 / 22 Loss: 0.6702769\n",
      "Iter 62 Batch 0 / 22 Loss: 0.85258335\n",
      "Iter 62 Batch 1 / 22 Loss: 0.8235767\n",
      "Iter 62 Batch 2 / 22 Loss: 0.6198178\n",
      "Iter 62 Batch 3 / 22 Loss: 0.27827597\n",
      "Iter 62 Batch 4 / 22 Loss: 0.3810648\n",
      "Iter 62 Batch 5 / 22 Loss: 0.5625725\n",
      "Iter 62 Batch 6 / 22 Loss: 1.2063178\n",
      "Iter 62 Batch 7 / 22 Loss: 0.43643296\n",
      "Iter 62 Batch 8 / 22 Loss: 0.7445568\n",
      "Iter 62 Batch 9 / 22 Loss: 0.5056392\n",
      "Iter 62 Batch 10 / 22 Loss: 0.643863\n",
      "Iter 62 Batch 11 / 22 Loss: 1.1529837\n",
      "Iter 62 Batch 12 / 22 Loss: 0.5740543\n",
      "Iter 62 Batch 13 / 22 Loss: 0.642146\n",
      "Iter 62 Batch 14 / 22 Loss: 0.8350587\n",
      "Iter 62 Batch 15 / 22 Loss: 0.43074676\n",
      "Iter 62 Batch 16 / 22 Loss: 0.46923447\n",
      "Iter 62 Batch 17 / 22 Loss: 0.45316577\n",
      "Iter 62 Batch 18 / 22 Loss: 0.47100326\n",
      "Iter 62 Batch 19 / 22 Loss: 0.6864475\n",
      "Iter 62 Batch 20 / 22 Loss: 0.8852526\n",
      "Iter 62 Batch 21 / 22 Loss: 0.6606177\n",
      "Iter 63 Batch 0 / 22 Loss: 0.83654016\n",
      "Iter 63 Batch 1 / 22 Loss: 0.81396765\n",
      "Iter 63 Batch 2 / 22 Loss: 0.6166347\n",
      "Iter 63 Batch 3 / 22 Loss: 0.27051234\n",
      "Iter 63 Batch 4 / 22 Loss: 0.37255293\n",
      "Iter 63 Batch 5 / 22 Loss: 0.5570731\n",
      "Iter 63 Batch 6 / 22 Loss: 1.1998105\n",
      "Iter 63 Batch 7 / 22 Loss: 0.43644893\n",
      "Iter 63 Batch 8 / 22 Loss: 0.7394305\n",
      "Iter 63 Batch 9 / 22 Loss: 0.4968164\n",
      "Iter 63 Batch 10 / 22 Loss: 0.6139509\n",
      "Iter 63 Batch 11 / 22 Loss: 1.1505488\n",
      "Iter 63 Batch 12 / 22 Loss: 0.5641784\n",
      "Iter 63 Batch 13 / 22 Loss: 0.6360743\n",
      "Iter 63 Batch 14 / 22 Loss: 0.8140198\n",
      "Iter 63 Batch 15 / 22 Loss: 0.42722952\n",
      "Iter 63 Batch 16 / 22 Loss: 0.4577828\n",
      "Iter 63 Batch 17 / 22 Loss: 0.4434927\n",
      "Iter 63 Batch 18 / 22 Loss: 0.44010952\n",
      "Iter 63 Batch 19 / 22 Loss: 0.66996455\n",
      "Iter 63 Batch 20 / 22 Loss: 0.8720182\n",
      "Iter 63 Batch 21 / 22 Loss: 0.6385584\n",
      "Iter 64 Batch 0 / 22 Loss: 0.8281853\n",
      "Iter 64 Batch 1 / 22 Loss: 0.8124611\n",
      "Iter 64 Batch 2 / 22 Loss: 0.6177797\n",
      "Iter 64 Batch 3 / 22 Loss: 0.26621217\n",
      "Iter 64 Batch 4 / 22 Loss: 0.37285984\n",
      "Iter 64 Batch 5 / 22 Loss: 0.5334754\n",
      "Iter 64 Batch 6 / 22 Loss: 1.1971202\n",
      "Iter 64 Batch 7 / 22 Loss: 0.42639387\n",
      "Iter 64 Batch 8 / 22 Loss: 0.73437905\n",
      "Iter 64 Batch 9 / 22 Loss: 0.4855892\n",
      "Iter 64 Batch 10 / 22 Loss: 0.6026041\n",
      "Iter 64 Batch 11 / 22 Loss: 1.1469041\n",
      "Iter 64 Batch 12 / 22 Loss: 0.5518174\n",
      "Iter 64 Batch 13 / 22 Loss: 0.6341636\n",
      "Iter 64 Batch 14 / 22 Loss: 0.7974158\n",
      "Iter 64 Batch 15 / 22 Loss: 0.41962054\n",
      "Iter 64 Batch 16 / 22 Loss: 0.45280278\n",
      "Iter 64 Batch 17 / 22 Loss: 0.4397369\n",
      "Iter 64 Batch 18 / 22 Loss: 0.43086854\n",
      "Iter 64 Batch 19 / 22 Loss: 0.65777504\n",
      "Iter 64 Batch 20 / 22 Loss: 0.8519747\n",
      "Iter 64 Batch 21 / 22 Loss: 0.63024235\n",
      "Iter 65 Batch 0 / 22 Loss: 0.82088524\n",
      "Iter 65 Batch 1 / 22 Loss: 0.79367775\n",
      "Iter 65 Batch 2 / 22 Loss: 0.61213577\n",
      "Iter 65 Batch 3 / 22 Loss: 0.2625546\n",
      "Iter 65 Batch 4 / 22 Loss: 0.3690199\n",
      "Iter 65 Batch 5 / 22 Loss: 0.5191049\n",
      "Iter 65 Batch 6 / 22 Loss: 1.1983578\n",
      "Iter 65 Batch 7 / 22 Loss: 0.4303252\n",
      "Iter 65 Batch 8 / 22 Loss: 0.7297477\n",
      "Iter 65 Batch 9 / 22 Loss: 0.4866661\n",
      "Iter 65 Batch 10 / 22 Loss: 0.6005153\n",
      "Iter 65 Batch 11 / 22 Loss: 1.1448057\n",
      "Iter 65 Batch 12 / 22 Loss: 0.5373485\n",
      "Iter 65 Batch 13 / 22 Loss: 0.62716275\n",
      "Iter 65 Batch 14 / 22 Loss: 0.79312\n",
      "Iter 65 Batch 15 / 22 Loss: 0.41240448\n",
      "Iter 65 Batch 16 / 22 Loss: 0.4377926\n",
      "Iter 65 Batch 17 / 22 Loss: 0.42718315\n",
      "Iter 65 Batch 18 / 22 Loss: 0.4244345\n",
      "Iter 65 Batch 19 / 22 Loss: 0.66136676\n",
      "Iter 65 Batch 20 / 22 Loss: 0.8393868\n",
      "Iter 65 Batch 21 / 22 Loss: 0.62076455\n",
      "Iter 66 Batch 0 / 22 Loss: 0.817148\n",
      "Iter 66 Batch 1 / 22 Loss: 0.7806414\n",
      "Iter 66 Batch 2 / 22 Loss: 0.61104286\n",
      "Iter 66 Batch 3 / 22 Loss: 0.26016882\n",
      "Iter 66 Batch 4 / 22 Loss: 0.36916092\n",
      "Iter 66 Batch 5 / 22 Loss: 0.5154407\n",
      "Iter 66 Batch 6 / 22 Loss: 1.1956501\n",
      "Iter 66 Batch 7 / 22 Loss: 0.42547503\n",
      "Iter 66 Batch 8 / 22 Loss: 0.7314584\n",
      "Iter 66 Batch 9 / 22 Loss: 0.4744658\n",
      "Iter 66 Batch 10 / 22 Loss: 0.593893\n",
      "Iter 66 Batch 11 / 22 Loss: 1.1471151\n",
      "Iter 66 Batch 12 / 22 Loss: 0.52938366\n",
      "Iter 66 Batch 13 / 22 Loss: 0.6188576\n",
      "Iter 66 Batch 14 / 22 Loss: 0.78068835\n",
      "Iter 66 Batch 15 / 22 Loss: 0.41466993\n",
      "Iter 66 Batch 16 / 22 Loss: 0.42628658\n",
      "Iter 66 Batch 17 / 22 Loss: 0.42652625\n",
      "Iter 66 Batch 18 / 22 Loss: 0.42708907\n",
      "Iter 66 Batch 19 / 22 Loss: 0.64769113\n",
      "Iter 66 Batch 20 / 22 Loss: 0.8298943\n",
      "Iter 66 Batch 21 / 22 Loss: 0.61558163\n",
      "Iter 67 Batch 0 / 22 Loss: 0.81644714\n",
      "Iter 67 Batch 1 / 22 Loss: 0.77189404\n",
      "Iter 67 Batch 2 / 22 Loss: 0.6034901\n",
      "Iter 67 Batch 3 / 22 Loss: 0.25769177\n",
      "Iter 67 Batch 4 / 22 Loss: 0.36376226\n",
      "Iter 67 Batch 5 / 22 Loss: 0.50681174\n",
      "Iter 67 Batch 6 / 22 Loss: 1.2002181\n",
      "Iter 67 Batch 7 / 22 Loss: 0.42578256\n",
      "Iter 67 Batch 8 / 22 Loss: 0.7272378\n",
      "Iter 67 Batch 9 / 22 Loss: 0.47558236\n",
      "Iter 67 Batch 10 / 22 Loss: 0.5883843\n",
      "Iter 67 Batch 11 / 22 Loss: 1.143964\n",
      "Iter 67 Batch 12 / 22 Loss: 0.51888204\n",
      "Iter 67 Batch 13 / 22 Loss: 0.6135952\n",
      "Iter 67 Batch 14 / 22 Loss: 0.77691317\n",
      "Iter 67 Batch 15 / 22 Loss: 0.42859384\n",
      "Iter 67 Batch 16 / 22 Loss: 0.41641226\n",
      "Iter 67 Batch 17 / 22 Loss: 0.41792145\n",
      "Iter 67 Batch 18 / 22 Loss: 0.42619264\n",
      "Iter 67 Batch 19 / 22 Loss: 0.6488377\n",
      "Iter 67 Batch 20 / 22 Loss: 0.8247552\n",
      "Iter 67 Batch 21 / 22 Loss: 0.6104787\n",
      "Iter 68 Batch 0 / 22 Loss: 0.81375104\n",
      "Iter 68 Batch 1 / 22 Loss: 0.76741135\n",
      "Iter 68 Batch 2 / 22 Loss: 0.6087521\n",
      "Iter 68 Batch 3 / 22 Loss: 0.2578654\n",
      "Iter 68 Batch 4 / 22 Loss: 0.36423865\n",
      "Iter 68 Batch 5 / 22 Loss: 0.50160146\n",
      "Iter 68 Batch 6 / 22 Loss: 1.1957781\n",
      "Iter 68 Batch 7 / 22 Loss: 0.42045027\n",
      "Iter 68 Batch 8 / 22 Loss: 0.7339317\n",
      "Iter 68 Batch 9 / 22 Loss: 0.46484527\n",
      "Iter 68 Batch 10 / 22 Loss: 0.58955175\n",
      "Iter 68 Batch 11 / 22 Loss: 1.1448541\n",
      "Iter 68 Batch 12 / 22 Loss: 0.5181169\n",
      "Iter 68 Batch 13 / 22 Loss: 0.6038499\n",
      "Iter 68 Batch 14 / 22 Loss: 0.7664675\n",
      "Iter 68 Batch 15 / 22 Loss: 0.44170666\n",
      "Iter 68 Batch 16 / 22 Loss: 0.4164389\n",
      "Iter 68 Batch 17 / 22 Loss: 0.4210825\n",
      "Iter 68 Batch 18 / 22 Loss: 0.41975203\n",
      "Iter 68 Batch 19 / 22 Loss: 0.64430255\n",
      "Iter 68 Batch 20 / 22 Loss: 0.8174016\n",
      "Iter 68 Batch 21 / 22 Loss: 0.6087286\n",
      "Iter 69 Batch 0 / 22 Loss: 0.81451595\n",
      "Iter 69 Batch 1 / 22 Loss: 0.77575505\n",
      "Iter 69 Batch 2 / 22 Loss: 0.57146096\n",
      "Iter 69 Batch 3 / 22 Loss: 0.26493052\n",
      "Iter 69 Batch 4 / 22 Loss: 0.38299\n",
      "Iter 69 Batch 5 / 22 Loss: 0.58993495\n",
      "Iter 69 Batch 6 / 22 Loss: 1.228085\n",
      "Iter 69 Batch 7 / 22 Loss: 0.4268748\n",
      "Iter 69 Batch 8 / 22 Loss: 0.7227718\n",
      "Iter 69 Batch 9 / 22 Loss: 0.47866386\n",
      "Iter 69 Batch 10 / 22 Loss: 0.60167277\n",
      "Iter 69 Batch 11 / 22 Loss: 1.1989326\n",
      "Iter 69 Batch 12 / 22 Loss: 0.52195936\n",
      "Iter 69 Batch 13 / 22 Loss: 0.60906345\n",
      "Iter 69 Batch 14 / 22 Loss: 0.791205\n",
      "Iter 69 Batch 15 / 22 Loss: 0.41968888\n",
      "Iter 69 Batch 16 / 22 Loss: 0.41921243\n",
      "Iter 69 Batch 17 / 22 Loss: 0.44489935\n",
      "Iter 69 Batch 18 / 22 Loss: 0.4187522\n",
      "Iter 69 Batch 19 / 22 Loss: 0.6381786\n",
      "Iter 69 Batch 20 / 22 Loss: 0.8064456\n",
      "Iter 69 Batch 21 / 22 Loss: 0.7412571\n",
      "Iter 70 Batch 0 / 22 Loss: 0.8360355\n",
      "Iter 70 Batch 1 / 22 Loss: 0.7500107\n",
      "Iter 70 Batch 2 / 22 Loss: 0.5335697\n",
      "Iter 70 Batch 3 / 22 Loss: 0.26225638\n",
      "Iter 70 Batch 4 / 22 Loss: 0.36194593\n",
      "Iter 70 Batch 5 / 22 Loss: 0.51050794\n",
      "Iter 70 Batch 6 / 22 Loss: 1.2065525\n",
      "Iter 70 Batch 7 / 22 Loss: 0.46591568\n",
      "Iter 70 Batch 8 / 22 Loss: 0.7349685\n",
      "Iter 70 Batch 9 / 22 Loss: 0.4754568\n",
      "Iter 70 Batch 10 / 22 Loss: 0.5753017\n",
      "Iter 70 Batch 11 / 22 Loss: 1.1953402\n",
      "Iter 70 Batch 12 / 22 Loss: 0.5164435\n",
      "Iter 70 Batch 13 / 22 Loss: 0.5959547\n",
      "Iter 70 Batch 14 / 22 Loss: 0.80151653\n",
      "Iter 70 Batch 15 / 22 Loss: 0.47947478\n",
      "Iter 70 Batch 16 / 22 Loss: 0.4064139\n",
      "Iter 70 Batch 17 / 22 Loss: 0.43030232\n",
      "Iter 70 Batch 18 / 22 Loss: 0.46467322\n",
      "Iter 70 Batch 19 / 22 Loss: 0.63613737\n",
      "Iter 70 Batch 20 / 22 Loss: 0.8481418\n",
      "Iter 70 Batch 21 / 22 Loss: 0.70898783\n",
      "Iter 71 Batch 0 / 22 Loss: 0.8169473\n",
      "Iter 71 Batch 1 / 22 Loss: 0.7700425\n",
      "Iter 71 Batch 2 / 22 Loss: 0.52374685\n",
      "Iter 71 Batch 3 / 22 Loss: 0.25390548\n",
      "Iter 71 Batch 4 / 22 Loss: 0.3855105\n",
      "Iter 71 Batch 5 / 22 Loss: 0.53294635\n",
      "Iter 71 Batch 6 / 22 Loss: 1.2137496\n",
      "Iter 71 Batch 7 / 22 Loss: 0.41765076\n",
      "Iter 71 Batch 8 / 22 Loss: 0.72305435\n",
      "Iter 71 Batch 9 / 22 Loss: 0.45443806\n",
      "Iter 71 Batch 10 / 22 Loss: 0.5869723\n",
      "Iter 71 Batch 11 / 22 Loss: 1.1906579\n",
      "Iter 71 Batch 12 / 22 Loss: 0.5236657\n",
      "Iter 71 Batch 13 / 22 Loss: 0.59643835\n",
      "Iter 71 Batch 14 / 22 Loss: 0.77042574\n",
      "Iter 71 Batch 15 / 22 Loss: 0.44769496\n",
      "Iter 71 Batch 16 / 22 Loss: 0.41381687\n",
      "Iter 71 Batch 17 / 22 Loss: 0.40298074\n",
      "Iter 71 Batch 18 / 22 Loss: 0.42024875\n",
      "Iter 71 Batch 19 / 22 Loss: 0.6378096\n",
      "Iter 71 Batch 20 / 22 Loss: 0.8272197\n",
      "Iter 71 Batch 21 / 22 Loss: 0.7200152\n",
      "Iter 72 Batch 0 / 22 Loss: 0.8293941\n",
      "Iter 72 Batch 1 / 22 Loss: 0.7462337\n",
      "Iter 72 Batch 2 / 22 Loss: 0.5276128\n",
      "Iter 72 Batch 3 / 22 Loss: 0.26274782\n",
      "Iter 72 Batch 4 / 22 Loss: 0.35483605\n",
      "Iter 72 Batch 5 / 22 Loss: 0.4872004\n",
      "Iter 72 Batch 6 / 22 Loss: 1.1897656\n",
      "Iter 72 Batch 7 / 22 Loss: 0.4150392\n",
      "Iter 72 Batch 8 / 22 Loss: 0.730253\n",
      "Iter 72 Batch 9 / 22 Loss: 0.44378975\n",
      "Iter 72 Batch 10 / 22 Loss: 0.5876286\n",
      "Iter 72 Batch 11 / 22 Loss: 1.1566485\n",
      "Iter 72 Batch 12 / 22 Loss: 0.51615864\n",
      "Iter 72 Batch 13 / 22 Loss: 0.5875412\n",
      "Iter 72 Batch 14 / 22 Loss: 0.75334334\n",
      "Iter 72 Batch 15 / 22 Loss: 0.4127609\n",
      "Iter 72 Batch 16 / 22 Loss: 0.4482743\n",
      "Iter 72 Batch 17 / 22 Loss: 0.4390772\n",
      "Iter 72 Batch 18 / 22 Loss: 0.40971613\n",
      "Iter 72 Batch 19 / 22 Loss: 0.6358807\n",
      "Iter 72 Batch 20 / 22 Loss: 0.9340228\n",
      "Iter 72 Batch 21 / 22 Loss: 0.6609907\n",
      "Iter 73 Batch 0 / 22 Loss: 0.831267\n",
      "Iter 73 Batch 1 / 22 Loss: 0.7354187\n",
      "Iter 73 Batch 2 / 22 Loss: 0.5742345\n",
      "Iter 73 Batch 3 / 22 Loss: 0.2560817\n",
      "Iter 73 Batch 4 / 22 Loss: 0.35297656\n",
      "Iter 73 Batch 5 / 22 Loss: 0.48860055\n",
      "Iter 73 Batch 6 / 22 Loss: 1.1806166\n",
      "Iter 73 Batch 7 / 22 Loss: 0.42779756\n",
      "Iter 73 Batch 8 / 22 Loss: 0.74597466\n",
      "Iter 73 Batch 9 / 22 Loss: 0.47362566\n",
      "Iter 73 Batch 10 / 22 Loss: 0.584099\n",
      "Iter 73 Batch 11 / 22 Loss: 1.2585893\n",
      "Iter 73 Batch 12 / 22 Loss: 0.49994576\n",
      "Iter 73 Batch 13 / 22 Loss: 0.59697586\n",
      "Iter 73 Batch 14 / 22 Loss: 0.887647\n",
      "Iter 73 Batch 15 / 22 Loss: 0.4102097\n",
      "Iter 73 Batch 16 / 22 Loss: 0.45806804\n",
      "Iter 73 Batch 17 / 22 Loss: 0.4831217\n",
      "Iter 73 Batch 18 / 22 Loss: 0.44433248\n",
      "Iter 73 Batch 19 / 22 Loss: 0.6340241\n",
      "Iter 73 Batch 20 / 22 Loss: 0.9702604\n",
      "Iter 73 Batch 21 / 22 Loss: 0.66541725\n",
      "Iter 74 Batch 0 / 22 Loss: 0.82841814\n",
      "Iter 74 Batch 1 / 22 Loss: 0.7573278\n",
      "Iter 74 Batch 2 / 22 Loss: 0.5032163\n",
      "Iter 74 Batch 3 / 22 Loss: 0.29499936\n",
      "Iter 74 Batch 4 / 22 Loss: 0.35662466\n",
      "Iter 74 Batch 5 / 22 Loss: 0.4994089\n",
      "Iter 74 Batch 6 / 22 Loss: 1.1984977\n",
      "Iter 74 Batch 7 / 22 Loss: 0.40882915\n",
      "Iter 74 Batch 8 / 22 Loss: 0.732502\n",
      "Iter 74 Batch 9 / 22 Loss: 0.4401472\n",
      "Iter 74 Batch 10 / 22 Loss: 0.56922096\n",
      "Iter 74 Batch 11 / 22 Loss: 1.1724876\n",
      "Iter 74 Batch 12 / 22 Loss: 0.49235725\n",
      "Iter 74 Batch 13 / 22 Loss: 0.5937323\n",
      "Iter 74 Batch 14 / 22 Loss: 0.774748\n",
      "Iter 74 Batch 15 / 22 Loss: 0.4055233\n",
      "Iter 74 Batch 16 / 22 Loss: 0.4489117\n",
      "Iter 74 Batch 17 / 22 Loss: 0.4192915\n",
      "Iter 74 Batch 18 / 22 Loss: 0.3949754\n",
      "Iter 74 Batch 19 / 22 Loss: 0.6332745\n",
      "Iter 74 Batch 20 / 22 Loss: 0.8449881\n",
      "Iter 74 Batch 21 / 22 Loss: 0.6380465\n",
      "Iter 75 Batch 0 / 22 Loss: 0.8179943\n",
      "Iter 75 Batch 1 / 22 Loss: 0.732062\n",
      "Iter 75 Batch 2 / 22 Loss: 0.5505644\n",
      "Iter 75 Batch 3 / 22 Loss: 0.2675803\n",
      "Iter 75 Batch 4 / 22 Loss: 0.3383467\n",
      "Iter 75 Batch 5 / 22 Loss: 0.48765534\n",
      "Iter 75 Batch 6 / 22 Loss: 1.191341\n",
      "Iter 75 Batch 7 / 22 Loss: 0.41837144\n",
      "Iter 75 Batch 8 / 22 Loss: 0.7264782\n",
      "Iter 75 Batch 9 / 22 Loss: 0.43279022\n",
      "Iter 75 Batch 10 / 22 Loss: 0.5778166\n",
      "Iter 75 Batch 11 / 22 Loss: 1.1680365\n",
      "Iter 75 Batch 12 / 22 Loss: 0.5095662\n",
      "Iter 75 Batch 13 / 22 Loss: 0.5873583\n",
      "Iter 75 Batch 14 / 22 Loss: 0.7424389\n",
      "Iter 75 Batch 15 / 22 Loss: 0.431262\n",
      "Iter 75 Batch 16 / 22 Loss: 0.45129833\n",
      "Iter 75 Batch 17 / 22 Loss: 0.43828994\n",
      "Iter 75 Batch 18 / 22 Loss: 0.409786\n",
      "Iter 75 Batch 19 / 22 Loss: 0.630664\n",
      "Iter 75 Batch 20 / 22 Loss: 0.77823067\n",
      "Iter 75 Batch 21 / 22 Loss: 0.58864576\n",
      "Iter 76 Batch 0 / 22 Loss: 0.80537903\n",
      "Iter 76 Batch 1 / 22 Loss: 0.73089886\n",
      "Iter 76 Batch 2 / 22 Loss: 0.504496\n",
      "Iter 76 Batch 3 / 22 Loss: 0.2523195\n",
      "Iter 76 Batch 4 / 22 Loss: 0.3466392\n",
      "Iter 76 Batch 5 / 22 Loss: 0.4902012\n",
      "Iter 76 Batch 6 / 22 Loss: 1.2027243\n",
      "Iter 76 Batch 7 / 22 Loss: 0.4098916\n",
      "Iter 76 Batch 8 / 22 Loss: 0.7200997\n",
      "Iter 76 Batch 9 / 22 Loss: 0.44740728\n",
      "Iter 76 Batch 10 / 22 Loss: 0.5764601\n",
      "Iter 76 Batch 11 / 22 Loss: 1.1873716\n",
      "Iter 76 Batch 12 / 22 Loss: 0.49330807\n",
      "Iter 76 Batch 13 / 22 Loss: 0.5574621\n",
      "Iter 76 Batch 14 / 22 Loss: 0.7457117\n",
      "Iter 76 Batch 15 / 22 Loss: 0.40956014\n",
      "Iter 76 Batch 16 / 22 Loss: 0.37523544\n",
      "Iter 76 Batch 17 / 22 Loss: 0.46691477\n",
      "Iter 76 Batch 18 / 22 Loss: 0.4289769\n",
      "Iter 76 Batch 19 / 22 Loss: 0.6911328\n",
      "Iter 76 Batch 20 / 22 Loss: 0.7852886\n",
      "Iter 76 Batch 21 / 22 Loss: 0.6576025\n",
      "Iter 77 Batch 0 / 22 Loss: 0.79752606\n",
      "Iter 77 Batch 1 / 22 Loss: 0.73043257\n",
      "Iter 77 Batch 2 / 22 Loss: 0.49412423\n",
      "Iter 77 Batch 3 / 22 Loss: 0.25064635\n",
      "Iter 77 Batch 4 / 22 Loss: 0.34058762\n",
      "Iter 77 Batch 5 / 22 Loss: 0.4722942\n",
      "Iter 77 Batch 6 / 22 Loss: 1.2103119\n",
      "Iter 77 Batch 7 / 22 Loss: 0.40188333\n",
      "Iter 77 Batch 8 / 22 Loss: 0.7136767\n",
      "Iter 77 Batch 9 / 22 Loss: 0.44702742\n",
      "Iter 77 Batch 10 / 22 Loss: 0.57505995\n",
      "Iter 77 Batch 11 / 22 Loss: 1.1555927\n",
      "Iter 77 Batch 12 / 22 Loss: 0.48830858\n",
      "Iter 77 Batch 13 / 22 Loss: 0.5697937\n",
      "Iter 77 Batch 14 / 22 Loss: 0.7655547\n",
      "Iter 77 Batch 15 / 22 Loss: 0.39898014\n",
      "Iter 77 Batch 16 / 22 Loss: 0.37664163\n",
      "Iter 77 Batch 17 / 22 Loss: 0.39582524\n",
      "Iter 77 Batch 18 / 22 Loss: 0.39247262\n",
      "Iter 77 Batch 19 / 22 Loss: 0.68099046\n",
      "Iter 77 Batch 20 / 22 Loss: 0.7672281\n",
      "Iter 77 Batch 21 / 22 Loss: 0.63125587\n",
      "Iter 78 Batch 0 / 22 Loss: 0.7935645\n",
      "Iter 78 Batch 1 / 22 Loss: 0.71459174\n",
      "Iter 78 Batch 2 / 22 Loss: 0.5028824\n",
      "Iter 78 Batch 3 / 22 Loss: 0.24738586\n",
      "Iter 78 Batch 4 / 22 Loss: 0.34012502\n",
      "Iter 78 Batch 5 / 22 Loss: 0.46253335\n",
      "Iter 78 Batch 6 / 22 Loss: 1.198297\n",
      "Iter 78 Batch 7 / 22 Loss: 0.40258756\n",
      "Iter 78 Batch 8 / 22 Loss: 0.71543515\n",
      "Iter 78 Batch 9 / 22 Loss: 0.43051797\n",
      "Iter 78 Batch 10 / 22 Loss: 0.5722778\n",
      "Iter 78 Batch 11 / 22 Loss: 1.1649646\n",
      "Iter 78 Batch 12 / 22 Loss: 0.49247018\n",
      "Iter 78 Batch 13 / 22 Loss: 0.56245005\n",
      "Iter 78 Batch 14 / 22 Loss: 0.7386788\n",
      "Iter 78 Batch 15 / 22 Loss: 0.39298677\n",
      "Iter 78 Batch 16 / 22 Loss: 0.37389317\n",
      "Iter 78 Batch 17 / 22 Loss: 0.43200502\n",
      "Iter 78 Batch 18 / 22 Loss: 0.39055794\n",
      "Iter 78 Batch 19 / 22 Loss: 0.6376117\n",
      "Iter 78 Batch 20 / 22 Loss: 0.7697909\n",
      "Iter 78 Batch 21 / 22 Loss: 0.5691628\n",
      "Iter 79 Batch 0 / 22 Loss: 0.79306257\n",
      "Iter 79 Batch 1 / 22 Loss: 0.7130451\n",
      "Iter 79 Batch 2 / 22 Loss: 0.48661825\n",
      "Iter 79 Batch 3 / 22 Loss: 0.24473265\n",
      "Iter 79 Batch 4 / 22 Loss: 0.33497745\n",
      "Iter 79 Batch 5 / 22 Loss: 0.46927547\n",
      "Iter 79 Batch 6 / 22 Loss: 1.1877377\n",
      "Iter 79 Batch 7 / 22 Loss: 0.3981154\n",
      "Iter 79 Batch 8 / 22 Loss: 0.7197187\n",
      "Iter 79 Batch 9 / 22 Loss: 0.44664228\n",
      "Iter 79 Batch 10 / 22 Loss: 0.5600455\n",
      "Iter 79 Batch 11 / 22 Loss: 1.1735156\n",
      "Iter 79 Batch 12 / 22 Loss: 0.49285135\n",
      "Iter 79 Batch 13 / 22 Loss: 0.560145\n",
      "Iter 79 Batch 14 / 22 Loss: 0.73683184\n",
      "Iter 79 Batch 15 / 22 Loss: 0.4006343\n",
      "Iter 79 Batch 16 / 22 Loss: 0.37526253\n",
      "Iter 79 Batch 17 / 22 Loss: 0.40125865\n",
      "Iter 79 Batch 18 / 22 Loss: 0.37995422\n",
      "Iter 79 Batch 19 / 22 Loss: 0.65052676\n",
      "Iter 79 Batch 20 / 22 Loss: 0.7789558\n",
      "Iter 79 Batch 21 / 22 Loss: 0.66699404\n",
      "Iter 80 Batch 0 / 22 Loss: 0.79477644\n",
      "Iter 80 Batch 1 / 22 Loss: 0.71613586\n",
      "Iter 80 Batch 2 / 22 Loss: 0.4931314\n",
      "Iter 80 Batch 3 / 22 Loss: 0.24598822\n",
      "Iter 80 Batch 4 / 22 Loss: 0.32881713\n",
      "Iter 80 Batch 5 / 22 Loss: 0.45904905\n",
      "Iter 80 Batch 6 / 22 Loss: 1.1992934\n",
      "Iter 80 Batch 7 / 22 Loss: 0.3968056\n",
      "Iter 80 Batch 8 / 22 Loss: 0.72183996\n",
      "Iter 80 Batch 9 / 22 Loss: 0.43320194\n",
      "Iter 80 Batch 10 / 22 Loss: 0.57498413\n",
      "Iter 80 Batch 11 / 22 Loss: 1.1593251\n",
      "Iter 80 Batch 12 / 22 Loss: 0.49403813\n",
      "Iter 80 Batch 13 / 22 Loss: 0.56058925\n",
      "Iter 80 Batch 14 / 22 Loss: 0.8142266\n",
      "Iter 80 Batch 15 / 22 Loss: 0.39490825\n",
      "Iter 80 Batch 16 / 22 Loss: 0.4246762\n",
      "Iter 80 Batch 17 / 22 Loss: 0.38424122\n",
      "Iter 80 Batch 18 / 22 Loss: 0.38529274\n",
      "Iter 80 Batch 19 / 22 Loss: 0.69817656\n",
      "Iter 80 Batch 20 / 22 Loss: 0.83617246\n",
      "Iter 80 Batch 21 / 22 Loss: 0.6416571\n",
      "Iter 81 Batch 0 / 22 Loss: 0.79247946\n",
      "Iter 81 Batch 1 / 22 Loss: 0.7102654\n",
      "Iter 81 Batch 2 / 22 Loss: 0.47167903\n",
      "Iter 81 Batch 3 / 22 Loss: 0.24059927\n",
      "Iter 81 Batch 4 / 22 Loss: 0.33273843\n",
      "Iter 81 Batch 5 / 22 Loss: 0.46464783\n",
      "Iter 81 Batch 6 / 22 Loss: 1.204696\n",
      "Iter 81 Batch 7 / 22 Loss: 0.41378257\n",
      "Iter 81 Batch 8 / 22 Loss: 0.7101586\n",
      "Iter 81 Batch 9 / 22 Loss: 0.4358259\n",
      "Iter 81 Batch 10 / 22 Loss: 0.5642405\n",
      "Iter 81 Batch 11 / 22 Loss: 1.1801331\n",
      "Iter 81 Batch 12 / 22 Loss: 0.4886968\n",
      "Iter 81 Batch 13 / 22 Loss: 0.585278\n",
      "Iter 81 Batch 14 / 22 Loss: 0.7354618\n",
      "Iter 81 Batch 15 / 22 Loss: 0.39215747\n",
      "Iter 81 Batch 16 / 22 Loss: 0.40140563\n",
      "Iter 81 Batch 17 / 22 Loss: 0.38088042\n",
      "Iter 81 Batch 18 / 22 Loss: 0.377697\n",
      "Iter 81 Batch 19 / 22 Loss: 0.62504286\n",
      "Iter 81 Batch 20 / 22 Loss: 0.7636891\n",
      "Iter 81 Batch 21 / 22 Loss: 0.6208582\n",
      "Iter 82 Batch 0 / 22 Loss: 0.8007993\n",
      "Iter 82 Batch 1 / 22 Loss: 0.71073616\n",
      "Iter 82 Batch 2 / 22 Loss: 0.4748556\n",
      "Iter 82 Batch 3 / 22 Loss: 0.23996237\n",
      "Iter 82 Batch 4 / 22 Loss: 0.33481207\n",
      "Iter 82 Batch 5 / 22 Loss: 0.46009493\n",
      "Iter 82 Batch 6 / 22 Loss: 1.194849\n",
      "Iter 82 Batch 7 / 22 Loss: 0.40785325\n",
      "Iter 82 Batch 8 / 22 Loss: 0.7133239\n",
      "Iter 82 Batch 9 / 22 Loss: 0.4327038\n",
      "Iter 82 Batch 10 / 22 Loss: 0.5713106\n",
      "Iter 82 Batch 11 / 22 Loss: 1.1385555\n",
      "Iter 82 Batch 12 / 22 Loss: 0.48370135\n",
      "Iter 82 Batch 13 / 22 Loss: 0.54952663\n",
      "Iter 82 Batch 14 / 22 Loss: 0.71138924\n",
      "Iter 82 Batch 15 / 22 Loss: 0.40105322\n",
      "Iter 82 Batch 16 / 22 Loss: 0.45523527\n",
      "Iter 82 Batch 17 / 22 Loss: 0.40467706\n",
      "Iter 82 Batch 18 / 22 Loss: 0.3698991\n",
      "Iter 82 Batch 19 / 22 Loss: 0.6175949\n",
      "Iter 82 Batch 20 / 22 Loss: 0.75122434\n",
      "Iter 82 Batch 21 / 22 Loss: 0.6231394\n",
      "Iter 83 Batch 0 / 22 Loss: 0.7877245\n",
      "Iter 83 Batch 1 / 22 Loss: 0.6970873\n",
      "Iter 83 Batch 2 / 22 Loss: 0.47459108\n",
      "Iter 83 Batch 3 / 22 Loss: 0.23888414\n",
      "Iter 83 Batch 4 / 22 Loss: 0.32632202\n",
      "Iter 83 Batch 5 / 22 Loss: 0.452457\n",
      "Iter 83 Batch 6 / 22 Loss: 1.1996744\n",
      "Iter 83 Batch 7 / 22 Loss: 0.39056903\n",
      "Iter 83 Batch 8 / 22 Loss: 0.7203616\n",
      "Iter 83 Batch 9 / 22 Loss: 0.4242625\n",
      "Iter 83 Batch 10 / 22 Loss: 0.5533304\n",
      "Iter 83 Batch 11 / 22 Loss: 1.1616483\n",
      "Iter 83 Batch 12 / 22 Loss: 0.47383645\n",
      "Iter 83 Batch 13 / 22 Loss: 0.5319663\n",
      "Iter 83 Batch 14 / 22 Loss: 0.7192136\n",
      "Iter 83 Batch 15 / 22 Loss: 0.40692756\n",
      "Iter 83 Batch 16 / 22 Loss: 0.35566258\n",
      "Iter 83 Batch 17 / 22 Loss: 0.42155078\n",
      "Iter 83 Batch 18 / 22 Loss: 0.37857175\n",
      "Iter 83 Batch 19 / 22 Loss: 0.63144016\n",
      "Iter 83 Batch 20 / 22 Loss: 0.74760395\n",
      "Iter 83 Batch 21 / 22 Loss: 0.56582594\n",
      "Iter 84 Batch 0 / 22 Loss: 0.78539395\n",
      "Iter 84 Batch 1 / 22 Loss: 0.6998581\n",
      "Iter 84 Batch 2 / 22 Loss: 0.46939358\n",
      "Iter 84 Batch 3 / 22 Loss: 0.23748443\n",
      "Iter 84 Batch 4 / 22 Loss: 0.32709438\n",
      "Iter 84 Batch 5 / 22 Loss: 0.49181762\n",
      "Iter 84 Batch 6 / 22 Loss: 1.2249706\n",
      "Iter 84 Batch 7 / 22 Loss: 0.3926318\n",
      "Iter 84 Batch 8 / 22 Loss: 0.6979313\n",
      "Iter 84 Batch 9 / 22 Loss: 0.4320951\n",
      "Iter 84 Batch 10 / 22 Loss: 0.569048\n",
      "Iter 84 Batch 11 / 22 Loss: 1.1335193\n",
      "Iter 84 Batch 12 / 22 Loss: 0.47364968\n",
      "Iter 84 Batch 13 / 22 Loss: 0.54445565\n",
      "Iter 84 Batch 14 / 22 Loss: 0.7116671\n",
      "Iter 84 Batch 15 / 22 Loss: 0.38521945\n",
      "Iter 84 Batch 16 / 22 Loss: 0.36858216\n",
      "Iter 84 Batch 17 / 22 Loss: 0.3642642\n",
      "Iter 84 Batch 18 / 22 Loss: 0.3616534\n",
      "Iter 84 Batch 19 / 22 Loss: 0.6154737\n",
      "Iter 84 Batch 20 / 22 Loss: 0.74597454\n",
      "Iter 84 Batch 21 / 22 Loss: 0.70241094\n",
      "Iter 85 Batch 0 / 22 Loss: 0.7870546\n",
      "Iter 85 Batch 1 / 22 Loss: 0.6866295\n",
      "Iter 85 Batch 2 / 22 Loss: 0.48033762\n",
      "Iter 85 Batch 3 / 22 Loss: 0.23662643\n",
      "Iter 85 Batch 4 / 22 Loss: 0.3349599\n",
      "Iter 85 Batch 5 / 22 Loss: 0.4973759\n",
      "Iter 85 Batch 6 / 22 Loss: 1.1905512\n",
      "Iter 85 Batch 7 / 22 Loss: 0.39649457\n",
      "Iter 85 Batch 8 / 22 Loss: 0.70492995\n",
      "Iter 85 Batch 9 / 22 Loss: 0.43570632\n",
      "Iter 85 Batch 10 / 22 Loss: 0.56366265\n",
      "Iter 85 Batch 11 / 22 Loss: 1.2118366\n",
      "Iter 85 Batch 12 / 22 Loss: 0.4743895\n",
      "Iter 85 Batch 13 / 22 Loss: 0.5293734\n",
      "Iter 85 Batch 14 / 22 Loss: 0.7184903\n",
      "Iter 85 Batch 15 / 22 Loss: 0.3861068\n",
      "Iter 85 Batch 16 / 22 Loss: 0.40800995\n",
      "Iter 85 Batch 17 / 22 Loss: 0.3634334\n",
      "Iter 85 Batch 18 / 22 Loss: 0.35503578\n",
      "Iter 85 Batch 19 / 22 Loss: 0.6085336\n",
      "Iter 85 Batch 20 / 22 Loss: 0.7304532\n",
      "Iter 85 Batch 21 / 22 Loss: 0.64462614\n",
      "Iter 86 Batch 0 / 22 Loss: 0.7865427\n",
      "Iter 86 Batch 1 / 22 Loss: 0.6911654\n",
      "Iter 86 Batch 2 / 22 Loss: 0.47568786\n",
      "Iter 86 Batch 3 / 22 Loss: 0.23157158\n",
      "Iter 86 Batch 4 / 22 Loss: 0.32395518\n",
      "Iter 86 Batch 5 / 22 Loss: 0.4580176\n",
      "Iter 86 Batch 6 / 22 Loss: 1.1944836\n",
      "Iter 86 Batch 7 / 22 Loss: 0.38253438\n",
      "Iter 86 Batch 8 / 22 Loss: 0.7043827\n",
      "Iter 86 Batch 9 / 22 Loss: 0.4180534\n",
      "Iter 86 Batch 10 / 22 Loss: 0.5463615\n",
      "Iter 86 Batch 11 / 22 Loss: 1.1685839\n",
      "Iter 86 Batch 12 / 22 Loss: 0.4730901\n",
      "Iter 86 Batch 13 / 22 Loss: 0.53754854\n",
      "Iter 86 Batch 14 / 22 Loss: 0.70424384\n",
      "Iter 86 Batch 15 / 22 Loss: 0.39418688\n",
      "Iter 86 Batch 16 / 22 Loss: 0.34473744\n",
      "Iter 86 Batch 17 / 22 Loss: 0.35865363\n",
      "Iter 86 Batch 18 / 22 Loss: 0.36418962\n",
      "Iter 86 Batch 19 / 22 Loss: 0.6145237\n",
      "Iter 86 Batch 20 / 22 Loss: 0.7583934\n",
      "Iter 86 Batch 21 / 22 Loss: 0.63209784\n",
      "Iter 87 Batch 0 / 22 Loss: 0.77970296\n",
      "Iter 87 Batch 1 / 22 Loss: 0.6862413\n",
      "Iter 87 Batch 2 / 22 Loss: 0.46386507\n",
      "Iter 87 Batch 3 / 22 Loss: 0.23076019\n",
      "Iter 87 Batch 4 / 22 Loss: 0.31501758\n",
      "Iter 87 Batch 5 / 22 Loss: 0.4458382\n",
      "Iter 87 Batch 6 / 22 Loss: 1.1962605\n",
      "Iter 87 Batch 7 / 22 Loss: 0.3810104\n",
      "Iter 87 Batch 8 / 22 Loss: 0.7036777\n",
      "Iter 87 Batch 9 / 22 Loss: 0.41429996\n",
      "Iter 87 Batch 10 / 22 Loss: 0.5420454\n",
      "Iter 87 Batch 11 / 22 Loss: 1.1395757\n",
      "Iter 87 Batch 12 / 22 Loss: 0.4654337\n",
      "Iter 87 Batch 13 / 22 Loss: 0.5395697\n",
      "Iter 87 Batch 14 / 22 Loss: 0.6995889\n",
      "Iter 87 Batch 15 / 22 Loss: 0.38456947\n",
      "Iter 87 Batch 16 / 22 Loss: 0.33338594\n",
      "Iter 87 Batch 17 / 22 Loss: 0.3568949\n",
      "Iter 87 Batch 18 / 22 Loss: 0.35154334\n",
      "Iter 87 Batch 19 / 22 Loss: 0.60804385\n",
      "Iter 87 Batch 20 / 22 Loss: 0.75498885\n",
      "Iter 87 Batch 21 / 22 Loss: 0.5721695\n",
      "Iter 88 Batch 0 / 22 Loss: 0.79188097\n",
      "Iter 88 Batch 1 / 22 Loss: 0.69185907\n",
      "Iter 88 Batch 2 / 22 Loss: 0.47331077\n",
      "Iter 88 Batch 3 / 22 Loss: 0.23195182\n",
      "Iter 88 Batch 4 / 22 Loss: 1.0587331\n",
      "Iter 88 Batch 5 / 22 Loss: 0.48299205\n",
      "Iter 88 Batch 6 / 22 Loss: 1.4282691\n",
      "Iter 88 Batch 7 / 22 Loss: 0.6350018\n",
      "Iter 88 Batch 8 / 22 Loss: 1.5351353\n",
      "Iter 88 Batch 9 / 22 Loss: 1.5766772\n",
      "Iter 88 Batch 10 / 22 Loss: 0.94288176\n",
      "Iter 88 Batch 11 / 22 Loss: 1.3041972\n",
      "Iter 88 Batch 12 / 22 Loss: 0.70306563\n",
      "Iter 88 Batch 13 / 22 Loss: 1.0439823\n",
      "Iter 88 Batch 14 / 22 Loss: 1.581906\n",
      "Iter 88 Batch 15 / 22 Loss: 1.511539\n",
      "Iter 88 Batch 16 / 22 Loss: 0.7220647\n",
      "Iter 88 Batch 17 / 22 Loss: 1.7922456\n",
      "Iter 88 Batch 18 / 22 Loss: 0.59944046\n",
      "Iter 88 Batch 19 / 22 Loss: 1.3302904\n",
      "Iter 88 Batch 20 / 22 Loss: 1.3012317\n",
      "Iter 88 Batch 21 / 22 Loss: 1.2262022\n",
      "Iter 89 Batch 0 / 22 Loss: 1.3364401\n",
      "Iter 89 Batch 1 / 22 Loss: 1.2064375\n",
      "Iter 89 Batch 2 / 22 Loss: 0.97378105\n",
      "Iter 89 Batch 3 / 22 Loss: 1.9921544\n",
      "Iter 89 Batch 4 / 22 Loss: 1.3553138\n",
      "Iter 89 Batch 5 / 22 Loss: 0.6918372\n",
      "Iter 89 Batch 6 / 22 Loss: 1.5388961\n",
      "Iter 89 Batch 7 / 22 Loss: 0.89972115\n",
      "Iter 89 Batch 8 / 22 Loss: 1.4935459\n",
      "Iter 89 Batch 9 / 22 Loss: 1.3854507\n",
      "Iter 89 Batch 10 / 22 Loss: 0.89411116\n",
      "Iter 89 Batch 11 / 22 Loss: 1.3450228\n",
      "Iter 89 Batch 12 / 22 Loss: 0.72498745\n",
      "Iter 89 Batch 13 / 22 Loss: 0.7361647\n",
      "Iter 89 Batch 14 / 22 Loss: 1.7185166\n",
      "Iter 89 Batch 15 / 22 Loss: 1.5991822\n",
      "Iter 89 Batch 16 / 22 Loss: 0.75512147\n",
      "Iter 89 Batch 17 / 22 Loss: 1.1468562\n",
      "Iter 89 Batch 18 / 22 Loss: 0.96741956\n",
      "Iter 89 Batch 19 / 22 Loss: 1.139781\n",
      "Iter 89 Batch 20 / 22 Loss: 1.2337837\n",
      "Iter 89 Batch 21 / 22 Loss: 0.6699053\n",
      "Iter 90 Batch 0 / 22 Loss: 1.153504\n",
      "Iter 90 Batch 1 / 22 Loss: 1.508076\n",
      "Iter 90 Batch 2 / 22 Loss: 0.7156005\n",
      "Iter 90 Batch 3 / 22 Loss: 1.4351115\n",
      "Iter 90 Batch 4 / 22 Loss: 1.4900582\n",
      "Iter 90 Batch 5 / 22 Loss: 1.0352447\n",
      "Iter 90 Batch 6 / 22 Loss: 1.4673252\n",
      "Iter 90 Batch 7 / 22 Loss: 1.3486423\n",
      "Iter 90 Batch 8 / 22 Loss: 1.1446803\n",
      "Iter 90 Batch 9 / 22 Loss: 1.7298617\n",
      "Iter 90 Batch 10 / 22 Loss: 0.7497749\n",
      "Iter 90 Batch 11 / 22 Loss: 1.2141457\n",
      "Iter 90 Batch 12 / 22 Loss: 0.7810608\n",
      "Iter 90 Batch 13 / 22 Loss: 1.1948206\n",
      "Iter 90 Batch 14 / 22 Loss: 0.7322674\n",
      "Iter 90 Batch 15 / 22 Loss: 1.2443391\n",
      "Iter 90 Batch 16 / 22 Loss: 0.8476193\n",
      "Iter 90 Batch 17 / 22 Loss: 1.4227206\n",
      "Iter 90 Batch 18 / 22 Loss: 0.89365053\n",
      "Iter 90 Batch 19 / 22 Loss: 1.0880427\n",
      "Iter 90 Batch 20 / 22 Loss: 1.2627833\n",
      "Iter 90 Batch 21 / 22 Loss: 0.62524295\n",
      "Iter 91 Batch 0 / 22 Loss: 1.2529938\n",
      "Iter 91 Batch 1 / 22 Loss: 1.3859288\n",
      "Iter 91 Batch 2 / 22 Loss: 0.91566503\n",
      "Iter 91 Batch 3 / 22 Loss: 1.0992398\n",
      "Iter 91 Batch 4 / 22 Loss: 1.4987043\n",
      "Iter 91 Batch 5 / 22 Loss: 0.7688701\n",
      "Iter 91 Batch 6 / 22 Loss: 1.4215689\n",
      "Iter 91 Batch 7 / 22 Loss: 1.3074127\n",
      "Iter 91 Batch 8 / 22 Loss: 1.3408756\n",
      "Iter 91 Batch 9 / 22 Loss: 1.1031892\n",
      "Iter 91 Batch 10 / 22 Loss: 0.8090668\n",
      "Iter 91 Batch 11 / 22 Loss: 1.1720374\n",
      "Iter 91 Batch 12 / 22 Loss: 0.79733956\n",
      "Iter 91 Batch 13 / 22 Loss: 0.89431083\n",
      "Iter 91 Batch 14 / 22 Loss: 0.89020944\n",
      "Iter 91 Batch 15 / 22 Loss: 1.7341042\n",
      "Iter 91 Batch 16 / 22 Loss: 1.1441532\n",
      "Iter 91 Batch 17 / 22 Loss: 1.1211343\n",
      "Iter 91 Batch 18 / 22 Loss: 0.8344696\n",
      "Iter 91 Batch 19 / 22 Loss: 0.954435\n",
      "Iter 91 Batch 20 / 22 Loss: 1.727815\n",
      "Iter 91 Batch 21 / 22 Loss: 0.9417688\n",
      "Iter 92 Batch 0 / 22 Loss: 1.3169247\n",
      "Iter 92 Batch 1 / 22 Loss: 1.3936894\n",
      "Iter 92 Batch 2 / 22 Loss: 0.8464665\n",
      "Iter 92 Batch 3 / 22 Loss: 0.9961008\n",
      "Iter 92 Batch 4 / 22 Loss: 0.9378747\n",
      "Iter 92 Batch 5 / 22 Loss: 0.81837714\n",
      "Iter 92 Batch 6 / 22 Loss: 1.5062537\n",
      "Iter 92 Batch 7 / 22 Loss: 0.93595797\n",
      "Iter 92 Batch 8 / 22 Loss: 1.2378149\n",
      "Iter 92 Batch 9 / 22 Loss: 0.98561066\n",
      "Iter 92 Batch 10 / 22 Loss: 0.79352236\n",
      "Iter 92 Batch 11 / 22 Loss: 1.1280034\n",
      "Iter 92 Batch 12 / 22 Loss: 1.303278\n",
      "Iter 92 Batch 13 / 22 Loss: 1.1141133\n",
      "Iter 92 Batch 14 / 22 Loss: 0.96255237\n",
      "Iter 92 Batch 15 / 22 Loss: 0.67398113\n",
      "Iter 92 Batch 16 / 22 Loss: 0.8288733\n",
      "Iter 92 Batch 17 / 22 Loss: 1.143426\n",
      "Iter 92 Batch 18 / 22 Loss: 0.7466704\n",
      "Iter 92 Batch 19 / 22 Loss: 1.3151162\n",
      "Iter 92 Batch 20 / 22 Loss: 1.3371872\n",
      "Iter 92 Batch 21 / 22 Loss: 1.6195792\n",
      "Iter 93 Batch 0 / 22 Loss: 1.7480972\n",
      "Iter 93 Batch 1 / 22 Loss: 1.2958226\n",
      "Iter 93 Batch 2 / 22 Loss: 1.0012894\n",
      "Iter 93 Batch 3 / 22 Loss: 1.2966056\n",
      "Iter 93 Batch 4 / 22 Loss: 1.0267833\n",
      "Iter 93 Batch 5 / 22 Loss: 1.3608693\n",
      "Iter 93 Batch 6 / 22 Loss: 1.596823\n",
      "Iter 93 Batch 7 / 22 Loss: 0.83376586\n",
      "Iter 93 Batch 8 / 22 Loss: 0.962278\n",
      "Iter 93 Batch 9 / 22 Loss: 0.96043473\n",
      "Iter 93 Batch 10 / 22 Loss: 0.7145387\n",
      "Iter 93 Batch 11 / 22 Loss: 1.1669978\n",
      "Iter 93 Batch 12 / 22 Loss: 0.86612844\n",
      "Iter 93 Batch 13 / 22 Loss: 1.1054349\n",
      "Iter 93 Batch 14 / 22 Loss: 0.9604834\n",
      "Iter 93 Batch 15 / 22 Loss: 0.70362544\n",
      "Iter 93 Batch 16 / 22 Loss: 0.73504746\n",
      "Iter 93 Batch 17 / 22 Loss: 1.0686212\n",
      "Iter 93 Batch 18 / 22 Loss: 0.90959275\n",
      "Iter 93 Batch 19 / 22 Loss: 0.8807349\n",
      "Iter 93 Batch 20 / 22 Loss: 1.2232841\n",
      "Iter 93 Batch 21 / 22 Loss: 1.1697364\n",
      "Iter 94 Batch 0 / 22 Loss: 1.3029107\n",
      "Iter 94 Batch 1 / 22 Loss: 0.95395905\n",
      "Iter 94 Batch 2 / 22 Loss: 0.89390373\n",
      "Iter 94 Batch 3 / 22 Loss: 1.5489577\n",
      "Iter 94 Batch 4 / 22 Loss: 0.6339748\n",
      "Iter 94 Batch 5 / 22 Loss: 1.0796676\n",
      "Iter 94 Batch 6 / 22 Loss: 1.424229\n",
      "Iter 94 Batch 7 / 22 Loss: 0.9301999\n",
      "Iter 94 Batch 8 / 22 Loss: 1.1088711\n",
      "Iter 94 Batch 9 / 22 Loss: 0.8346455\n",
      "Iter 94 Batch 10 / 22 Loss: 0.8689331\n",
      "Iter 94 Batch 11 / 22 Loss: 1.1862271\n",
      "Iter 94 Batch 12 / 22 Loss: 0.89732534\n",
      "Iter 94 Batch 13 / 22 Loss: 1.0418389\n",
      "Iter 94 Batch 14 / 22 Loss: 0.9709743\n",
      "Iter 94 Batch 15 / 22 Loss: 0.82618725\n",
      "Iter 94 Batch 16 / 22 Loss: 0.53696746\n",
      "Iter 94 Batch 17 / 22 Loss: 0.8532999\n",
      "Iter 94 Batch 18 / 22 Loss: 0.87323105\n",
      "Iter 94 Batch 19 / 22 Loss: 0.92360806\n",
      "Iter 94 Batch 20 / 22 Loss: 1.1456077\n",
      "Iter 94 Batch 21 / 22 Loss: 1.0000492\n",
      "Iter 95 Batch 0 / 22 Loss: 1.3132939\n",
      "Iter 95 Batch 1 / 22 Loss: 0.7773582\n",
      "Iter 95 Batch 2 / 22 Loss: 0.9413335\n",
      "Iter 95 Batch 3 / 22 Loss: 0.72697335\n",
      "Iter 95 Batch 4 / 22 Loss: 0.6593835\n",
      "Iter 95 Batch 5 / 22 Loss: 0.85307515\n",
      "Iter 95 Batch 6 / 22 Loss: 1.4368899\n",
      "Iter 95 Batch 7 / 22 Loss: 0.86294746\n",
      "Iter 95 Batch 8 / 22 Loss: 0.9447415\n",
      "Iter 95 Batch 9 / 22 Loss: 0.7581637\n",
      "Iter 95 Batch 10 / 22 Loss: 0.8024337\n",
      "Iter 95 Batch 11 / 22 Loss: 1.2055173\n",
      "Iter 95 Batch 12 / 22 Loss: 0.94146645\n",
      "Iter 95 Batch 13 / 22 Loss: 0.9786328\n",
      "Iter 95 Batch 14 / 22 Loss: 0.9106267\n",
      "Iter 95 Batch 15 / 22 Loss: 0.8290179\n",
      "Iter 95 Batch 16 / 22 Loss: 0.5100261\n",
      "Iter 95 Batch 17 / 22 Loss: 0.76953566\n",
      "Iter 95 Batch 18 / 22 Loss: 0.81184554\n",
      "Iter 95 Batch 19 / 22 Loss: 0.9326414\n",
      "Iter 95 Batch 20 / 22 Loss: 1.1161491\n",
      "Iter 95 Batch 21 / 22 Loss: 0.94428444\n",
      "Iter 96 Batch 0 / 22 Loss: 1.2711943\n",
      "Iter 96 Batch 1 / 22 Loss: 0.7062922\n",
      "Iter 96 Batch 2 / 22 Loss: 0.94125736\n",
      "Iter 96 Batch 3 / 22 Loss: 0.5930435\n",
      "Iter 96 Batch 4 / 22 Loss: 0.5646236\n",
      "Iter 96 Batch 5 / 22 Loss: 0.81090015\n",
      "Iter 96 Batch 6 / 22 Loss: 1.4040005\n",
      "Iter 96 Batch 7 / 22 Loss: 0.7927399\n",
      "Iter 96 Batch 8 / 22 Loss: 0.9904163\n",
      "Iter 96 Batch 9 / 22 Loss: 0.6059846\n",
      "Iter 96 Batch 10 / 22 Loss: 0.7844989\n",
      "Iter 96 Batch 11 / 22 Loss: 1.1961926\n",
      "Iter 96 Batch 12 / 22 Loss: 0.95849776\n",
      "Iter 96 Batch 13 / 22 Loss: 0.960765\n",
      "Iter 96 Batch 14 / 22 Loss: 0.90877634\n",
      "Iter 96 Batch 15 / 22 Loss: 0.75061494\n",
      "Iter 96 Batch 16 / 22 Loss: 0.43055767\n",
      "Iter 96 Batch 17 / 22 Loss: 0.73729736\n",
      "Iter 96 Batch 18 / 22 Loss: 0.78550476\n",
      "Iter 96 Batch 19 / 22 Loss: 0.8539438\n",
      "Iter 96 Batch 20 / 22 Loss: 1.0864421\n",
      "Iter 96 Batch 21 / 22 Loss: 0.8909777\n",
      "Iter 97 Batch 0 / 22 Loss: 1.2041708\n",
      "Iter 97 Batch 1 / 22 Loss: 0.6916877\n",
      "Iter 97 Batch 2 / 22 Loss: 0.931773\n",
      "Iter 97 Batch 3 / 22 Loss: 0.52825403\n",
      "Iter 97 Batch 4 / 22 Loss: 0.44648272\n",
      "Iter 97 Batch 5 / 22 Loss: 0.855593\n",
      "Iter 97 Batch 6 / 22 Loss: 1.3707792\n",
      "Iter 97 Batch 7 / 22 Loss: 0.78196543\n",
      "Iter 97 Batch 8 / 22 Loss: 0.9700082\n",
      "Iter 97 Batch 9 / 22 Loss: 0.5879421\n",
      "Iter 97 Batch 10 / 22 Loss: 0.78606534\n",
      "Iter 97 Batch 11 / 22 Loss: 1.1979105\n",
      "Iter 97 Batch 12 / 22 Loss: 0.954637\n",
      "Iter 97 Batch 13 / 22 Loss: 0.95886075\n",
      "Iter 97 Batch 14 / 22 Loss: 0.88800997\n",
      "Iter 97 Batch 15 / 22 Loss: 0.72503996\n",
      "Iter 97 Batch 16 / 22 Loss: 0.42643028\n",
      "Iter 97 Batch 17 / 22 Loss: 0.7320486\n",
      "Iter 97 Batch 18 / 22 Loss: 0.7342806\n",
      "Iter 97 Batch 19 / 22 Loss: 0.8148336\n",
      "Iter 97 Batch 20 / 22 Loss: 1.0734987\n",
      "Iter 97 Batch 21 / 22 Loss: 0.9533758\n",
      "Iter 98 Batch 0 / 22 Loss: 1.1963334\n",
      "Iter 98 Batch 1 / 22 Loss: 0.6329739\n",
      "Iter 98 Batch 2 / 22 Loss: 0.9016843\n",
      "Iter 98 Batch 3 / 22 Loss: 0.45985803\n",
      "Iter 98 Batch 4 / 22 Loss: 0.58195704\n",
      "Iter 98 Batch 5 / 22 Loss: 0.7761003\n",
      "Iter 98 Batch 6 / 22 Loss: 1.3872674\n",
      "Iter 98 Batch 7 / 22 Loss: 0.76581264\n",
      "Iter 98 Batch 8 / 22 Loss: 0.95584047\n",
      "Iter 98 Batch 9 / 22 Loss: 0.5531496\n",
      "Iter 98 Batch 10 / 22 Loss: 0.7675148\n",
      "Iter 98 Batch 11 / 22 Loss: 1.1931993\n",
      "Iter 98 Batch 12 / 22 Loss: 0.95392656\n",
      "Iter 98 Batch 13 / 22 Loss: 0.94275266\n",
      "Iter 98 Batch 14 / 22 Loss: 0.88521713\n",
      "Iter 98 Batch 15 / 22 Loss: 0.69935066\n",
      "Iter 98 Batch 16 / 22 Loss: 0.40090322\n",
      "Iter 98 Batch 17 / 22 Loss: 0.7003524\n",
      "Iter 98 Batch 18 / 22 Loss: 0.71117264\n",
      "Iter 98 Batch 19 / 22 Loss: 0.7920992\n",
      "Iter 98 Batch 20 / 22 Loss: 1.0527538\n",
      "Iter 98 Batch 21 / 22 Loss: 0.90788484\n",
      "Iter 99 Batch 0 / 22 Loss: 1.1071278\n",
      "Iter 99 Batch 1 / 22 Loss: 0.6209865\n",
      "Iter 99 Batch 2 / 22 Loss: 0.8768013\n",
      "Iter 99 Batch 3 / 22 Loss: 0.4563474\n",
      "Iter 99 Batch 4 / 22 Loss: 0.45014828\n",
      "Iter 99 Batch 5 / 22 Loss: 0.7576984\n",
      "Iter 99 Batch 6 / 22 Loss: 1.372349\n",
      "Iter 99 Batch 7 / 22 Loss: 0.738024\n",
      "Iter 99 Batch 8 / 22 Loss: 0.9533863\n",
      "Iter 99 Batch 9 / 22 Loss: 0.5665019\n",
      "Iter 99 Batch 10 / 22 Loss: 0.7720393\n",
      "Iter 99 Batch 11 / 22 Loss: 1.1886059\n",
      "Iter 99 Batch 12 / 22 Loss: 0.92632675\n",
      "Iter 99 Batch 13 / 22 Loss: 0.92963207\n",
      "Iter 99 Batch 14 / 22 Loss: 0.86374223\n",
      "Iter 99 Batch 15 / 22 Loss: 0.69881064\n",
      "Iter 99 Batch 16 / 22 Loss: 0.3965785\n",
      "Iter 99 Batch 17 / 22 Loss: 0.67338526\n",
      "Iter 99 Batch 18 / 22 Loss: 0.67097545\n",
      "Iter 99 Batch 19 / 22 Loss: 0.7857864\n",
      "Iter 99 Batch 20 / 22 Loss: 1.0490527\n",
      "Iter 99 Batch 21 / 22 Loss: 0.75023526\n",
      "Iter 100 Batch 0 / 22 Loss: 1.0824623\n",
      "Iter 100 Batch 1 / 22 Loss: 0.6296265\n",
      "Iter 100 Batch 2 / 22 Loss: 0.8881422\n",
      "Iter 100 Batch 3 / 22 Loss: 0.46883333\n",
      "Iter 100 Batch 4 / 22 Loss: 0.7742923\n",
      "Iter 100 Batch 5 / 22 Loss: 0.75543153\n",
      "Iter 100 Batch 6 / 22 Loss: 1.3609031\n",
      "Iter 100 Batch 7 / 22 Loss: 0.817636\n",
      "Iter 100 Batch 8 / 22 Loss: 0.93490374\n",
      "Iter 100 Batch 9 / 22 Loss: 0.58884406\n",
      "Iter 100 Batch 10 / 22 Loss: 0.76182073\n",
      "Iter 100 Batch 11 / 22 Loss: 1.1879156\n",
      "Iter 100 Batch 12 / 22 Loss: 0.9180151\n",
      "Iter 100 Batch 13 / 22 Loss: 0.91816956\n",
      "Iter 100 Batch 14 / 22 Loss: 0.84592277\n",
      "Iter 100 Batch 15 / 22 Loss: 0.6822677\n",
      "Iter 100 Batch 16 / 22 Loss: 0.37991232\n",
      "Iter 100 Batch 17 / 22 Loss: 0.67992723\n",
      "Iter 100 Batch 18 / 22 Loss: 0.63277584\n",
      "Iter 100 Batch 19 / 22 Loss: 0.7793214\n",
      "Iter 100 Batch 20 / 22 Loss: 1.0366744\n",
      "Iter 100 Batch 21 / 22 Loss: 0.7860216\n",
      "Iter 101 Batch 0 / 22 Loss: 1.0349513\n",
      "Iter 101 Batch 1 / 22 Loss: 0.6482003\n",
      "Iter 101 Batch 2 / 22 Loss: 0.88343054\n",
      "Iter 101 Batch 3 / 22 Loss: 0.44897962\n",
      "Iter 101 Batch 4 / 22 Loss: 0.36612752\n",
      "Iter 101 Batch 5 / 22 Loss: 0.76493716\n",
      "Iter 101 Batch 6 / 22 Loss: 1.3884857\n",
      "Iter 101 Batch 7 / 22 Loss: 0.74081963\n",
      "Iter 101 Batch 8 / 22 Loss: 0.8931891\n",
      "Iter 101 Batch 9 / 22 Loss: 0.5159411\n",
      "Iter 101 Batch 10 / 22 Loss: 0.7423214\n",
      "Iter 101 Batch 11 / 22 Loss: 1.1893251\n",
      "Iter 101 Batch 12 / 22 Loss: 0.90808123\n",
      "Iter 101 Batch 13 / 22 Loss: 0.9249951\n",
      "Iter 101 Batch 14 / 22 Loss: 0.886879\n",
      "Iter 101 Batch 15 / 22 Loss: 0.67697585\n",
      "Iter 101 Batch 16 / 22 Loss: 0.37329197\n",
      "Iter 101 Batch 17 / 22 Loss: 0.68453485\n",
      "Iter 101 Batch 18 / 22 Loss: 0.58730996\n",
      "Iter 101 Batch 19 / 22 Loss: 0.77042323\n",
      "Iter 101 Batch 20 / 22 Loss: 1.0339894\n",
      "Iter 101 Batch 21 / 22 Loss: 0.9217302\n",
      "Iter 102 Batch 0 / 22 Loss: 1.068252\n",
      "Iter 102 Batch 1 / 22 Loss: 0.61464435\n",
      "Iter 102 Batch 2 / 22 Loss: 0.8428453\n",
      "Iter 102 Batch 3 / 22 Loss: 0.43233725\n",
      "Iter 102 Batch 4 / 22 Loss: 0.57100236\n",
      "Iter 102 Batch 5 / 22 Loss: 0.7225165\n",
      "Iter 102 Batch 6 / 22 Loss: 1.4066999\n",
      "Iter 102 Batch 7 / 22 Loss: 0.7882223\n",
      "Iter 102 Batch 8 / 22 Loss: 0.8920636\n",
      "Iter 102 Batch 9 / 22 Loss: 0.5141388\n",
      "Iter 102 Batch 10 / 22 Loss: 0.7185191\n",
      "Iter 102 Batch 11 / 22 Loss: 1.1852927\n",
      "Iter 102 Batch 12 / 22 Loss: 0.8948611\n",
      "Iter 102 Batch 13 / 22 Loss: 0.9135195\n",
      "Iter 102 Batch 14 / 22 Loss: 0.86727846\n",
      "Iter 102 Batch 15 / 22 Loss: 0.6470225\n",
      "Iter 102 Batch 16 / 22 Loss: 0.3585992\n",
      "Iter 102 Batch 17 / 22 Loss: 0.65212244\n",
      "Iter 102 Batch 18 / 22 Loss: 0.60804147\n",
      "Iter 102 Batch 19 / 22 Loss: 0.7593157\n",
      "Iter 102 Batch 20 / 22 Loss: 1.0199763\n",
      "Iter 102 Batch 21 / 22 Loss: 0.8555884\n",
      "Iter 103 Batch 0 / 22 Loss: 0.99239975\n",
      "Iter 103 Batch 1 / 22 Loss: 0.6200954\n",
      "Iter 103 Batch 2 / 22 Loss: 0.84796363\n",
      "Iter 103 Batch 3 / 22 Loss: 0.42212787\n",
      "Iter 103 Batch 4 / 22 Loss: 0.5120273\n",
      "Iter 103 Batch 5 / 22 Loss: 0.72280586\n",
      "Iter 103 Batch 6 / 22 Loss: 1.3728408\n",
      "Iter 103 Batch 7 / 22 Loss: 0.7502648\n",
      "Iter 103 Batch 8 / 22 Loss: 0.89367867\n",
      "Iter 103 Batch 9 / 22 Loss: 0.5217535\n",
      "Iter 103 Batch 10 / 22 Loss: 0.7499432\n",
      "Iter 103 Batch 11 / 22 Loss: 1.1843574\n",
      "Iter 103 Batch 12 / 22 Loss: 0.8734678\n",
      "Iter 103 Batch 13 / 22 Loss: 0.91192114\n",
      "Iter 103 Batch 14 / 22 Loss: 0.8717648\n",
      "Iter 103 Batch 15 / 22 Loss: 0.63801956\n",
      "Iter 103 Batch 16 / 22 Loss: 0.35483766\n",
      "Iter 103 Batch 17 / 22 Loss: 0.6282629\n",
      "Iter 103 Batch 18 / 22 Loss: 0.57689756\n",
      "Iter 103 Batch 19 / 22 Loss: 0.74873626\n",
      "Iter 103 Batch 20 / 22 Loss: 1.0230702\n",
      "Iter 103 Batch 21 / 22 Loss: 0.70120883\n",
      "Iter 104 Batch 0 / 22 Loss: 1.052817\n",
      "Iter 104 Batch 1 / 22 Loss: 0.6044201\n",
      "Iter 104 Batch 2 / 22 Loss: 0.88369\n",
      "Iter 104 Batch 3 / 22 Loss: 0.44321293\n",
      "Iter 104 Batch 4 / 22 Loss: 0.57867074\n",
      "Iter 104 Batch 5 / 22 Loss: 0.7304918\n",
      "Iter 104 Batch 6 / 22 Loss: 1.3675518\n",
      "Iter 104 Batch 7 / 22 Loss: 0.75925785\n",
      "Iter 104 Batch 8 / 22 Loss: 0.86735076\n",
      "Iter 104 Batch 9 / 22 Loss: 0.5073081\n",
      "Iter 104 Batch 10 / 22 Loss: 0.7195862\n",
      "Iter 104 Batch 11 / 22 Loss: 1.1812762\n",
      "Iter 104 Batch 12 / 22 Loss: 0.86358875\n",
      "Iter 104 Batch 13 / 22 Loss: 0.89863575\n",
      "Iter 104 Batch 14 / 22 Loss: 0.86918116\n",
      "Iter 104 Batch 15 / 22 Loss: 0.632507\n",
      "Iter 104 Batch 16 / 22 Loss: 0.35041964\n",
      "Iter 104 Batch 17 / 22 Loss: 0.6235308\n",
      "Iter 104 Batch 18 / 22 Loss: 0.5855831\n",
      "Iter 104 Batch 19 / 22 Loss: 0.74121857\n",
      "Iter 104 Batch 20 / 22 Loss: 0.99856496\n",
      "Iter 104 Batch 21 / 22 Loss: 0.7855761\n",
      "Iter 105 Batch 0 / 22 Loss: 0.9550461\n",
      "Iter 105 Batch 1 / 22 Loss: 0.6262114\n",
      "Iter 105 Batch 2 / 22 Loss: 0.84565973\n",
      "Iter 105 Batch 3 / 22 Loss: 0.4401996\n",
      "Iter 105 Batch 4 / 22 Loss: 0.46337226\n",
      "Iter 105 Batch 5 / 22 Loss: 0.7119731\n",
      "Iter 105 Batch 6 / 22 Loss: 1.36498\n",
      "Iter 105 Batch 7 / 22 Loss: 0.7419926\n",
      "Iter 105 Batch 8 / 22 Loss: 0.863446\n",
      "Iter 105 Batch 9 / 22 Loss: 0.48424318\n",
      "Iter 105 Batch 10 / 22 Loss: 0.7373365\n",
      "Iter 105 Batch 11 / 22 Loss: 1.1818994\n",
      "Iter 105 Batch 12 / 22 Loss: 0.841437\n",
      "Iter 105 Batch 13 / 22 Loss: 0.89733016\n",
      "Iter 105 Batch 14 / 22 Loss: 0.86634666\n",
      "Iter 105 Batch 15 / 22 Loss: 0.6230813\n",
      "Iter 105 Batch 16 / 22 Loss: 0.35009998\n",
      "Iter 105 Batch 17 / 22 Loss: 0.6178646\n",
      "Iter 105 Batch 18 / 22 Loss: 0.56981444\n",
      "Iter 105 Batch 19 / 22 Loss: 0.729721\n",
      "Iter 105 Batch 20 / 22 Loss: 0.9943464\n",
      "Iter 105 Batch 21 / 22 Loss: 0.6793213\n",
      "Iter 106 Batch 0 / 22 Loss: 0.9722694\n",
      "Iter 106 Batch 1 / 22 Loss: 0.6559098\n",
      "Iter 106 Batch 2 / 22 Loss: 0.8698633\n",
      "Iter 106 Batch 3 / 22 Loss: 0.47978565\n",
      "Iter 106 Batch 4 / 22 Loss: 0.5605116\n",
      "Iter 106 Batch 5 / 22 Loss: 0.71234083\n",
      "Iter 106 Batch 6 / 22 Loss: 1.3594892\n",
      "Iter 106 Batch 7 / 22 Loss: 0.7357538\n",
      "Iter 106 Batch 8 / 22 Loss: 0.85309136\n",
      "Iter 106 Batch 9 / 22 Loss: 0.47650376\n",
      "Iter 106 Batch 10 / 22 Loss: 0.72126067\n",
      "Iter 106 Batch 11 / 22 Loss: 1.181019\n",
      "Iter 106 Batch 12 / 22 Loss: 0.83921397\n",
      "Iter 106 Batch 13 / 22 Loss: 0.88868093\n",
      "Iter 106 Batch 14 / 22 Loss: 0.86028194\n",
      "Iter 106 Batch 15 / 22 Loss: 0.57296044\n",
      "Iter 106 Batch 16 / 22 Loss: 0.33620185\n",
      "Iter 106 Batch 17 / 22 Loss: 0.6108744\n",
      "Iter 106 Batch 18 / 22 Loss: 0.5551652\n",
      "Iter 106 Batch 19 / 22 Loss: 0.7117694\n",
      "Iter 106 Batch 20 / 22 Loss: 0.98563486\n",
      "Iter 106 Batch 21 / 22 Loss: 0.74544466\n",
      "Iter 107 Batch 0 / 22 Loss: 0.8835351\n",
      "Iter 107 Batch 1 / 22 Loss: 0.6319877\n",
      "Iter 107 Batch 2 / 22 Loss: 0.8507245\n",
      "Iter 107 Batch 3 / 22 Loss: 0.4037887\n",
      "Iter 107 Batch 4 / 22 Loss: 0.295807\n",
      "Iter 107 Batch 5 / 22 Loss: 0.69319296\n",
      "Iter 107 Batch 6 / 22 Loss: 1.3642523\n",
      "Iter 107 Batch 7 / 22 Loss: 0.7436435\n",
      "Iter 107 Batch 8 / 22 Loss: 0.8504162\n",
      "Iter 107 Batch 9 / 22 Loss: 0.46612012\n",
      "Iter 107 Batch 10 / 22 Loss: 0.70781064\n",
      "Iter 107 Batch 11 / 22 Loss: 1.180144\n",
      "Iter 107 Batch 12 / 22 Loss: 0.83344096\n",
      "Iter 107 Batch 13 / 22 Loss: 0.88621575\n",
      "Iter 107 Batch 14 / 22 Loss: 0.85374665\n",
      "Iter 107 Batch 15 / 22 Loss: 0.5493516\n",
      "Iter 107 Batch 16 / 22 Loss: 0.33060282\n",
      "Iter 107 Batch 17 / 22 Loss: 0.6009191\n",
      "Iter 107 Batch 18 / 22 Loss: 0.554736\n",
      "Iter 107 Batch 19 / 22 Loss: 0.7076356\n",
      "Iter 107 Batch 20 / 22 Loss: 0.97990656\n",
      "Iter 107 Batch 21 / 22 Loss: 0.75769293\n",
      "Iter 108 Batch 0 / 22 Loss: 0.8738227\n",
      "Iter 108 Batch 1 / 22 Loss: 0.6222548\n",
      "Iter 108 Batch 2 / 22 Loss: 0.8424506\n",
      "Iter 108 Batch 3 / 22 Loss: 0.39529917\n",
      "Iter 108 Batch 4 / 22 Loss: 0.29305452\n",
      "Iter 108 Batch 5 / 22 Loss: 0.68758166\n",
      "Iter 108 Batch 6 / 22 Loss: 1.3614986\n",
      "Iter 108 Batch 7 / 22 Loss: 0.72366786\n",
      "Iter 108 Batch 8 / 22 Loss: 0.85043615\n",
      "Iter 108 Batch 9 / 22 Loss: 0.4561384\n",
      "Iter 108 Batch 10 / 22 Loss: 0.6998557\n",
      "Iter 108 Batch 11 / 22 Loss: 1.178276\n",
      "Iter 108 Batch 12 / 22 Loss: 0.8328087\n",
      "Iter 108 Batch 13 / 22 Loss: 0.8820032\n",
      "Iter 108 Batch 14 / 22 Loss: 0.8504767\n",
      "Iter 108 Batch 15 / 22 Loss: 0.5451155\n",
      "Iter 108 Batch 16 / 22 Loss: 0.32640192\n",
      "Iter 108 Batch 17 / 22 Loss: 0.6048095\n",
      "Iter 108 Batch 18 / 22 Loss: 0.5553658\n",
      "Iter 108 Batch 19 / 22 Loss: 0.7002092\n",
      "Iter 108 Batch 20 / 22 Loss: 0.97057736\n",
      "Iter 108 Batch 21 / 22 Loss: 0.7257365\n",
      "Iter 109 Batch 0 / 22 Loss: 0.8678311\n",
      "Iter 109 Batch 1 / 22 Loss: 0.60904324\n",
      "Iter 109 Batch 2 / 22 Loss: 0.84753156\n",
      "Iter 109 Batch 3 / 22 Loss: 0.3933365\n",
      "Iter 109 Batch 4 / 22 Loss: 0.29242957\n",
      "Iter 109 Batch 5 / 22 Loss: 0.68994397\n",
      "Iter 109 Batch 6 / 22 Loss: 1.3589768\n",
      "Iter 109 Batch 7 / 22 Loss: 0.71916693\n",
      "Iter 109 Batch 8 / 22 Loss: 0.8415191\n",
      "Iter 109 Batch 9 / 22 Loss: 0.44416624\n",
      "Iter 109 Batch 10 / 22 Loss: 0.69049644\n",
      "Iter 109 Batch 11 / 22 Loss: 1.1785959\n",
      "Iter 109 Batch 12 / 22 Loss: 0.8243104\n",
      "Iter 109 Batch 13 / 22 Loss: 0.88106585\n",
      "Iter 109 Batch 14 / 22 Loss: 0.8460799\n",
      "Iter 109 Batch 15 / 22 Loss: 0.5687431\n",
      "Iter 109 Batch 16 / 22 Loss: 0.32621127\n",
      "Iter 109 Batch 17 / 22 Loss: 0.5804368\n",
      "Iter 109 Batch 18 / 22 Loss: 0.5570407\n",
      "Iter 109 Batch 19 / 22 Loss: 0.6960327\n",
      "Iter 109 Batch 20 / 22 Loss: 0.97081196\n",
      "Iter 109 Batch 21 / 22 Loss: 0.6641239\n",
      "Iter 110 Batch 0 / 22 Loss: 0.8416507\n",
      "Iter 110 Batch 1 / 22 Loss: 0.6016613\n",
      "Iter 110 Batch 2 / 22 Loss: 0.85487014\n",
      "Iter 110 Batch 3 / 22 Loss: 0.3918537\n",
      "Iter 110 Batch 4 / 22 Loss: 0.39316815\n",
      "Iter 110 Batch 5 / 22 Loss: 0.6912628\n",
      "Iter 110 Batch 6 / 22 Loss: 1.3491368\n",
      "Iter 110 Batch 7 / 22 Loss: 0.71971524\n",
      "Iter 110 Batch 8 / 22 Loss: 0.8359881\n",
      "Iter 110 Batch 9 / 22 Loss: 0.43622005\n",
      "Iter 110 Batch 10 / 22 Loss: 0.69242406\n",
      "Iter 110 Batch 11 / 22 Loss: 1.177942\n",
      "Iter 110 Batch 12 / 22 Loss: 0.8263707\n",
      "Iter 110 Batch 13 / 22 Loss: 0.87917143\n",
      "Iter 110 Batch 14 / 22 Loss: 0.83746344\n",
      "Iter 110 Batch 15 / 22 Loss: 0.53533167\n",
      "Iter 110 Batch 16 / 22 Loss: 0.32254907\n",
      "Iter 110 Batch 17 / 22 Loss: 0.5778381\n",
      "Iter 110 Batch 18 / 22 Loss: 0.54945797\n",
      "Iter 110 Batch 19 / 22 Loss: 0.6677612\n",
      "Iter 110 Batch 20 / 22 Loss: 0.965256\n",
      "Iter 110 Batch 21 / 22 Loss: 0.6937828\n",
      "Iter 111 Batch 0 / 22 Loss: 0.8633586\n",
      "Iter 111 Batch 1 / 22 Loss: 0.60874057\n",
      "Iter 111 Batch 2 / 22 Loss: 0.83293176\n",
      "Iter 111 Batch 3 / 22 Loss: 0.38910368\n",
      "Iter 111 Batch 4 / 22 Loss: 0.2913556\n",
      "Iter 111 Batch 5 / 22 Loss: 0.6786432\n",
      "Iter 111 Batch 6 / 22 Loss: 1.3524026\n",
      "Iter 111 Batch 7 / 22 Loss: 0.68852437\n",
      "Iter 111 Batch 8 / 22 Loss: 0.8311893\n",
      "Iter 111 Batch 9 / 22 Loss: 0.4443028\n",
      "Iter 111 Batch 10 / 22 Loss: 0.69099575\n",
      "Iter 111 Batch 11 / 22 Loss: 1.1781027\n",
      "Iter 111 Batch 12 / 22 Loss: 0.8164414\n",
      "Iter 111 Batch 13 / 22 Loss: 0.8737056\n",
      "Iter 111 Batch 14 / 22 Loss: 0.8308725\n",
      "Iter 111 Batch 15 / 22 Loss: 0.53364444\n",
      "Iter 111 Batch 16 / 22 Loss: 0.32127744\n",
      "Iter 111 Batch 17 / 22 Loss: 0.5674022\n",
      "Iter 111 Batch 18 / 22 Loss: 0.5553925\n",
      "Iter 111 Batch 19 / 22 Loss: 0.6463367\n",
      "Iter 111 Batch 20 / 22 Loss: 0.96801734\n",
      "Iter 111 Batch 21 / 22 Loss: 0.6391549\n",
      "Iter 112 Batch 0 / 22 Loss: 0.83341706\n",
      "Iter 112 Batch 1 / 22 Loss: 0.60002285\n",
      "Iter 112 Batch 2 / 22 Loss: 0.8498908\n",
      "Iter 112 Batch 3 / 22 Loss: 0.38479167\n",
      "Iter 112 Batch 4 / 22 Loss: 0.39352834\n",
      "Iter 112 Batch 5 / 22 Loss: 0.6819997\n",
      "Iter 112 Batch 6 / 22 Loss: 1.3393688\n",
      "Iter 112 Batch 7 / 22 Loss: 0.7116733\n",
      "Iter 112 Batch 8 / 22 Loss: 0.82726043\n",
      "Iter 112 Batch 9 / 22 Loss: 0.4216712\n",
      "Iter 112 Batch 10 / 22 Loss: 0.6929572\n",
      "Iter 112 Batch 11 / 22 Loss: 1.1777186\n",
      "Iter 112 Batch 12 / 22 Loss: 0.81475735\n",
      "Iter 112 Batch 13 / 22 Loss: 0.87221634\n",
      "Iter 112 Batch 14 / 22 Loss: 0.8209272\n",
      "Iter 112 Batch 15 / 22 Loss: 0.5309643\n",
      "Iter 112 Batch 16 / 22 Loss: 0.32168955\n",
      "Iter 112 Batch 17 / 22 Loss: 0.5682985\n",
      "Iter 112 Batch 18 / 22 Loss: 0.5539924\n",
      "Iter 112 Batch 19 / 22 Loss: 0.65049857\n",
      "Iter 112 Batch 20 / 22 Loss: 1.005635\n",
      "Iter 112 Batch 21 / 22 Loss: 0.6445341\n",
      "Iter 113 Batch 0 / 22 Loss: 0.8144106\n",
      "Iter 113 Batch 1 / 22 Loss: 0.59733224\n",
      "Iter 113 Batch 2 / 22 Loss: 0.8359446\n",
      "Iter 113 Batch 3 / 22 Loss: 0.37286916\n",
      "Iter 113 Batch 4 / 22 Loss: 0.3375571\n",
      "Iter 113 Batch 5 / 22 Loss: 0.69105196\n",
      "Iter 113 Batch 6 / 22 Loss: 1.3489383\n",
      "Iter 113 Batch 7 / 22 Loss: 0.68439573\n",
      "Iter 113 Batch 8 / 22 Loss: 0.8675144\n",
      "Iter 113 Batch 9 / 22 Loss: 0.4857614\n",
      "Iter 113 Batch 10 / 22 Loss: 0.7075504\n",
      "Iter 113 Batch 11 / 22 Loss: 1.1776168\n",
      "Iter 113 Batch 12 / 22 Loss: 0.8168589\n",
      "Iter 113 Batch 13 / 22 Loss: 0.8665571\n",
      "Iter 113 Batch 14 / 22 Loss: 0.82994044\n",
      "Iter 113 Batch 15 / 22 Loss: 0.53063583\n",
      "Iter 113 Batch 16 / 22 Loss: 0.3181843\n",
      "Iter 113 Batch 17 / 22 Loss: 0.5664807\n",
      "Iter 113 Batch 18 / 22 Loss: 0.5620241\n",
      "Iter 113 Batch 19 / 22 Loss: 0.66113794\n",
      "Iter 113 Batch 20 / 22 Loss: 0.999691\n",
      "Iter 113 Batch 21 / 22 Loss: 0.6502821\n",
      "Iter 114 Batch 0 / 22 Loss: 0.7942588\n",
      "Iter 114 Batch 1 / 22 Loss: 0.5919988\n",
      "Iter 114 Batch 2 / 22 Loss: 0.8384689\n",
      "Iter 114 Batch 3 / 22 Loss: 0.36740974\n",
      "Iter 114 Batch 4 / 22 Loss: 0.33572605\n",
      "Iter 114 Batch 5 / 22 Loss: 0.6805637\n",
      "Iter 114 Batch 6 / 22 Loss: 1.336924\n",
      "Iter 114 Batch 7 / 22 Loss: 0.6841585\n",
      "Iter 114 Batch 8 / 22 Loss: 0.8238376\n",
      "Iter 114 Batch 9 / 22 Loss: 0.402753\n",
      "Iter 114 Batch 10 / 22 Loss: 0.6871767\n",
      "Iter 114 Batch 11 / 22 Loss: 1.1759814\n",
      "Iter 114 Batch 12 / 22 Loss: 0.8148222\n",
      "Iter 114 Batch 13 / 22 Loss: 0.8623147\n",
      "Iter 114 Batch 14 / 22 Loss: 0.8119641\n",
      "Iter 114 Batch 15 / 22 Loss: 0.5443158\n",
      "Iter 114 Batch 16 / 22 Loss: 0.3197111\n",
      "Iter 114 Batch 17 / 22 Loss: 0.5570109\n",
      "Iter 114 Batch 18 / 22 Loss: 0.5530802\n",
      "Iter 114 Batch 19 / 22 Loss: 0.6339714\n",
      "Iter 114 Batch 20 / 22 Loss: 0.99674404\n",
      "Iter 114 Batch 21 / 22 Loss: 0.61991084\n",
      "Iter 115 Batch 0 / 22 Loss: 0.80567443\n",
      "Iter 115 Batch 1 / 22 Loss: 0.6161865\n",
      "Iter 115 Batch 2 / 22 Loss: 0.84260654\n",
      "Iter 115 Batch 3 / 22 Loss: 0.36926877\n",
      "Iter 115 Batch 4 / 22 Loss: 0.3265358\n",
      "Iter 115 Batch 5 / 22 Loss: 0.67656606\n",
      "Iter 115 Batch 6 / 22 Loss: 1.3351263\n",
      "Iter 115 Batch 7 / 22 Loss: 0.7190206\n",
      "Iter 115 Batch 8 / 22 Loss: 0.8253337\n",
      "Iter 115 Batch 9 / 22 Loss: 0.40179837\n",
      "Iter 115 Batch 10 / 22 Loss: 0.6864282\n",
      "Iter 115 Batch 11 / 22 Loss: 1.1760011\n",
      "Iter 115 Batch 12 / 22 Loss: 0.806764\n",
      "Iter 115 Batch 13 / 22 Loss: 0.858038\n",
      "Iter 115 Batch 14 / 22 Loss: 0.8458922\n",
      "Iter 115 Batch 15 / 22 Loss: 0.5230609\n",
      "Iter 115 Batch 16 / 22 Loss: 0.31673706\n",
      "Iter 115 Batch 17 / 22 Loss: 0.5490321\n",
      "Iter 115 Batch 18 / 22 Loss: 0.5577521\n",
      "Iter 115 Batch 19 / 22 Loss: 0.5915585\n",
      "Iter 115 Batch 20 / 22 Loss: 0.9531482\n",
      "Iter 115 Batch 21 / 22 Loss: 0.620177\n",
      "Iter 116 Batch 0 / 22 Loss: 0.7750155\n",
      "Iter 116 Batch 1 / 22 Loss: 0.6012974\n",
      "Iter 116 Batch 2 / 22 Loss: 0.82685846\n",
      "Iter 116 Batch 3 / 22 Loss: 0.35917497\n",
      "Iter 116 Batch 4 / 22 Loss: 0.3141501\n",
      "Iter 116 Batch 5 / 22 Loss: 0.6663656\n",
      "Iter 116 Batch 6 / 22 Loss: 1.3365644\n",
      "Iter 116 Batch 7 / 22 Loss: 0.6903823\n",
      "Iter 116 Batch 8 / 22 Loss: 0.81511223\n",
      "Iter 116 Batch 9 / 22 Loss: 0.39397523\n",
      "Iter 116 Batch 10 / 22 Loss: 0.68422407\n",
      "Iter 116 Batch 11 / 22 Loss: 1.1779076\n",
      "Iter 116 Batch 12 / 22 Loss: 0.80283695\n",
      "Iter 116 Batch 13 / 22 Loss: 0.8605844\n",
      "Iter 116 Batch 14 / 22 Loss: 0.81818885\n",
      "Iter 116 Batch 15 / 22 Loss: 0.52706885\n",
      "Iter 116 Batch 16 / 22 Loss: 0.31197107\n",
      "Iter 116 Batch 17 / 22 Loss: 0.5412237\n",
      "Iter 116 Batch 18 / 22 Loss: 0.55619556\n",
      "Iter 116 Batch 19 / 22 Loss: 0.55860233\n",
      "Iter 116 Batch 20 / 22 Loss: 0.94324565\n",
      "Iter 116 Batch 21 / 22 Loss: 0.5990441\n",
      "Iter 117 Batch 0 / 22 Loss: 0.7685969\n",
      "Iter 117 Batch 1 / 22 Loss: 0.5715545\n",
      "Iter 117 Batch 2 / 22 Loss: 0.8268281\n",
      "Iter 117 Batch 3 / 22 Loss: 0.3565768\n",
      "Iter 117 Batch 4 / 22 Loss: 0.31355393\n",
      "Iter 117 Batch 5 / 22 Loss: 0.6628696\n",
      "Iter 117 Batch 6 / 22 Loss: 1.3216667\n",
      "Iter 117 Batch 7 / 22 Loss: 0.68549305\n",
      "Iter 117 Batch 8 / 22 Loss: 0.814548\n",
      "Iter 117 Batch 9 / 22 Loss: 0.3984839\n",
      "Iter 117 Batch 10 / 22 Loss: 0.6746661\n",
      "Iter 117 Batch 11 / 22 Loss: 1.1800182\n",
      "Iter 117 Batch 12 / 22 Loss: 0.8037007\n",
      "Iter 117 Batch 13 / 22 Loss: 0.8519829\n",
      "Iter 117 Batch 14 / 22 Loss: 0.7936172\n",
      "Iter 117 Batch 15 / 22 Loss: 0.51507616\n",
      "Iter 117 Batch 16 / 22 Loss: 0.32362214\n",
      "Iter 117 Batch 17 / 22 Loss: 0.5358266\n",
      "Iter 117 Batch 18 / 22 Loss: 0.55665934\n",
      "Iter 117 Batch 19 / 22 Loss: 0.5455705\n",
      "Iter 117 Batch 20 / 22 Loss: 0.93678\n",
      "Iter 117 Batch 21 / 22 Loss: 0.5870809\n",
      "Iter 118 Batch 0 / 22 Loss: 0.78155994\n",
      "Iter 118 Batch 1 / 22 Loss: 0.5668676\n",
      "Iter 118 Batch 2 / 22 Loss: 0.82830536\n",
      "Iter 118 Batch 3 / 22 Loss: 0.35085806\n",
      "Iter 118 Batch 4 / 22 Loss: 0.3119857\n",
      "Iter 118 Batch 5 / 22 Loss: 0.6601263\n",
      "Iter 118 Batch 6 / 22 Loss: 1.311222\n",
      "Iter 118 Batch 7 / 22 Loss: 0.673141\n",
      "Iter 118 Batch 8 / 22 Loss: 0.8127652\n",
      "Iter 118 Batch 9 / 22 Loss: 0.4099876\n",
      "Iter 118 Batch 10 / 22 Loss: 0.6719923\n",
      "Iter 118 Batch 11 / 22 Loss: 1.1757486\n",
      "Iter 118 Batch 12 / 22 Loss: 0.8041855\n",
      "Iter 118 Batch 13 / 22 Loss: 0.8505834\n",
      "Iter 118 Batch 14 / 22 Loss: 0.79243815\n",
      "Iter 118 Batch 15 / 22 Loss: 0.50971186\n",
      "Iter 118 Batch 16 / 22 Loss: 0.31259367\n",
      "Iter 118 Batch 17 / 22 Loss: 0.5377482\n",
      "Iter 118 Batch 18 / 22 Loss: 0.55008686\n",
      "Iter 118 Batch 19 / 22 Loss: 0.53809696\n",
      "Iter 118 Batch 20 / 22 Loss: 0.9320941\n",
      "Iter 118 Batch 21 / 22 Loss: 0.57245755\n",
      "Iter 119 Batch 0 / 22 Loss: 0.8192558\n",
      "Iter 119 Batch 1 / 22 Loss: 0.5480928\n",
      "Iter 119 Batch 2 / 22 Loss: 0.82061476\n",
      "Iter 119 Batch 3 / 22 Loss: 0.37394235\n",
      "Iter 119 Batch 4 / 22 Loss: 0.3240788\n",
      "Iter 119 Batch 5 / 22 Loss: 0.64787006\n",
      "Iter 119 Batch 6 / 22 Loss: 1.3372023\n",
      "Iter 119 Batch 7 / 22 Loss: 0.67761815\n",
      "Iter 119 Batch 8 / 22 Loss: 0.8084639\n",
      "Iter 119 Batch 9 / 22 Loss: 0.43847677\n",
      "Iter 119 Batch 10 / 22 Loss: 0.69081444\n",
      "Iter 119 Batch 11 / 22 Loss: 1.1751136\n",
      "Iter 119 Batch 12 / 22 Loss: 0.77475816\n",
      "Iter 119 Batch 13 / 22 Loss: 0.8642974\n",
      "Iter 119 Batch 14 / 22 Loss: 0.87536633\n",
      "Iter 119 Batch 15 / 22 Loss: 0.552003\n",
      "Iter 119 Batch 16 / 22 Loss: 0.31929594\n",
      "Iter 119 Batch 17 / 22 Loss: 0.6213541\n",
      "Iter 119 Batch 18 / 22 Loss: 0.5802864\n",
      "Iter 119 Batch 19 / 22 Loss: 0.5767162\n",
      "Iter 119 Batch 20 / 22 Loss: 0.9585973\n",
      "Iter 119 Batch 21 / 22 Loss: 0.57646406\n"
     ]
    }
   ],
   "source": [
    "bins_per_channel = 128\n",
    "input_dims = bins_per_channel*3 #RGB\n",
    "output_classes = 3 #Terran, Protoss, Zerg\n",
    "iterations = 120\n",
    "learning_rate=1e-4\n",
    "batch_size=4\n",
    "resize_shape = (64,64)\n",
    "x_col='filename'\n",
    "y_col='target'\n",
    "\n",
    "#Model\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(units=16, activation='relu', input_dim=input_dims))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=16, activation='relu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(units=output_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.SGD(lr=learning_rate, momentum=0.9, nesterov=True))\n",
    "\n",
    "# Iterations\n",
    "\n",
    "rows = train_df.shape[0]\n",
    "batches = int(np.ceil(rows/batch_size))\n",
    "\n",
    "for iterx in range(iterations):\n",
    "    for batch in range(batches):\n",
    "        offset = batch*batch_size\n",
    "        xb,yb = batch_hist_from_df(idf=train_df,x_col=x_col,y_col=y_col,\n",
    "                           batch_size=batch_size,offset=offset,\n",
    "                            resize=resize_shape,bins=bins_per_channel)\n",
    "        loss = model.train_on_batch(xb, yb)\n",
    "        print(\"Iter\",iterx,\"/\",iterations,\"Batch\",batch,\"/\",batches,\"Loss:\",loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test our model in the testing set  \n",
    "Now, we define our batch testing using the testing set. Since the **predict** or **evaluate ** functions of the model keras doesn't have the metrics parameter, we calculate the accuracy manually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0 / 6 Loss: 0.9565176963806152\n",
      "Batch 1 / 6 Loss: 1.0996533632278442\n",
      "Batch 2 / 6 Loss: 1.2299405336380005\n",
      "Batch 3 / 6 Loss: 1.0088927745819092\n",
      "Batch 4 / 6 Loss: 0.685764729976654\n",
      "Batch 5 / 6 Loss: 0.884490966796875\n",
      "Total accuracy 0.4583333333333333\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Evaluate\n",
    "#loss_and_metrics = model.evaluate(x_test, y_test)\n",
    "test_rows = test_df.shape[0]\n",
    "tbatches = int(np.ceil(test_rows/batch_size))\n",
    "general_accuracy = []\n",
    "\n",
    "for batch in range(tbatches):\n",
    "    offset = batch*batch_size\n",
    "    xb,yb = batch_hist_from_df(idf=test_df,x_col=x_col,y_col=y_col,\n",
    "                           batch_size=batch_size,offset=offset,\n",
    "                            resize=resize_shape,bins=bins_per_channel)\n",
    "    \n",
    "    classes = model.predict(xb)\n",
    "    loss = model.evaluate(xb, yb,verbose=0)\n",
    "    \n",
    "    class_pred = np.argmax(classes,1)\n",
    "    print(\"Batch\",batch,\"/\",tbatches,\"Loss:\",loss)\n",
    "    ground_truth = np.argmax(yb,1)\n",
    "    \n",
    "    accuracy = sum(np.equal(class_pred,ground_truth))/batch_size\n",
    "    general_accuracy.append(accuracy)    \n",
    "\n",
    "print(\"Total accuracy\",np.mean(general_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
